# AWS - EKS Post Exploitation

{{#include ../../../../banners/hacktricks-training.md}}

## EKS

Für weitere Informationen siehe

{{#ref}}
../../aws-services/aws-eks-enum.md
{{#endref}}

### Enumerate the cluster from the AWS Console

Wenn Sie die Berechtigung **`eks:AccessKubernetesApi`** haben, können Sie **Kubernetes-Objekte anzeigen** über die AWS EKS-Konsole ([Learn more](https://docs.aws.amazon.com/eks/latest/userguide/view-workloads.html)).

### Mit dem AWS Kubernetes Cluster verbinden

- Einfache Methode:
```bash
# Generate kubeconfig
aws eks update-kubeconfig --name aws-eks-dev
```
- Nicht der einfache Weg:

Wenn du **ein Token erhalten kannst** mit **`aws eks get-token --name <cluster_name>`** aber keine Berechtigungen hast, Cluster-Informationen abzurufen (describeCluster), könntest du **deine eigene `~/.kube/config` vorbereiten**. Allerdings brauchst du, obwohl du das Token hast, noch den **URL-Endpunkt, um dich zu verbinden** (wenn du es geschafft hast, ein JWT token aus einem pod zu bekommen, lies [here](aws-eks-post-exploitation/README.md#get-api-server-endpoint-from-a-jwt-token)) und den **Namen des Clusters**.

In meinem Fall habe ich die Info nicht in den CloudWatch-Logs gefunden, sondern in den LaunchTemaplates userData und auch in den userData der EC2-Maschinen. Diese Info sieht man in userData leicht, zum Beispiel im nächsten Beispiel (der Clustername war cluster-name):
```bash
API_SERVER_URL=https://6253F6CA47F81264D8E16FAA7A103A0D.gr7.us-east-1.eks.amazonaws.com

/etc/eks/bootstrap.sh cluster-name --kubelet-extra-args '--node-labels=eks.amazonaws.com/sourceLaunchTemplateVersion=1,alpha.eksctl.io/cluster-name=cluster-name,alpha.eksctl.io/nodegroup-name=prd-ondemand-us-west-2b,role=worker,eks.amazonaws.com/nodegroup-image=ami-002539dd2c532d0a5,eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup=prd-ondemand-us-west-2b,type=ondemand,eks.amazonaws.com/sourceLaunchTemplateId=lt-0f0f0ba62bef782e5 --max-pods=58' --b64-cluster-ca $B64_CLUSTER_CA --apiserver-endpoint $API_SERVER_URL --dns-cluster-ip $K8S_CLUSTER_DNS_IP --use-max-pods false
```
<details>

<summary>kube config</summary>
```yaml
describe-cache-parametersapiVersion: v1
clusters:
- cluster:
certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeU1USXlPREUyTWpjek1Wb1hEVE15TVRJeU5URTJNamN6TVZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTDlXCk9OS0ZqeXZoRUxDZGhMNnFwWkMwa1d0UURSRVF1UzVpRDcwK2pjbjFKWXZ4a3FsV1ZpbmtwOUt5N2x2ME5mUW8KYkNqREFLQWZmMEtlNlFUWVVvOC9jQXJ4K0RzWVlKV3dzcEZGbWlsY1lFWFZHMG5RV1VoMVQ3VWhOanc0MllMRQpkcVpzTGg4OTlzTXRLT1JtVE5sN1V6a05pTlUzSytueTZSRysvVzZmbFNYYnRiT2kwcXJSeFVpcDhMdWl4WGRVCnk4QTg3VjRjbllsMXo2MUt3NllIV3hhSm11eWI5enRtbCtBRHQ5RVhOUXhDMExrdWcxSDBqdTl1MDlkU09YYlkKMHJxY2lINjYvSTh0MjlPZ3JwNkY0dit5eUNJUjZFQURRaktHTFVEWUlVSkZ4WXA0Y1pGcVA1aVJteGJ5Nkh3UwpDSE52TWNJZFZRRUNQMlg5R2c4Q0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZQVXFsekhWZmlDd0xqalhPRmJJUUc3L0VxZ1hNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBS1o4c0l4aXpsemx0aXRPcGcySgpYV0VUSThoeWxYNWx6cW1mV0dpZkdFVVduUDU3UEVtWW55eWJHbnZ5RlVDbnczTldMRTNrbEVMQVE4d0tLSG8rCnBZdXAzQlNYamdiWFovdWVJc2RhWlNucmVqNU1USlJ3SVFod250ZUtpU0J4MWFRVU01ZGdZc2c4SlpJY3I2WC8KRG5POGlHOGxmMXVxend1dUdHSHM2R1lNR0Mvd1V0czVvcm1GS291SmtSUWhBZElMVkNuaStYNCtmcHUzT21UNwprS3VmR0tyRVlKT09VL1c2YTB3OTRycU9iSS9Mem1GSWxJQnVNcXZWVDBwOGtlcTc1eklpdGNzaUJmYVVidng3Ci9sMGhvS1RqM0IrOGlwbktIWW4wNGZ1R2F2YVJRbEhWcldDVlZ4c3ZyYWpxOUdJNWJUUlJ6TnpTbzFlcTVZNisKRzVBPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
server: https://6253F6CA47F81264D8E16FAA7A103A0D.gr7.us-west-2.eks.amazonaws.com
name: arn:aws:eks:us-east-1:<acc-id>:cluster/<cluster-name>
contexts:
- context:
cluster: arn:aws:eks:us-east-1:<acc-id>:cluster/<cluster-name>
user: arn:aws:eks:us-east-1:<acc-id>:cluster/<cluster-name>
name: arn:aws:eks:us-east-1:<acc-id>:cluster/<cluster-name>
current-context: arn:aws:eks:us-east-1:<acc-id>:cluster/<cluster-name>
kind: Config
preferences: {}
users:
- name: arn:aws:eks:us-east-1:<acc-id>:cluster/<cluster-name>
user:
exec:
apiVersion: client.authentication.k8s.io/v1beta1
args:
- --region
- us-west-2
- --profile
- <profile>
- eks
- get-token
- --cluster-name
- <cluster-name>
command: aws
env: null
interactiveMode: IfAvailable
provideClusterInfo: false
```
</details>

### From AWS to Kubernetes

Der **creator** des **EKS cluster** wird IMMER in der Lage sein, in den kubernetes-Clusterteil der Gruppe **`system:masters`** (k8s admin) zu gelangen. Zum Zeitpunkt dieses Schreibens gibt es **keinen direkten Weg**, herauszufinden, **wer den Cluster erstellt hat** (du kannst CloudTrail prüfen). Und es gibt **keinen Weg**, dieses **Privileg zu entfernen**.

Der Weg, **mehr AWS IAM users oder roles Zugriff auf K8s** zu gewähren, erfolgt über das **configmap** **`aws-auth`**.

> [!WARNING]
> Daher kann jeder mit **write access** auf das ConfigMap **`aws-auth`** den **gesamten Cluster kompromittieren**.

Für mehr Informationen darüber, wie man **zusätzliche Privilegien für IAM roles & users** im **gleichen oder einem anderen Account** gewährt und wie man dies **missbrauchen** kann, siehe [**privesc check this page**](../../../kubernetes-security/abusing-roles-clusterroles-in-kubernetes/index.html#aws-eks-aws-auth-configmaps).

Siehe auch[ **this awesome**](https://blog.lightspin.io/exploiting-eks-authentication-vulnerability-in-aws-iam-authenticator) **post to learn how the authentication IAM -> Kubernetes work**.

### From Kubernetes to AWS

Es ist möglich, eine **OpenID authentication for kubernetes service account** zu erlauben, damit diese Rollen in AWS übernehmen können. Erfahre, wie [**this work in this page**](../../../kubernetes-security/kubernetes-pivoting-to-clouds.md#workflow-of-iam-role-for-service-accounts-1).

### GET Api Server Endpoint from a JWT Token

Beim Decodieren des JWT token erhalten wir die cluster id & auch die Region. ![image](https://github.com/HackTricks-wiki/hacktricks-cloud/assets/87022719/0e47204a-eea5-4fcb-b702-36dc184a39e9) Dabei ist zu wissen, dass das Standardformat für EKS url ist
```bash
https://<cluster-id>.<two-random-chars><number>.<region>.eks.amazonaws.com
```
Ich habe keine Dokumentation gefunden, die die Kriterien für die 'two chars' und die 'number' erklärt. Nach einigen Tests meinerseits sehe ich jedoch wiederholt diese:

- gr7
- yl4

Es sind sowieso nur 3 chars — wir können sie bruteforce. Nutze das untenstehende Script, um die Liste zu generieren
```python
from itertools import product
from string import ascii_lowercase

letter_combinations = product('abcdefghijklmnopqrstuvwxyz', repeat = 2)
number_combinations = product('0123456789', repeat = 1)

result = [
f'{''.join(comb[0])}{comb[1][0]}'
for comb in product(letter_combinations, number_combinations)
]

with open('out.txt', 'w') as f:
f.write('\n'.join(result))
```
Dann mit wfuzz
```bash
wfuzz -Z -z file,out.txt --hw 0 https://<cluster-id>.FUZZ.<region>.eks.amazonaws.com
```
> [!WARNING]
> Denk daran, & zu ersetzen .

### Umgehung von CloudTrail

Wenn ein Angreifer Anmeldeinformationen eines AWS-Kontos mit **Berechtigungen für ein EKS** erlangt. Wenn der Angreifer seine eigene **`kubeconfig`** konfiguriert (ohne **`update-kubeconfig`** aufzurufen), wie zuvor erläutert, erzeugt **`get-token`** keine Logs in Cloudtrail, weil es nicht mit der AWS API interagiert (es erstellt das Token nur lokal).

Wenn der Angreifer also mit dem EKS-Cluster kommuniziert, **cloudtrail wird nichts protokollieren, was mit dem gestohlenen Benutzer und dessen Zugriff zusammenhängt**.

Beachte, dass das **EKS-Cluster möglicherweise Logs aktiviert hat**, die diesen Zugriff protokollieren (obwohl sie standardmäßig deaktiviert sind).

### EKS Lösegeld?

Standardmäßig hat der **Benutzer oder die Rolle, die einen Cluster erstellt hat**, **IMMER Admin-Rechte** über den Cluster. Und das ist der einzige "sichere" Zugriff, den AWS auf den Kubernetes-Cluster haben wird.

Also, wenn ein **Angreifer einen Cluster mit fargate kompromittiert** und **alle anderen Admins entfernt** und **den AWS user/role löscht, der den Cluster erstellt hat**, ~~könnte der Angreifer den Cluster erpresst haben~~.

> [!TIP]
> Beachte, dass wenn der Cluster **EC2 VMs** verwendet hat, es möglich sein kann, Admin-Rechte vom **Node** zu erlangen und den Cluster wiederherzustellen.
>
> Tatsächlich, wenn der Cluster Fargate verwendet, könntest du EC2-Nodes erstellen oder alles in den Cluster auf EC2 verschieben und ihn wiederherstellen, indem du auf die tokens im Node zugreifst.

{{#include ../../../../banners/hacktricks-training.md}}
