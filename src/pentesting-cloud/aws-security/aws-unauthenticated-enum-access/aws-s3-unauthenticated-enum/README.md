# AWS - S3 Unauthenticated Enum

{{#include ../../../../banners/hacktricks-training.md}}

## S3 Public Buckets

Ein Bucket gilt als **“public”**, wenn **jeder Benutzer den Inhalt** des Buckets auflisten kann, und als **“private”**, wenn der Inhalt des Buckets **nur von bestimmten Benutzern aufgelistet oder beschrieben werden kann**.

Unternehmen können **Berechtigungen von Buckets falsch konfiguriert** haben, wodurch Zugriff entweder auf alles oder auf alle in AWS authentifizierten Benutzer in jedem Konto (also auf jeden) gewährt wird. Beachte, dass selbst bei solchen Fehlkonfigurationen einige Aktionen möglicherweise nicht ausgeführt werden können, da Buckets eigene Access Control Lists (ACLs) haben können.

**Erfahre mehr über AWS-S3 Fehlkonfigurationen hier:** [**http://flaws.cloud**](http://flaws.cloud/) **und** [**http://flaws2.cloud/**](http://flaws2.cloud)

### Finding AWS Buckets

Verschiedene Methoden, um festzustellen, ob eine Webseite AWS verwendet, um Ressourcen zu speichern:

#### Enumeration & OSINT:

- Verwendung des Browser-Plugins **wappalyzer**
- Mit burp (**spidering** des Webs) oder durch manuelles Durchklicken der Seite werden alle **geladenen Ressourcen** im Verlauf gespeichert.
- **Prüfe Ressourcen** in Domains wie:

```
http://s3.amazonaws.com/[bucket_name]/
http://[bucket_name].s3.amazonaws.com/
```

- Prüfe auf **CNAMES**, da `resources.domain.com` möglicherweise das CNAME `bucket.s3.amazonaws.com` hat
- **[s3dns](https://github.com/olizimmermann/s3dns)** – Ein leichter DNS-Server, der passiv Cloud-Storage-Buckets (S3, GCP, Azure) durch Analyse des DNS-Verkehrs identifiziert. Er erkennt CNAMEs, folgt Auflösungs-Ketten und matched Bucket-Muster und bietet eine ruhige Alternative zu Brute-Force- oder API-basierter Entdeckung. Ideal für Recon- und OSINT-Workflows.
- Prüfe [https://buckets.grayhatwarfare.com](https://buckets.grayhatwarfare.com/), eine Webseite mit bereits **entdeckten offenen Buckets**.
- Der **Bucket-Name** und der **Bucket-Domainname** müssen **identisch** sein.
- **flaws.cloud** hat die **IP** 52.92.181.107 und wenn du die Seite aufrufst, leitet sie zu [https://aws.amazon.com/s3/](https://aws.amazon.com/s3/) weiter. Außerdem liefert `dig -x 52.92.181.107` `s3-website-us-west-2.amazonaws.com`.
- Um zu überprüfen, ob es sich um einen Bucket handelt, kannst du auch **https://flaws.cloud.s3.amazonaws.com/** besuchen.

#### Brute-Force

Du kannst Buckets finden, indem du Namen, die mit dem Unternehmen, das du pentesting, zusammenhängen, per Brute-Force ausprobierst:

- [https://github.com/sa7mon/S3Scanner](https://github.com/sa7mon/S3Scanner)
- [https://github.com/clario-tech/s3-inspector](https://github.com/clario-tech/s3-inspector)
- [https://github.com/jordanpotti/AWSBucketDump](https://github.com/jordanpotti/AWSBucketDump) (Enthält eine Liste mit potenziellen Bucket-Namen)
- [https://github.com/fellchase/flumberboozle/tree/master/flumberbuckets](https://github.com/fellchase/flumberboozle/tree/master/flumberbuckets)
- [https://github.com/smaranchand/bucky](https://github.com/smaranchand/bucky)
- [https://github.com/tomdev/teh_s3_bucketeers](https://github.com/tomdev/teh_s3_bucketeers)
- [https://github.com/RhinoSecurityLabs/Security-Research/tree/master/tools/aws-pentest-tools/s3](https://github.com/RhinoSecurityLabs/Security-Research/tree/master/tools/aws-pentest-tools/s3)
- [https://github.com/Eilonh/s3crets_scanner](https://github.com/Eilonh/s3crets_scanner)
- [https://github.com/belane/CloudHunter](https://github.com/belane/CloudHunter)

<pre class="language-bash"><code class="lang-bash"># Generate a wordlist to create permutations
curl -s https://raw.githubusercontent.com/cujanovic/goaltdns/master/words.txt > /tmp/words-s3.txt.temp
curl -s https://raw.githubusercontent.com/jordanpotti/AWSBucketDump/master/BucketNames.txt >>/tmp/words-s3.txt.temp
cat /tmp/words-s3.txt.temp | sort -u > /tmp/words-s3.txt

# Generate a wordlist based on the domains and subdomains to test
## Write those domains and subdomains in subdomains.txt
cat subdomains.txt > /tmp/words-hosts-s3.txt
cat subdomains.txt | tr "." "-" >> /tmp/words-hosts-s3.txt
cat subdomains.txt | tr "." "\n" | sort -u >> /tmp/words-hosts-s3.txt

# Create permutations based in a list with the domains and subdomains to attack
goaltdns -l /tmp/words-hosts-s3.txt -w /tmp/words-s3.txt -o /tmp/final-words-s3.txt.temp
## The previous tool is specialized increating permutations for subdomains, lets filter that list
<strong>### Remove lines ending with "."
</strong>cat /tmp/final-words-s3.txt.temp | grep -Ev "\.$" > /tmp/final-words-s3.txt.temp2
### Create list without TLD
cat /tmp/final-words-s3.txt.temp2 | sed -E 's/\.[a-zA-Z0-9]+$//' > /tmp/final-words-s3.txt.temp3
### Create list without dots
cat /tmp/final-words-s3.txt.temp3 | tr -d "." > /tmp/final-words-s3.txt.temp4http://phantom.s3.amazonaws.com/
### Create list without hyphens
cat /tmp/final-words-s3.txt.temp3 | tr "." "-" > /tmp/final-words-s3.txt.temp5

## Generate the final wordlist
cat /tmp/final-words-s3.txt.temp2 /tmp/final-words-s3.txt.temp3 /tmp/final-words-s3.txt.temp4 /tmp/final-words-s3.txt.temp5 | grep -v -- "-\." | awk '{print tolower($0)}' | sort -u > /tmp/final-words-s3.txt

## Call s3scanner
s3scanner --threads 100 scan --buckets-file /tmp/final-words-s3.txt  | grep bucket_exists
</code></pre>

#### Loot S3 Buckets

Bei offenen S3-Buckets kann [**BucketLoot**](https://github.com/redhuntlabs/BucketLoot) automatisch **nach interessanten Informationen suchen**.

### Find the Region

Du findest alle von AWS unterstützten Regionen unter [**https://docs.aws.amazon.com/general/latest/gr/s3.html**](https://docs.aws.amazon.com/general/latest/gr/s3.html)

#### By DNS

Du kannst die Region eines Buckets mittels `dig` und `nslookup` ermitteln, indem du eine DNS-Anfrage der entdeckten IP durchführst:
```bash
dig flaws.cloud
;; ANSWER SECTION:
flaws.cloud.    5    IN    A    52.218.192.11

nslookup 52.218.192.11
Non-authoritative answer:
11.192.218.52.in-addr.arpa name = s3-website-us-west-2.amazonaws.com.
```
Prüfe, ob die aufgelöste Domain das Wort "website" enthält.\
Du kannst auf die statische Website zugreifen, indem du folgende Adresse aufrufst: `flaws.cloud.s3-website-us-west-2.amazonaws.com`\
oder den Bucket über folgende Adresse aufrufen: `flaws.cloud.s3-us-west-2.amazonaws.com`



#### Durch Ausprobieren

Wenn du versuchst, auf einen Bucket zuzugreifen, aber in der **Domain eine andere Region angibst** (zum Beispiel ist der Bucket in `bucket.s3.amazonaws.com`, du versuchst aber `bucket.s3-website-us-west-2.amazonaws.com` aufzurufen), wirst du auf den **korrekten Standort hingewiesen**:

![](<../../../images/image (106).png>)

### Bucket enumerieren

Um die Offenheit des Buckets zu testen, kann ein Benutzer einfach die URL in seinem Webbrowser eingeben. Ein privater Bucket antwortet mit "Access Denied". Ein öffentlicher Bucket listet die ersten 1,000 Objekte, die gespeichert wurden.

Für alle offen:

![](<../../../images/image (201).png>)

Privat:

![](<../../../images/image (83).png>)

Du kannst das auch mit dem CLI prüfen:
```bash
#Use --no-sign-request for check Everyones permissions
#Use --profile <PROFILE_NAME> to indicate the AWS profile(keys) that youwant to use: Check for "Any Authenticated AWS User" permissions
#--recursive if you want list recursivelyls
#Opcionally you can select the region if you now it
aws s3 ls s3://flaws.cloud/ [--no-sign-request] [--profile <PROFILE_NAME>] [ --recursive] [--region us-west-2]
```
Wenn der Bucket keinen Domainnamen hat, verwende beim Versuch, ihn zu enumerate, **nur den Bucket-Namen** und nicht die gesamte AWSs3-Domain. Beispiel: `s3://<BUCKETNAME>`

### Öffentliche URL-Vorlage
```
https://{user_provided}.s3.amazonaws.com
```
### Account-ID aus öffentlichem Bucket abrufen

Es ist möglich, ein AWS-Konto zu ermitteln, indem man den neuen **`S3:ResourceAccount`** **Policy Condition Key** ausnutzt. Diese Bedingung schränkt den Zugriff basierend auf dem S3 bucket ein, in dem sich ein Account befindet (andere kontobasierte Richtlinien schränken basierend auf dem Konto ein, in dem sich der anfragende Principal befindet).\
Und weil die Richtlinie **wildcards** enthalten kann, ist es möglich, die Kontonummer **eine Ziffer nach der anderen** zu ermitteln.

Dieses Tool automatisiert den Prozess:
```bash
# Installation
pipx install s3-account-search
pip install s3-account-search
# With a bucket
s3-account-search arn:aws:iam::123456789012:role/s3_read s3://my-bucket
# With an object
s3-account-search arn:aws:iam::123456789012:role/s3_read s3://my-bucket/path/to/object.ext
```
Diese Technik funktioniert auch mit API Gateway URLs, Lambda URLs, Data Exchange data sets und sogar, um den Wert von tags zu erhalten (wenn du den tag key kennst). Du findest mehr Informationen in der [**original research**](https://blog.plerion.com/conditional-love-for-aws-metadata-enumeration/) und dem Tool [**conditional-love**](https://github.com/plerionhq/conditional-love/) zur Automatisierung dieser exploitation.

### Bestätigung, dass ein bucket zu einem AWS-Konto gehört

Wie in [**this blog post**](https://blog.plerion.com/things-you-wish-you-didnt-need-to-know-about-s3/)** erklärt, if you have permissions to list a bucket** ist es möglich, die accountID zu bestätigen, zu der der bucket gehört, indem du eine Anfrage wie folgt sendest:
```bash
curl -X GET "[bucketname].amazonaws.com/" \
-H "x-amz-expected-bucket-owner: [correct-account-id]"

<?xml version="1.0" encoding="UTF-8"?>
<ListBucketResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/">...</ListBucketResult>
```
Wenn der Fehler „Access Denied“ lautet, bedeutet das, dass die Account-ID falsch war.

### Verwendete E-Mails zur root account enumeration

Wie in [**this blog post**](https://blog.plerion.com/things-you-wish-you-didnt-need-to-know-about-s3/) erklärt, ist es möglich zu prüfen, ob eine E-Mail-Adresse mit einem AWS account verknüpft ist, indem man **versucht, einer E-Mail Berechtigungen** für einen S3-Bucket über ACLs zu gewähren. Wenn dadurch kein Fehler ausgelöst wird, bedeutet das, dass die E-Mail der root user eines AWS accounts ist:
```python
s3_client.put_bucket_acl(
Bucket=bucket_name,
AccessControlPolicy={
'Grants': [
{
'Grantee': {
'EmailAddress': 'some@emailtotest.com',
'Type': 'AmazonCustomerByEmail',
},
'Permission': 'READ'
},
],
'Owner': {
'DisplayName': 'Whatever',
'ID': 'c3d78ab5093a9ab8a5184de715d409c2ab5a0e2da66f08c2f6cc5c0bdeadbeef'
}
}
)
```
## Referenzen

- [https://www.youtube.com/watch?v=8ZXRw4Ry3mQ](https://www.youtube.com/watch?v=8ZXRw4Ry3mQ)
- [https://cloudar.be/awsblog/finding-the-account-id-of-any-public-s3-bucket/](https://cloudar.be/awsblog/finding-the-account-id-of-any-public-s3-bucket/)

{{#include ../../../../banners/hacktricks-training.md}}
