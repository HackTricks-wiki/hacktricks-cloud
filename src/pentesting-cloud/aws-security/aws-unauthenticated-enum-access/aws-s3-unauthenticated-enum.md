# AWS - S3 Unauthenticated Enum

{{#include ../../../banners/hacktricks-training.md}}

## S3 Öffentliche Buckets

Ein Bucket wird als **„öffentlich“** betrachtet, wenn **jeder Benutzer den Inhalt** des Buckets auflisten kann, und als **„privat“**, wenn der Inhalt des Buckets **nur von bestimmten Benutzern aufgelistet oder geschrieben werden kann**.

Unternehmen könnten **Berechtigungen für Buckets falsch konfiguriert** haben, was entweder den Zugriff auf alles oder auf alle authentifizierten Benutzer in AWS in jedem Konto (also auf jeden) ermöglicht. Beachten Sie, dass selbst bei solchen Fehlkonfigurationen einige Aktionen möglicherweise nicht ausgeführt werden können, da Buckets ihre eigenen Zugriffskontrolllisten (ACLs) haben können.

**Erfahren Sie hier mehr über AWS-S3 Fehlkonfigurationen:** [**http://flaws.cloud**](http://flaws.cloud/) **und** [**http://flaws2.cloud/**](http://flaws2.cloud)

### Finden von AWS Buckets

Verschiedene Methoden, um herauszufinden, ob eine Webseite AWS zur Speicherung von Ressourcen verwendet:

#### Enumeration & OSINT:

- Verwendung des **wappalyzer** Browser-Plugins
- Verwendung von burp (**Spidering** des Webs) oder durch manuelles Navigieren durch die Seite, alle **geladenen Ressourcen** werden im Verlauf gespeichert.
- **Überprüfen Sie Ressourcen** in Domains wie:

```
http://s3.amazonaws.com/[bucket_name]/
http://[bucket_name].s3.amazonaws.com/
```

- Überprüfen Sie auf **CNAMES**, da `resources.domain.com` den CNAME `bucket.s3.amazonaws.com` haben könnte
- **[s3dns](https://github.com/olizimmermann/s3dns)** – Ein leichter DNS-Server, der passiv Cloud-Speicher-Buckets (S3, GCP, Azure) identifiziert, indem er den DNS-Verkehr analysiert. Er erkennt CNAMEs, folgt Auflösungs-Ketten und passt Bucket-Muster an, was eine ruhige Alternative zu Brute-Force- oder API-basierten Entdeckungen bietet. Perfekt für Recon- und OSINT-Workflows.
- Überprüfen Sie [https://buckets.grayhatwarfare.com](https://buckets.grayhatwarfare.com/), eine Webseite mit bereits **entdeckten offenen Buckets**.
- Der **Bucket-Name** und der **Bucket-Domain-Name** müssen **identisch sein.**
- **flaws.cloud** hat die **IP** 52.92.181.107 und wenn Sie dorthin gehen, werden Sie zu [https://aws.amazon.com/s3/](https://aws.amazon.com/s3/) weitergeleitet. Auch `dig -x 52.92.181.107` gibt `s3-website-us-west-2.amazonaws.com` zurück.
- Um zu überprüfen, ob es sich um einen Bucket handelt, können Sie auch **besuchen** [https://flaws.cloud.s3.amazonaws.com/](https://flaws.cloud.s3.amazonaws.com/).

#### Brute-Force

Sie können Buckets finden, indem Sie **Namen** im Zusammenhang mit dem Unternehmen, das Sie testen, **brute-forcen**:

- [https://github.com/sa7mon/S3Scanner](https://github.com/sa7mon/S3Scanner)
- [https://github.com/clario-tech/s3-inspector](https://github.com/clario-tech/s3-inspector)
- [https://github.com/jordanpotti/AWSBucketDump](https://github.com/jordanpotti/AWSBucketDump) (Enthält eine Liste mit potenziellen Bucket-Namen)
- [https://github.com/fellchase/flumberboozle/tree/master/flumberbuckets](https://github.com/fellchase/flumberboozle/tree/master/flumberbuckets)
- [https://github.com/smaranchand/bucky](https://github.com/smaranchand/bucky)
- [https://github.com/tomdev/teh_s3_bucketeers](https://github.com/tomdev/teh_s3_bucketeers)
- [https://github.com/RhinoSecurityLabs/Security-Research/tree/master/tools/aws-pentest-tools/s3](https://github.com/RhinoSecurityLabs/Security-Research/tree/master/tools/aws-pentest-tools/s3)
- [https://github.com/Eilonh/s3crets_scanner](https://github.com/Eilonh/s3crets_scanner)
- [https://github.com/belane/CloudHunter](https://github.com/belane/CloudHunter)

<pre class="language-bash"><code class="lang-bash"># Generieren Sie eine Wortliste, um Permutationen zu erstellen
curl -s https://raw.githubusercontent.com/cujanovic/goaltdns/master/words.txt > /tmp/words-s3.txt.temp
curl -s https://raw.githubusercontent.com/jordanpotti/AWSBucketDump/master/BucketNames.txt >>/tmp/words-s3.txt.temp
cat /tmp/words-s3.txt.temp | sort -u > /tmp/words-s3.txt

# Generieren Sie eine Wortliste basierend auf den Domains und Subdomains, die getestet werden sollen
## Schreiben Sie diese Domains und Subdomains in subdomains.txt
cat subdomains.txt > /tmp/words-hosts-s3.txt
cat subdomains.txt | tr "." "-" >> /tmp/words-hosts-s3.txt
cat subdomains.txt | tr "." "\n" | sort -u >> /tmp/words-hosts-s3.txt

# Erstellen Sie Permutationen basierend auf einer Liste mit den Domains und Subdomains, die angegriffen werden sollen
goaltdns -l /tmp/words-hosts-s3.txt -w /tmp/words-s3.txt -o /tmp/final-words-s3.txt.temp
## Das vorherige Tool ist spezialisiert auf die Erstellung von Permutationen für Subdomains, lassen Sie uns diese Liste filtern
<strong>### Entfernen Sie Zeilen, die mit "." enden
</strong>cat /tmp/final-words-s3.txt.temp | grep -Ev "\.$" > /tmp/final-words-s3.txt.temp2
### Erstellen Sie eine Liste ohne TLD
cat /tmp/final-words-s3.txt.temp2 | sed -E 's/\.[a-zA-Z0-9]+$//' > /tmp/final-words-s3.txt.temp3
### Erstellen Sie eine Liste ohne Punkte
cat /tmp/final-words-s3.txt.temp3 | tr -d "." > /tmp/final-words-s3.txt.temp4http://phantom.s3.amazonaws.com/
### Erstellen Sie eine Liste ohne Bindestriche
cat /tmp/final-words-s3.txt.temp3 | tr "." "-" > /tmp/final-words-s3.txt.temp5

## Generieren Sie die endgültige Wortliste
cat /tmp/final-words-s3.txt.temp2 /tmp/final-words-s3.txt.temp3 /tmp/final-words-s3.txt.temp4 /tmp/final-words-s3.txt.temp5 | grep -v -- "-\." | awk '{print tolower($0)}' | sort -u > /tmp/final-words-s3.txt

## Rufen Sie s3scanner auf
s3scanner --threads 100 scan --buckets-file /tmp/final-words-s3.txt  | grep bucket_exists
</code></pre>

#### Loot S3 Buckets

Gegebene S3 offene Buckets kann [**BucketLoot**](https://github.com/redhuntlabs/BucketLoot) automatisch **nach interessanten Informationen suchen**.

### Finde die Region

Sie können alle von AWS unterstützten Regionen in [**https://docs.aws.amazon.com/general/latest/gr/s3.html**](https://docs.aws.amazon.com/general/latest/gr/s3.html) finden.

#### Über DNS

Sie können die Region eines Buckets mit einem **`dig`** und **`nslookup`** erhalten, indem Sie eine **DNS-Anfrage der entdeckten IP** durchführen:
```bash
dig flaws.cloud
;; ANSWER SECTION:
flaws.cloud.    5    IN    A    52.218.192.11

nslookup 52.218.192.11
Non-authoritative answer:
11.192.218.52.in-addr.arpa name = s3-website-us-west-2.amazonaws.com.
```
Überprüfen Sie, ob die aufgelöste Domain das Wort "website" enthält.\
Sie können auf die statische Website zugreifen, indem Sie zu: `flaws.cloud.s3-website-us-west-2.amazonaws.com` gehen\
oder Sie können auf den Bucket zugreifen, indem Sie besuchen: `flaws.cloud.s3-us-west-2.amazonaws.com`



#### Durch Ausprobieren

Wenn Sie versuchen, auf einen Bucket zuzugreifen, aber im **Domainnamen eine andere Region angeben** (zum Beispiel der Bucket ist in `bucket.s3.amazonaws.com`, aber Sie versuchen, auf `bucket.s3-website-us-west-2.amazonaws.com` zuzugreifen, dann werden Sie **auf den richtigen Standort hingewiesen**:

![](<../../../images/image (106).png>)

### Auflisten des Buckets

Um die Offenheit des Buckets zu testen, kann ein Benutzer einfach die URL in seinen Webbrowser eingeben. Ein privater Bucket antwortet mit "Zugriff verweigert". Ein öffentlicher Bucket listet die ersten 1.000 Objekte auf, die gespeichert wurden.

Für alle zugänglich:

![](<../../../images/image (201).png>)

Privat:

![](<../../../images/image (83).png>)

Sie können dies auch mit der CLI überprüfen:
```bash
#Use --no-sign-request for check Everyones permissions
#Use --profile <PROFILE_NAME> to indicate the AWS profile(keys) that youwant to use: Check for "Any Authenticated AWS User" permissions
#--recursive if you want list recursivelyls
#Opcionally you can select the region if you now it
aws s3 ls s3://flaws.cloud/ [--no-sign-request] [--profile <PROFILE_NAME>] [ --recursive] [--region us-west-2]
```
Wenn der Bucket keinen Domainnamen hat, geben Sie beim Versuch, ihn aufzulisten, **nur den Bucket-Namen** und nicht die gesamte AWSs3-Domain an. Beispiel: `s3://<BUCKETNAME>`

### Öffentliches URL-Template
```
https://{user_provided}.s3.amazonaws.com
```
### Konto-ID aus öffentlichem Bucket abrufen

Es ist möglich, eine AWS-Konto-ID zu bestimmen, indem man den neuen **`S3:ResourceAccount`** **Policy Condition Key** ausnutzt. Diese Bedingung **beschränkt den Zugriff basierend auf dem S3-Bucket**, in dem sich ein Konto befindet (andere kontobasierte Richtlinien beschränken den Zugriff basierend auf dem Konto, in dem sich der anfragende Principal befindet).\
Und da die Richtlinie **Wildcard-Zeichen** enthalten kann, ist es möglich, die Kontonummer **nur eine Ziffer nach der anderen** zu finden.

Dieses Tool automatisiert den Prozess:
```bash
# Installation
pipx install s3-account-search
pip install s3-account-search
# With a bucket
s3-account-search arn:aws:iam::123456789012:role/s3_read s3://my-bucket
# With an object
s3-account-search arn:aws:iam::123456789012:role/s3_read s3://my-bucket/path/to/object.ext
```
Diese Technik funktioniert auch mit API Gateway-URLs, Lambda-URLs, Data Exchange-Datensätzen und sogar um den Wert von Tags zu erhalten (wenn Sie den Tag-Schlüssel kennen). Weitere Informationen finden Sie in der [**originalen Forschung**](https://blog.plerion.com/conditional-love-for-aws-metadata-enumeration/) und dem Tool [**conditional-love**](https://github.com/plerionhq/conditional-love/), um diese Ausnutzung zu automatisieren.

### Bestätigen, dass ein Bucket zu einem AWS-Konto gehört

Wie in [**diesem Blogbeitrag**](https://blog.plerion.com/things-you-wish-you-didnt-need-to-know-about-s3/) erklärt, **wenn Sie Berechtigungen zum Auflisten eines Buckets haben**, ist es möglich, eine accountID zu bestätigen, zu der der Bucket gehört, indem Sie eine Anfrage wie folgt senden:
```bash
curl -X GET "[bucketname].amazonaws.com/" \
-H "x-amz-expected-bucket-owner: [correct-account-id]"

<?xml version="1.0" encoding="UTF-8"?>
<ListBucketResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/">...</ListBucketResult>
```
Wenn der Fehler "Zugriff verweigert" lautet, bedeutet das, dass die Kontonummer falsch war.

### Verwendete E-Mails zur Enumeration des Root-Kontos

Wie in [**diesem Blogbeitrag**](https://blog.plerion.com/things-you-wish-you-didnt-need-to-know-about-s3/) erklärt, ist es möglich zu überprüfen, ob eine E-Mail-Adresse mit einem AWS-Konto verbunden ist, indem man **versucht, einer E-Mail Berechtigungen** über einen S3-Bucket über ACLs zu gewähren. Wenn dies keinen Fehler auslöst, bedeutet das, dass die E-Mail ein Root-Benutzer eines AWS-Kontos ist:
```python
s3_client.put_bucket_acl(
Bucket=bucket_name,
AccessControlPolicy={
'Grants': [
{
'Grantee': {
'EmailAddress': 'some@emailtotest.com',
'Type': 'AmazonCustomerByEmail',
},
'Permission': 'READ'
},
],
'Owner': {
'DisplayName': 'Whatever',
'ID': 'c3d78ab5093a9ab8a5184de715d409c2ab5a0e2da66f08c2f6cc5c0bdeadbeef'
}
}
)
```
## Referenzen

- [https://www.youtube.com/watch?v=8ZXRw4Ry3mQ](https://www.youtube.com/watch?v=8ZXRw4Ry3mQ)
- [https://cloudar.be/awsblog/finding-the-account-id-of-any-public-s3-bucket/](https://cloudar.be/awsblog/finding-the-account-id-of-any-public-s3-bucket/)

{{#include ../../../banners/hacktricks-training.md}}
