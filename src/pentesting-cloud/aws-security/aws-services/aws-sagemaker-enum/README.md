# AWS - SageMaker Enum

{{#include ../../../../banners/hacktricks-training.md}}

## Service Overview

Amazon SageMaker ist AWS' verwaltete Machine-Learning-Plattform, die Notebooks, Trainings-Infrastruktur, Orchestrierung, Registries und verwaltete Endpoints zusammenführt. Eine Kompromittierung von SageMaker-Ressourcen ermöglicht typischerweise:

- Langfristige IAM-Ausführungsrollen mit weitreichendem Zugriff auf S3, ECR, Secrets Manager oder KMS.
- Zugriff auf sensible Datensätze, die in S3, EFS oder in Feature Stores gespeichert sind.
- Netzwerk-Footprints innerhalb von VPCs (Studio apps, training jobs, endpoints).
- Hochprivilegierte presigned URLs, die die Konsolen-Authentifizierung umgehen.

Das Verständnis, wie SageMaker aufgebaut ist, ist entscheidend, bevor Sie pivot, persist oder exfiltrate Daten.

## Core Building Blocks

- **Studio Domains & Spaces**: Web-IDE (JupyterLab, Code Editor, RStudio). Jede Domain hat ein gemeinsames EFS-Dateisystem und eine standardmäßige Ausführungsrolle.
- **Notebook Instances**: Verwaltete EC2-Instanzen für eigenständige Notebooks; verwenden separate Ausführungsrollen.
- **Training / Processing / Transform Jobs**: Ephemere Container, die Code aus ECR und Daten aus S3 ziehen.
- **Pipelines & Experiments**: Orchestrierte Workflows, die alle Schritte, Inputs und Outputs beschreiben.
- **Models & Endpoints**: Verpackte Artefakte, die für Inferenz über HTTPS-Endpunkte bereitgestellt werden.
- **Feature Store & Data Wrangler**: Verwaltete Services für Datenvorbereitung und Feature-Management.
- **Autopilot & JumpStart**: Automatisiertes ML und kuratierter Modellkatalog.
- **MLflow Tracking Servers**: Verwaltete MLflow UI/API mit presigned access tokens.

Jede Ressource referenziert eine Ausführungsrolle, S3-Standorte, Container-Images und optionale VPC-/KMS-Konfiguration — erfassen Sie alle während der Enumeration.

## Account & Global Metadata
```bash
REGION=us-east-1
# Portfolio status, used when provisioning Studio resources
aws sagemaker get-sagemaker-servicecatalog-portfolio-status --region $REGION

# List execution roles used by models (extend to other resources as needed)
aws sagemaker list-models --region $REGION --query 'Models[].ExecutionRoleArn' --output text | tr '	' '
' | sort -u

# Generic tag sweep across any SageMaker ARN you know
aws sagemaker list-tags --resource-arn <sagemaker-arn> --region $REGION
```
Notieren Sie jegliche Cross-Account-Trusts (execution roles oder S3 buckets mit external principals) und grundlegende Einschränkungen wie service control policies (SCPs).

## Studio Domains, Apps & Shared Spaces
```bash
aws sagemaker list-domains --region $REGION
aws sagemaker describe-domain --domain-id <domain-id> --region $REGION
aws sagemaker list-user-profiles --domain-id-equals <domain-id> --region $REGION
aws sagemaker describe-user-profile --domain-id <domain-id> --user-profile-name <profile> --region $REGION

# Enumerate apps (JupyterServer, KernelGateway, RStudioServerPro, CodeEditor, Canvas, etc.)
aws sagemaker list-apps --domain-id-equals <domain-id> --region $REGION
aws sagemaker describe-app --domain-id <domain-id> --user-profile-name <profile> --app-type JupyterServer --app-name default --region $REGION

# Shared collaborative spaces
aws sagemaker list-spaces --domain-id-equals <domain-id> --region $REGION
aws sagemaker describe-space --domain-id <domain-id> --space-name <space> --region $REGION

# Studio lifecycle configurations (shell scripts at start/stop)
aws sagemaker list-studio-lifecycle-configs --region $REGION
aws sagemaker describe-studio-lifecycle-config --studio-lifecycle-config-name <name> --region $REGION
```
Was zu protokollieren ist:

- `DomainArn`, `AppSecurityGroupIds`, `SubnetIds`, `DefaultUserSettings.ExecutionRole`.
- Gemountetes EFS (`HomeEfsFileSystemId`) und S3-Home-Verzeichnisse.
- Lifecycle-Skripte (enthalten oft Bootstrap-Zugangsdaten oder zusätzlichen Code zum Pushen/Pullen).

> [!TIP]
> Presigned Studio URLs können die Authentifizierung umgehen, wenn sie weitreichend gewährt werden.

## Notebook Instances & Lifecycle Configs
```bash
aws sagemaker list-notebook-instances --region $REGION
aws sagemaker describe-notebook-instance --notebook-instance-name <name> --region $REGION
aws sagemaker list-notebook-instance-lifecycle-configs --region $REGION
aws sagemaker describe-notebook-instance-lifecycle-config --notebook-instance-lifecycle-config-name <cfg> --region $REGION
```
Notebook-Metadaten geben Aufschluss über:

- Ausführungsrolle (`RoleArn`), direkter Internetzugang vs. nur VPC-Modus.
- S3-Standorte in `DefaultCodeRepository`, `DirectInternetAccess`, `RootAccess`.
- Lifecycle-Skripte für credentials oder persistence hooks.

## Training-, Processing-, Transform- und Batch-Jobs
```bash
aws sagemaker list-training-jobs --region $REGION
aws sagemaker describe-training-job --training-job-name <job> --region $REGION

aws sagemaker list-processing-jobs --region $REGION
aws sagemaker describe-processing-job --processing-job-name <job> --region $REGION

aws sagemaker list-transform-jobs --region $REGION
aws sagemaker describe-transform-job --transform-job-name <job> --region $REGION
```
Prüfen:

- `AlgorithmSpecification.TrainingImage` / `AppSpecification.ImageUri` – welche ECR-Images bereitgestellt werden.
- `InputDataConfig` & `OutputDataConfig` – S3-Buckets, Prefixes und KMS-Keys.
- `ResourceConfig.VolumeKmsKeyId`, `VpcConfig`, `EnableNetworkIsolation` – bestimmen Netzwerk- oder Verschlüsselungskonfiguration.
- `HyperParameters` können Umgebungsgeheimnisse oder Connection Strings leak.

## Pipelines, Experiments & Trials
```bash
aws sagemaker list-pipelines --region $REGION
aws sagemaker list-pipeline-executions --pipeline-name <pipeline> --region $REGION
aws sagemaker describe-pipeline --pipeline-name <pipeline> --region $REGION

aws sagemaker list-experiments --region $REGION
aws sagemaker list-trials --experiment-name <experiment> --region $REGION
aws sagemaker list-trial-components --trial-name <trial> --region $REGION
```
Pipeline-Definitionen beschreiben jeden Schritt, die zugehörigen Rollen, Container-Images und Umgebungsvariablen. Trial-Komponenten enthalten oft URIs von Trainingsartefakten, S3-Logs und Metriken, die auf sensible Datenflüsse hinweisen.

## Modelle, Endpoint-Konfigurationen & bereitgestellte Endpoints
```bash
aws sagemaker list-models --region $REGION
aws sagemaker describe-model --model-name <name> --region $REGION

aws sagemaker list-endpoint-configs --region $REGION
aws sagemaker describe-endpoint-config --endpoint-config-name <cfg> --region $REGION

aws sagemaker list-endpoints --region $REGION
aws sagemaker describe-endpoint --endpoint-name <endpoint> --region $REGION
```
Fokusbereiche:

- Modell-Artefakt S3-URIs (`PrimaryContainer.ModelDataUrl`) und Inference-Container-Images.
- Konfiguration der Endpoint Data Capture (S3 bucket, KMS) für mögliche log exfil.
- Multi-Model-Endpunkte, die `S3DataSource` oder `ModelPackage` verwenden (auf Cross-Account-Packaging prüfen).
- Netzwerk-Konfigurationen und Sicherheitsgruppen, die an Endpoints angehängt sind.

## Feature Store, Data Wrangler & Clarify
```bash
aws sagemaker list-feature-groups --region $REGION
aws sagemaker describe-feature-group --feature-group-name <feature-group> --region $REGION

aws sagemaker list-data-wrangler-flows --region $REGION
aws sagemaker describe-data-wrangler-flow --flow-name <flow> --region $REGION

aws sagemaker list-model-quality-job-definitions --region $REGION
aws sagemaker list-model-monitoring-schedule --region $REGION
```
Sicherheits-Hinweise:

- Online feature stores replizieren Daten in Kinesis; prüfen Sie `OnlineStoreConfig.SecurityConfig.KmsKeyId` und die VPC.
- Data Wrangler flows enthalten häufig JDBC/Redshift-Zugangsdaten oder private Endpunkte.
- Clarify/Model Monitor-Jobs exportieren Daten nach S3, die möglicherweise öffentlich lesbar oder kontoübergreifend zugänglich sind.

## MLflow Tracking Servers, Autopilot & JumpStart
```bash
aws sagemaker list-mlflow-tracking-servers --region $REGION
aws sagemaker describe-mlflow-tracking-server --tracking-server-name <name> --region $REGION

aws sagemaker list-auto-ml-jobs --region $REGION
aws sagemaker describe-auto-ml-job --auto-ml-job-name <name> --region $REGION

aws sagemaker list-jumpstart-models --region $REGION
aws sagemaker list-jumpstart-script-resources --region $REGION
```
- MLflow-Tracking-Server speichern Experimente und Artefakte; presigned URLs können alles offenlegen.
- Autopilot-Jobs starten mehrere training jobs — prüfe die Outputs auf versteckte Daten.
- JumpStart reference architectures können privilegierte Rollen im Account bereitstellen.

## IAM & Netzwerküberlegungen

- Liste die IAM-Policies auf, die an alle Ausführungsrollen angehängt sind (Studio, notebooks, training jobs, pipelines, endpoints).
- Prüfe Netzwerk-Kontexte: subnets, security groups, VPC endpoints. Viele Organisationen isolieren training jobs, vergessen aber, den ausgehenden Traffic zu beschränken.
- Überprüfe S3-Bucket-Policies, die in `ModelDataUrl`, `DataCaptureConfig`, `InputDataConfig` referenziert werden, auf externen Zugriff.

## Privilege Escalation

{{#ref}}
../../aws-privilege-escalation/aws-sagemaker-privesc/README.md
{{#endref}}

## Persistence

{{#ref}}
../../aws-persistence/aws-sagemaker-persistence/README.md
{{#endref}}

## Post-Exploitation

{{#ref}}
../../aws-post-exploitation/aws-sagemaker-post-exploitation/README.md
{{#endref}}

## Unauthorized Access

{{#ref}}
../../aws-sagemaker-unauthenticated-enum/README.md
{{#endref}}

## Referenzen

- [AWS SageMaker Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)
- [AWS CLI SageMaker Reference](https://docs.aws.amazon.com/cli/latest/reference/sagemaker/index.html)
- [SageMaker Studio Architecture](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio.html)
- [SageMaker Security Best Practices](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)

{{#include ../../../../banners/hacktricks-training.md}}
