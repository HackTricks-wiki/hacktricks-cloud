# AWS - SageMaker Enum

{{#include ../../../../banners/hacktricks-training.md}}

## Service-Übersicht

Amazon SageMaker ist AWS' verwaltete Machine-Learning-Plattform, die Notebooks, Trainingsinfrastruktur, Orchestrierung, Registries und verwaltete Endpunkte zusammenführt. Eine Kompromittierung von SageMaker-Ressourcen verschafft typischerweise:

- Langfristige IAM-Ausführungsrollen mit weitreichendem Zugriff auf S3, ECR, Secrets Manager oder KMS.
- Zugriff auf sensible Datensätze, die in S3, EFS oder in Feature Stores gespeichert sind.
- Netzwerk-Fußfeste innerhalb von VPCs (Studio apps, training jobs, endpoints).
- Hochprivilegierte presigned URLs, die die Console-Authentifizierung umgehen.

Zu verstehen, wie SageMaker aufgebaut ist, ist entscheidend, bevor Sie pivot, persist oder exfiltrate Daten.

## Core Building Blocks

- **Studio Domains & Spaces**: Web IDE (JupyterLab, Code Editor, RStudio). Jede Domain hat ein gemeinsames EFS-Dateisystem und eine standardmäßige Ausführungsrolle.
- **Notebook Instances**: Verwaltete EC2-Instanzen für eigenständige Notebooks; verwenden separate Ausführungsrollen.
- **Training / Processing / Transform Jobs**: Ephemere Container, die Code aus ECR und Daten aus S3 ziehen.
- **Pipelines & Experiments**: Orchestrierte Workflows, die alle Schritte, Inputs und Outputs beschreiben.
- **Models & Endpoints**: Verpackte Artefakte, die für Inference über HTTPS-Endpoints bereitgestellt werden.
- **Feature Store & Data Wrangler**: Verwaltete Services zur Datenaufbereitung und Feature-Verwaltung.
- **Autopilot & JumpStart**: Automatisiertes ML und kuratierter Modellkatalog.
- **MLflow Tracking Servers**: Verwaltetes MLflow UI/API mit presigned access tokens.

Jede Ressource referenziert eine Ausführungsrolle, S3-Standorte, Container-Images und optional VPC/KMS-Konfiguration—erfassen Sie alle während der enumeration.

## Konto- & globale Metadaten
```bash
REGION=us-east-1
# Portfolio status, used when provisioning Studio resources
aws sagemaker get-sagemaker-servicecatalog-portfolio-status --region $REGION

# List execution roles used by models (extend to other resources as needed)
aws sagemaker list-models --region $REGION --query 'Models[].ExecutionRoleArn' --output text | tr '	' '
' | sort -u

# Generic tag sweep across any SageMaker ARN you know
aws sagemaker list-tags --resource-arn <sagemaker-arn> --region $REGION
```
Notiere jegliche cross-account trust (execution roles oder S3 buckets mit external principals) und grundlegende Einschränkungen wie service control policies oder SCPs.

## Studio Domains, Apps & Shared Spaces
```bash
aws sagemaker list-domains --region $REGION
aws sagemaker describe-domain --domain-id <domain-id> --region $REGION
aws sagemaker list-user-profiles --domain-id-equals <domain-id> --region $REGION
aws sagemaker describe-user-profile --domain-id <domain-id> --user-profile-name <profile> --region $REGION

# Enumerate apps (JupyterServer, KernelGateway, RStudioServerPro, CodeEditor, Canvas, etc.)
aws sagemaker list-apps --domain-id-equals <domain-id> --region $REGION
aws sagemaker describe-app --domain-id <domain-id> --user-profile-name <profile> --app-type JupyterServer --app-name default --region $REGION

# Shared collaborative spaces
aws sagemaker list-spaces --domain-id-equals <domain-id> --region $REGION
aws sagemaker describe-space --domain-id <domain-id> --space-name <space> --region $REGION

# Studio lifecycle configurations (shell scripts at start/stop)
aws sagemaker list-studio-lifecycle-configs --region $REGION
aws sagemaker describe-studio-lifecycle-config --studio-lifecycle-config-name <name> --region $REGION
```
Was zu erfassen:

- `DomainArn`, `AppSecurityGroupIds`, `SubnetIds`, `DefaultUserSettings.ExecutionRole`.
- Eingehängte EFS (`HomeEfsFileSystemId`) und S3-Home-Verzeichnisse.
- Lifecycle-Skripte (enthalten oft Bootstrap-Anmeldeinformationen oder zusätzlichen Push-/Pull-Code).

> [!TIP]
> Vorgesignierte Studio-URLs können die Authentifizierung umgehen, wenn sie breit vergeben werden.

## Notebook-Instanzen & Lifecycle-Konfigurationen
```bash
aws sagemaker list-notebook-instances --region $REGION
aws sagemaker describe-notebook-instance --notebook-instance-name <name> --region $REGION
aws sagemaker list-notebook-instance-lifecycle-configs --region $REGION
aws sagemaker describe-notebook-instance-lifecycle-config --notebook-instance-lifecycle-config-name <cfg> --region $REGION
```
Notebook-Metadaten offenbaren:

- Ausführungsrolle (`RoleArn`), direkter Internetzugang vs. nur VPC-Modus.
- S3-Standorte in `DefaultCodeRepository`, `DirectInternetAccess`, `RootAccess`.
- Lifecycle-Skripte für credentials oder persistence hooks.

## Training-, Processing-, Transform- und Batch-Jobs
```bash
aws sagemaker list-training-jobs --region $REGION
aws sagemaker describe-training-job --training-job-name <job> --region $REGION

aws sagemaker list-processing-jobs --region $REGION
aws sagemaker describe-processing-job --processing-job-name <job> --region $REGION

aws sagemaker list-transform-jobs --region $REGION
aws sagemaker describe-transform-job --transform-job-name <job> --region $REGION
```
Prüfen:

- `AlgorithmSpecification.TrainingImage` / `AppSpecification.ImageUri` – welche ECR-Images bereitgestellt werden.
- `InputDataConfig` & `OutputDataConfig` – S3-Buckets, Prefixes und KMS-Schlüssel.
- `ResourceConfig.VolumeKmsKeyId`, `VpcConfig`, `EnableNetworkIsolation` – bestimmen die Netzwerk- oder Verschlüsselungs-Konfiguration.
- `HyperParameters` können Umgebungsgeheimnisse oder Connection-Strings leak.

## Pipelines, Experimente & Trials
```bash
aws sagemaker list-pipelines --region $REGION
aws sagemaker list-pipeline-executions --pipeline-name <pipeline> --region $REGION
aws sagemaker describe-pipeline --pipeline-name <pipeline> --region $REGION

aws sagemaker list-experiments --region $REGION
aws sagemaker list-trials --experiment-name <experiment> --region $REGION
aws sagemaker list-trial-components --trial-name <trial> --region $REGION
```
Pipeline-Definitionen beschreiben jeden Schritt, zugeordnete Rollen, Container-Images und Umgebungsvariablen. Trial-Komponenten enthalten häufig Trainings-Artefakt-URIs, S3-Logs und Metriken, die auf sensible Datenflüsse hinweisen.

## Modelle, Endpoint-Konfigurationen & bereitgestellte Endpoints
```bash
aws sagemaker list-models --region $REGION
aws sagemaker describe-model --model-name <name> --region $REGION

aws sagemaker list-endpoint-configs --region $REGION
aws sagemaker describe-endpoint-config --endpoint-config-name <cfg> --region $REGION

aws sagemaker list-endpoints --region $REGION
aws sagemaker describe-endpoint --endpoint-name <endpoint> --region $REGION
```
Fokusbereiche:

- S3-URIs der Model-Artefakte (`PrimaryContainer.ModelDataUrl`) und Inference-Container-Images.
- Konfiguration von Endpoint Data Capture (S3 bucket, KMS) für mögliche Log exfil.
- Multi-model Endpoints, die `S3DataSource` oder `ModelPackage` verwenden (auf cross-account packaging prüfen).
- Netzwerkkonfigurationen und security groups, die an Endpoints angehängt sind.

## Feature Store, Data Wrangler & Clarify
```bash
aws sagemaker list-feature-groups --region $REGION
aws sagemaker describe-feature-group --feature-group-name <feature-group> --region $REGION

aws sagemaker list-data-wrangler-flows --region $REGION
aws sagemaker describe-data-wrangler-flow --flow-name <flow> --region $REGION

aws sagemaker list-model-quality-job-definitions --region $REGION
aws sagemaker list-model-monitoring-schedule --region $REGION
```
Sicherheits-Hinweise:

- Online feature stores replizieren Daten zu Kinesis; überprüfe `OnlineStoreConfig.SecurityConfig.KmsKeyId` und VPC.
- Data Wrangler flows enthalten häufig eingebettete JDBC/Redshift-Zugangsdaten oder private Endpunkte.
- Clarify/Model Monitor jobs exportieren Daten nach S3, die möglicherweise weltweit lesbar oder kontenübergreifend zugänglich sind.

## MLflow Tracking Servers, Autopilot & JumpStart
```bash
aws sagemaker list-mlflow-tracking-servers --region $REGION
aws sagemaker describe-mlflow-tracking-server --tracking-server-name <name> --region $REGION

aws sagemaker list-auto-ml-jobs --region $REGION
aws sagemaker describe-auto-ml-job --auto-ml-job-name <name> --region $REGION

aws sagemaker list-jumpstart-models --region $REGION
aws sagemaker list-jumpstart-script-resources --region $REGION
```
- MLflow tracking servers speichern Experimente und Artefakte; presigned URLs können alles exponieren.
- Autopilot jobs starten mehrere training jobs — enumeriere Outputs nach versteckten Daten.
- JumpStart reference architectures können privilegierte Rollen im Konto bereitstellen.

## IAM & Netzwerküberlegungen

- Ermittle IAM-Policies, die an alle Ausführungsrollen angehängt sind (Studio, notebooks, training jobs, pipelines, endpoints).
- Überprüfe Netzwerkkontexte: subnets, security groups, VPC endpoints. Viele Organisationen isolieren training jobs, vergessen jedoch, ausgehenden Traffic zu beschränken.
- Überprüfe S3-Bucket-Policies, die in `ModelDataUrl`, `DataCaptureConfig`, `InputDataConfig` referenziert werden, auf externen Zugriff.

## Privilege Escalation

{{#ref}}
../../aws-privilege-escalation/aws-sagemaker-privesc/README.md
{{#endref}}

## Persistence

{{#ref}}
../../aws-persistence/aws-sagemaker-persistence/README.md
{{#endref}}

## Post-Exploitation

{{#ref}}
../../aws-post-exploitation/aws-sagemaker-post-exploitation/README.md
{{#endref}}

## Unauthorized Access

{{#ref}}
../aws-sagemaker-unauthorized-access/README.md
{{#endref}}

## Referenzen

- [AWS SageMaker Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)
- [AWS CLI SageMaker Reference](https://docs.aws.amazon.com/cli/latest/reference/sagemaker/index.html)
- [SageMaker Studio Architecture](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio.html)
- [SageMaker Security Best Practices](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)

{{#include ../../../../banners/hacktricks-training.md}}
