# AWS - S3, Athena & Glacier Enumeración

{{#include ../../../banners/hacktricks-training.md}}

## S3

Amazon S3 es un servicio que te permite **almacenar grandes cantidades de datos**.

Amazon S3 ofrece múltiples opciones para lograr la **protección** de los datos en reposo. Las opciones incluyen **Permisos** (Policy), **Cifrado** (Cliente y Lado del Servidor), **Versionado de bucket** y **borrado basado en MFA**. El **usuario puede habilitar** cualquiera de estas opciones para lograr la protección de datos. **Replicación de datos** es una funcionalidad interna de AWS donde **S3 replica automáticamente cada objeto a través de todas las Availability Zones** y la organización no necesita habilitarla en este caso.

Con permisos basados en recursos, puedes definir permisos para subdirectorios de tu bucket por separado.

### Versionado de bucket y borrado basado en MFA

Cuando el versionado del bucket está habilitado, cualquier acción que intente alterar un archivo generará una nueva versión del archivo, conservando también el contenido anterior. Por lo tanto, no sobrescribirá su contenido.

Además, el borrado basado en MFA evitará que las versiones de archivos en el bucket S3 sean eliminadas y que el Bucket Versioning sea deshabilitado, por lo que un atacante no podrá alterar estos archivos.

### S3 Access logs

Es posible **habilitar el registro de acceso de S3** (que por defecto está deshabilitado) en un bucket y guardar los logs en un bucket diferente para saber quién está accediendo al bucket (ambos buckets deben estar en la misma región).

### S3 Presigned URLs

Es posible generar una presigned URL que generalmente puede usarse para **acceder al archivo especificado** en el bucket. Una **presigned URL se ve así**:
```
https://<bucket-name>.s3.us-east-1.amazonaws.com/asd.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAUUE8GZC4S5L3TY3P%2F20230227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230227T142551Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBhQpdETJO3HKKDk2hjNIrPWwBE8gZaQccZFV3kCpPCWAiEAid3ueDtFFU%2FOQfUpvxYTGO%2BHoS4SWDMUrQAE0pIaB40qggMIYBAAGgwzMTgxNDIxMzg1NTMiDJLI5t7gr2EGxG1Y5CrfAioW0foHIQ074y4gvk0c%2B%2Fmqc7cNWb1njQslQkeePHkseJ3owzc%2FCwkgE0EuZTd4mw0aJciA2XIbJRCLPWTb%2FCBKPnIMJ5aBzIiA2ltsiUNQTTUxYmEgXZoJ6rFYgcodnmWW0Et4Xw59UlHnCDB2bLImxPprriyCzDDCD6nLyp3J8pFF1S8h3ZTJE7XguA8joMs4%2B2B1%2FeOZfuxXKyXPYSKQOOSbQiHUQc%2BFnOfwxleRL16prWk1t7TamvHR%2Bt3UgMn5QWzB3p8FgWwpJ6GjHLkYMJZ379tkimL1tJ7o%2BIod%2FMYrS7LDCifP9d%2FuYOhKWGhaakPuJKJh9fl%2B0vGl7kmApXigROxEWon6ms75laXebltsWwKcKuYca%2BUWu4jVJx%2BWUfI4ofoaGiCSaKALTqwu4QNBRT%2BMoK6h%2BQa7gN7JFGg322lkxRY53x27WMbUE4unn5EmI54T4dWt1%2Bg8ljDS%2BvKfBjqmAWRwuqyfwXa5YC3xxttOr3YVvR6%2BaXpzWtvNJQNnb6v0uI3%2BTtTexZkJpLQYqFcgZLQSxsXWSnf988qvASCIUhAzp2UnS1uqy7QjtD5T73zksYN2aesll7rvB80qIuujG6NOdHnRJ2M5%2FKXXNo1Yd15MtzPuSjRoSB9RSMon5jFu31OrQnA9eCUoawxbB0nHqwK8a43CKBZHhA8RoUAJW%2B48EuFsp3U%3D&X-Amz-Signature=3436e4139e84dbcf5e2e6086c0ebc92f4e1e9332b6fda24697bc339acbf2cdfa
```
Una presigned URL puede ser **creada desde el cli usando las credenciales de un principal con acceso al objeto** (si la cuenta que usas no tiene acceso, se creará una presigned URL más corta pero será inútil)
```bash
aws s3 presign --region <bucket-region> 's3://<bucket-name>/<file-name>'
```
> [!NOTE]
> El único permiso requerido para generar una presigned URL es el permiso que se está otorgando, así que para el comando anterior el único permiso necesario por el principal es `s3:GetObject`

También es posible crear presigned URLs con **otros permisos**:
```python
import boto3
url = boto3.client('s3').generate_presigned_url(
ClientMethod='put_object',
Params={'Bucket': 'BUCKET_NAME', 'Key': 'OBJECT_KEY'},
ExpiresIn=3600
)
```
### Mecanismos de cifrado de S3

**DEK significa Data Encryption Key (clave de cifrado de datos)** y es la clave que siempre se genera y se usa para cifrar los datos.

<details>

<summary><strong>Cifrado del lado del servidor con claves gestionadas por S3, SSE-S3</strong></summary>

Esta opción requiere una configuración mínima y todo el manejo de las claves de cifrado es gestionado por AWS. Todo lo que necesitas hacer es **subir tus datos y S3 se encargará de todos los demás aspectos**. A cada bucket en una cuenta S3 se le asigna una bucket key.

- Cifrado:
- Object Data + DEK en texto en claro creado --> Datos cifrados (almacenados dentro de S3)
- DEK en texto en claro creado + S3 Master Key --> DEK cifrado (almacenado dentro de S3) y el texto en claro se elimina de la memoria
- Descifrado:
- DEK cifrado + S3 Master Key --> DEK en texto en claro
- DEK en texto en claro + datos cifrados --> Object Data

Por favor, ten en cuenta que en este caso **la clave es gestionada por AWS** (rotación solo cada 3 años). Si usas tu propia clave podrás rotarla, deshabilitarla y aplicar control de acceso.

</details>

<details>

<summary><strong>Cifrado del lado del servidor con claves gestionadas por KMS, SSE-KMS</strong></summary>

Este método permite que S3 utilice el servicio de gestión de claves para generar tus data encryption keys. KMS te ofrece mucha más flexibilidad sobre cómo se gestionan tus claves. Por ejemplo, puedes deshabilitar, rotar y aplicar controles de acceso al CMK, y auditar su uso mediante AWS Cloud Trail.

- Cifrado:
- S3 solicita claves de datos a KMS CMK
- KMS usa una CMK para generar el par DEK en texto en claro y DEK cifrado y los envía a S£
- S3 usa la clave en texto en claro para cifrar los datos, almacena los datos cifrados y la clave cifrada y elimina de la memoria la clave en texto en claro
- Descifrado:
- S3 solicita a KMS que descifre la data key cifrada del objeto
- KMS descifra la data key con la CMK y la envía de vuelta a S3
- S3 descifra los datos del objeto

</details>

<details>

<summary><strong>Cifrado del lado del servidor con claves proporcionadas por el cliente, SSE-C</strong></summary>

Esta opción te da la posibilidad de proporcionar tu propia clave maestra que quizá ya uses fuera de AWS. Tu clave proporcionada por el cliente se enviaría junto con tus datos a S3, donde S3 realizaría el cifrado por ti.

- Cifrado:
- El usuario envía los datos del objeto + clave del cliente a S3
- La clave del cliente se usa para cifrar los datos y se almacenan los datos cifrados
- también se almacena un valor HMAC salado de la clave del cliente para validación futura de la clave
- la clave del cliente se elimina de la memoria
- Descifrado:
- El usuario envía la clave del cliente
- La clave se valida contra el valor HMAC almacenado
- La clave proporcionada por el cliente se usa entonces para descifrar los datos

</details>

<details>

<summary><strong>Cifrado del lado del cliente con KMS, CSE-KMS</strong></summary>

De manera similar a SSE-KMS, esto también utiliza el servicio de gestión de claves para generar tus data encryption keys. Sin embargo, esta vez KMS es llamado por el cliente y no por S3. El cifrado se realiza del lado del cliente y los datos cifrados se envían a S3 para su almacenamiento.

- Cifrado:
- El cliente solicita una data key a KMS
- KMS devuelve el DEK en texto en claro y el DEK cifrado con la CMK
- Ambas claves son devueltas
- El cliente cifra los datos con el DEK en texto en claro y envía a S3 los datos cifrados + el DEK cifrado (que se guarda como metadata de los datos cifrados dentro de S3)
- Descifrado:
- Los datos cifrados con el DEK cifrado son enviados al cliente
- El cliente pide a KMS que descifre la clave cifrada usando la CMK y KMS devuelve el DEK en texto en claro
- El cliente ahora puede descifrar los datos cifrados

</details>

<details>

<summary><strong>Cifrado del lado del cliente con claves proporcionadas por el cliente, CSE-C</strong></summary>

Usando este mecanismo, puedes utilizar tus propias claves proporcionadas y usar un cliente AWS-SDK para cifrar tus datos antes de enviarlos a S3 para su almacenamiento.

- Cifrado:
- El cliente genera un DEK y cifra los datos en texto en claro
- Luego, usando su propio CMK personalizado, cifra el DEK
- envía los datos cifrados + DEK cifrado a S3 donde se almacenan
- Descifrado:
- S3 envía los datos cifrados y el DEK
- Como el cliente ya tiene la CMK usada para cifrar el DEK, descifra el DEK y luego usa el DEK en texto en claro para descifrar los datos

</details>

### **Enumeración**

Una de las formas tradicionales principales de comprometer organizaciones de AWS comienza por comprometer buckets accesibles públicamente. **You can find** [**public buckets enumerators in this page**](../aws-unauthenticated-enum-access/index.html#s3-buckets)**.**
```bash
# Get buckets ACLs
aws s3api get-bucket-acl --bucket <bucket-name>
aws s3api get-object-acl --bucket <bucket-name> --key flag

# Get policy
aws s3api get-bucket-policy --bucket <bucket-name>
aws s3api get-bucket-policy-status --bucket <bucket-name> #if it's public

# list S3 buckets associated with a profile
aws s3 ls
aws s3api list-buckets

# list content of bucket (no creds)
aws s3 ls s3://bucket-name --no-sign-request
aws s3 ls s3://bucket-name --recursive

# list content of bucket (with creds)
aws s3 ls s3://bucket-name
aws s3api list-objects-v2 --bucket <bucket-name>
aws s3api list-objects --bucket <bucket-name>
aws s3api list-object-versions --bucket <bucket-name>

# copy local folder to S3
aws s3 cp MyFolder s3://bucket-name --recursive

# delete
aws s3 rb s3://bucket-name –-force

# download a whole S3 bucket
aws s3 sync s3://<bucket>/ .

# move S3 bucket to different location
aws s3 sync s3://oldbucket s3://newbucket --source-region us-west-1

# list the sizes of an S3 bucket and its contents
aws s3api list-objects --bucket BUCKETNAME --output json --query "[sum(Contents[].Size), length(Contents[])]"

# Update Bucket policy
aws s3api put-bucket-policy --policy file:///root/policy.json --bucket <bucket-name>
##JSON policy example
{
"Id": "Policy1568185116930",
"Version": "2012-10-17",
"Statement": [
{
"Sid": "Stmt1568184932403",
"Action": [
"s3:ListBucket"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome",
"Principal": "*"
},
{
"Sid": "Stmt1568185007451",
"Action": [
"s3:GetObject"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome/*",
"Principal": "*"
}
]
}

# Update bucket ACL
aws s3api get-bucket-acl --bucket <bucket-name> # Way 1 to get the ACL
aws s3api put-bucket-acl --bucket <bucket-name> --access-control-policy file://acl.json

aws s3api get-object-acl --bucket <bucket-name> --key flag #Way 2 to get the ACL
aws s3api put-object-acl --bucket <bucket-name> --key flag --access-control-policy file://objacl.json

##JSON ACL example
## Make sure to modify the Owner’s displayName and ID according to the Object ACL you retrieved.
{
"Owner": {
"DisplayName": "<DisplayName>",
"ID": "<ID>"
},
"Grants": [
{
"Grantee": {
"Type": "Group",
"URI": "http://acs.amazonaws.com/groups/global/AuthenticatedUsers"
},
"Permission": "FULL_CONTROL"
}
]
}
## An ACL should give you the permission WRITE_ACP to be able to put a new ACL
```
### dual-stack <a href="#dual-stack-endpoints-description" id="dual-stack-endpoints-description"></a>

Puedes acceder a un bucket S3 a través de un endpoint dual-stack usando un nombre de endpoint en virtual hosted-style o path-style. Estos son útiles para acceder a S3 mediante IPv6.

Dual-stack endpoints usan la siguiente sintaxis:

- `bucketname.s3.dualstack.aws-region.amazonaws.com`
- `s3.dualstack.aws-region.amazonaws.com/bucketname`

### Privesc

En la siguiente página puedes ver cómo **abuse S3 permissions to escalate privileges**:

{{#ref}}
../aws-privilege-escalation/aws-s3-privesc/README.md
{{#endref}}

### Unauthenticated Access

{{#ref}}
../aws-unauthenticated-enum-access/aws-s3-unauthenticated-enum/README.md
{{#endref}}

### S3 Post Exploitation

{{#ref}}
../aws-post-exploitation/aws-s3-post-exploitation/README.md
{{#endref}}

### Persistence

{{#ref}}
../aws-persistence/aws-s3-persistence/README.md
{{#endref}}

## Other S3 vulns

### S3 HTTP Cache Poisoning Issue <a href="#heading-s3-http-desync-cache-poisoning-issue" id="heading-s3-http-desync-cache-poisoning-issue"></a>

[**Según esta investigación**](https://rafa.hashnode.dev/exploiting-http-parsers-inconsistencies#heading-s3-http-desync-cache-poisoning-issue) era posible cachear la respuesta de un bucket arbitrario como si perteneciera a otro distinto. Esto podría haberse abusado para modificar, por ejemplo, las respuestas de archivos JavaScript y comprometer páginas arbitrarias que usan S3 para almacenar código estático.

## Amazon Athena

Amazon Athena es un servicio interactivo de consultas que facilita **analizar datos** directamente en Amazon Simple Storage Service (Amazon **S3**) **usando** **SQL** estándar.

Necesitas **preparar una tabla relacional** con el formato del contenido que va a aparecer en los buckets S3 monitorizados. Y entonces, Amazon Athena podrá poblar la BD desde los logs, de modo que puedas consultarla.

Amazon Athena soporta la **capacidad de consultar datos en S3 que ya están cifrados** y, si está configurado para ello, **Athena también puede cifrar los resultados de la consulta que luego pueden almacenarse en S3**.

**Este cifrado de resultados es independiente de los datos subyacentes de S3 consultados**, lo que significa que incluso si los datos S3 no están cifrados, los resultados de la consulta pueden cifrarse. Un par de puntos a tener en cuenta son que Amazon Athena solo soporta datos que han sido **cifrados** con los **siguientes métodos de cifrado de S3**, **SSE-S3, SSE-KMS, y CSE-KMS**.

SSE-C y CSE-C no son compatibles. Además, es importante entender que Amazon Athena solo ejecutará consultas contra **objetos cifrados que estén en la misma región que la propia consulta**. Si necesitas consultar datos S3 que han sido cifrados usando KMS, entonces se requieren permisos específicos por parte del usuario de Athena para permitirles realizar la consulta.

### Enumeration
```bash
# Get catalogs
aws athena list-data-catalogs

# Get databases inside catalog
aws athena list-databases --catalog-name <catalog-name>
aws athena list-table-metadata --catalog-name <catalog-name> --database-name <db-name>

# Get query executions, queries and results
aws athena list-query-executions
aws athena get-query-execution --query-execution-id <id> # Get query and meta of results
aws athena get-query-results --query-execution-id <id> # This will rerun the query and get the results

# Get workgroups & Prepared statements
aws athena list-work-groups
aws athena list-prepared-statements --work-group <wg-name>
aws athena get-prepared-statement --statement-name <name> --work-group <wg-name>

# Run query
aws athena start-query-execution --query-string <query>
```
## Referencias

- [https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3](https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3)
- [https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)

{{#include ../../../banners/hacktricks-training.md}}
