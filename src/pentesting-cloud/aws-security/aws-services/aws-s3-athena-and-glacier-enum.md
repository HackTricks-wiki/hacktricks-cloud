# AWS - S3, Athena y Glacier Enum

{{#include ../../../banners/hacktricks-training.md}}

## S3

Amazon S3 es un servicio que permite **almacenar grandes cantidades de datos**.

Amazon S3 proporciona múltiples opciones para lograr la **protección** de datos en reposo. Las opciones incluyen **Permisos** (Política), **Cifrado** (Lado del Cliente y del Servidor), **Versionado de Bucket** y **eliminación basada en MFA**. El **usuario puede habilitar** cualquiera de estas opciones para lograr la protección de datos. **La replicación de datos** es una función interna de AWS donde **S3 replica automáticamente cada objeto en todas las Zonas de Disponibilidad** y la organización no necesita habilitarla en este caso.

Con permisos basados en recursos, puedes definir permisos para subdirectorios de tu bucket por separado.

### Versionado de Bucket y eliminación basada en MFA

Cuando el versionado de bucket está habilitado, cualquier acción que intente alterar un archivo dentro de un archivo generará una nueva versión del archivo, manteniendo también el contenido anterior del mismo. Por lo tanto, no sobrescribirá su contenido.

Además, la eliminación basada en MFA evitará que las versiones de archivo en el bucket S3 sean eliminadas y también que el versionado de bucket sea deshabilitado, por lo que un atacante no podrá alterar estos archivos.

### Registros de acceso a S3

Es posible **habilitar el registro de acceso a S3** (que por defecto está deshabilitado) para algún bucket y guardar los registros en un bucket diferente para saber quién está accediendo al bucket (ambos buckets deben estar en la misma región).

### URLs Presignadas de S3

Es posible generar una URL presignada que generalmente se puede usar para **acceder al archivo especificado** en el bucket. Una **URL presignada se ve así**:
```
https://<bucket-name>.s3.us-east-1.amazonaws.com/asd.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAUUE8GZC4S5L3TY3P%2F20230227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230227T142551Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBhQpdETJO3HKKDk2hjNIrPWwBE8gZaQccZFV3kCpPCWAiEAid3ueDtFFU%2FOQfUpvxYTGO%2BHoS4SWDMUrQAE0pIaB40qggMIYBAAGgwzMTgxNDIxMzg1NTMiDJLI5t7gr2EGxG1Y5CrfAioW0foHIQ074y4gvk0c%2B%2Fmqc7cNWb1njQslQkeePHkseJ3owzc%2FCwkgE0EuZTd4mw0aJciA2XIbJRCLPWTb%2FCBKPnIMJ5aBzIiA2ltsiUNQTTUxYmEgXZoJ6rFYgcodnmWW0Et4Xw59UlHnCDB2bLImxPprriyCzDDCD6nLyp3J8pFF1S8h3ZTJE7XguA8joMs4%2B2B1%2FeOZfuxXKyXPYSKQOOSbQiHUQc%2BFnOfwxleRL16prWk1t7TamvHR%2Bt3UgMn5QWzB3p8FgWwpJ6GjHLkYMJZ379tkimL1tJ7o%2BIod%2FMYrS7LDCifP9d%2FuYOhKWGhaakPuJKJh9fl%2B0vGl7kmApXigROxEWon6ms75laXebltsWwKcKuYca%2BUWu4jVJx%2BWUfI4ofoaGiCSaKALTqwu4QNBRT%2BMoK6h%2BQa7gN7JFGg322lkxRY53x27WMbUE4unn5EmI54T4dWt1%2Bg8ljDS%2BvKfBjqmAWRwuqyfwXa5YC3xxttOr3YVvR6%2BaXpzWtvNJQNnb6v0uI3%2BTtTexZkJpLQYqFcgZLQSxsXWSnf988qvASCIUhAzp2UnS1uqy7QjtD5T73zksYN2aesll7rvB80qIuujG6NOdHnRJ2M5%2FKXXNo1Yd15MtzPuSjRoSB9RSMon5jFu31OrQnA9eCUoawxbB0nHqwK8a43CKBZHhA8RoUAJW%2B48EuFsp3U%3D&X-Amz-Signature=3436e4139e84dbcf5e2e6086c0ebc92f4e1e9332b6fda24697bc339acbf2cdfa
```
Una URL prefirmada puede ser **creada desde la cli utilizando credenciales de un principal con acceso al objeto** (si la cuenta que usas no tiene acceso, se creará una URL prefirmada más corta pero será inútil)
```bash
aws s3 presign --region <bucket-region> 's3://<bucket-name>/<file-name>'
```
> [!NOTE]
> El único permiso requerido para generar una URL firmada es el permiso que se está otorgando, por lo que para el comando anterior el único permiso que necesita el principal es `s3:GetObject`

También es posible crear URLs firmadas con **otros permisos**:
```python
import boto3
url = boto3.client('s3').generate_presigned_url(
ClientMethod='put_object',
Params={'Bucket': 'BUCKET_NAME', 'Key': 'OBJECT_KEY'},
ExpiresIn=3600
)
```
### Mecanismos de Cifrado S3

**DEK significa Clave de Cifrado de Datos** y es la clave que siempre se genera y se utiliza para cifrar datos.

<details>

<summary><strong>Cifrado del lado del servidor con claves gestionadas por S3, SSE-S3</strong></summary>

Esta opción requiere una configuración mínima y toda la gestión de las claves de cifrado utilizadas es gestionada por AWS. Todo lo que necesitas hacer es **subir tus datos y S3 se encargará de todos los demás aspectos**. A cada bucket en una cuenta de S3 se le asigna una clave de bucket.

- Cifrado:
- Datos del objeto + DEK en texto plano creado --> Datos cifrados (almacenados dentro de S3)
- DEK en texto plano creado + Clave Maestra de S3 --> DEK cifrado (almacenado dentro de S3) y el texto plano se elimina de la memoria
- Descifrado:
- DEK cifrado + Clave Maestra de S3 --> DEK en texto plano
- DEK en texto plano + Datos cifrados --> Datos del objeto

Por favor, ten en cuenta que en este caso **la clave es gestionada por AWS** (rotación solo cada 3 años). Si usas tu propia clave, podrás rotar, desactivar y aplicar control de acceso.

</details>

<details>

<summary><strong>Cifrado del lado del servidor con claves gestionadas por KMS, SSE-KMS</strong></summary>

Este método permite a S3 utilizar el servicio de gestión de claves para generar tus claves de cifrado de datos. KMS te ofrece una flexibilidad mucho mayor en cómo se gestionan tus claves. Por ejemplo, puedes desactivar, rotar y aplicar controles de acceso a la CMK, y ordenar en contra de su uso utilizando AWS Cloud Trail.

- Cifrado:
- S3 solicita claves de datos a KMS CMK
- KMS utiliza una CMK para generar el par DEK en texto plano y DEK cifrado y los envía a S3
- S3 utiliza la clave en texto plano para cifrar los datos, almacena los datos cifrados y la clave cifrada y elimina de la memoria la clave en texto plano
- Descifrado:
- S3 solicita a KMS que descifre la clave de datos cifrada del objeto
- KMS descifra la clave de datos con la CMK y la envía de vuelta a S3
- S3 descifra los datos del objeto

</details>

<details>

<summary><strong>Cifrado del lado del servidor con claves proporcionadas por el cliente, SSE-C</strong></summary>

Esta opción te da la oportunidad de proporcionar tu propia clave maestra que ya puedes estar utilizando fuera de AWS. Tu clave proporcionada por el cliente se enviaría con tus datos a S3, donde S3 realizaría el cifrado por ti.

- Cifrado:
- El usuario envía los datos del objeto + Clave del cliente a S3
- La clave del cliente se utiliza para cifrar los datos y los datos cifrados se almacenan
- también se almacena un valor HMAC salado de la clave del cliente para futuras validaciones de clave
- la clave del cliente se elimina de la memoria
- Descifrado:
- El usuario envía la clave del cliente
- La clave se valida contra el valor HMAC almacenado
- La clave proporcionada por el cliente se utiliza para descifrar los datos

</details>

<details>

<summary><strong>Cifrado del lado del cliente con KMS, CSE-KMS</strong></summary>

De manera similar a SSE-KMS, este también utiliza el servicio de gestión de claves para generar tus claves de cifrado de datos. Sin embargo, esta vez KMS se invoca a través del cliente, no de S3. El cifrado se realiza del lado del cliente y los datos cifrados se envían a S3 para ser almacenados.

- Cifrado:
- El cliente solicita una clave de datos a KMS
- KMS devuelve el DEK en texto plano y el DEK cifrado con la CMK
- Ambas claves se envían de vuelta
- El cliente luego cifra los datos con el DEK en texto plano y envía a S3 los datos cifrados + el DEK cifrado (que se guarda como metadatos de los datos cifrados dentro de S3)
- Descifrado:
- Los datos cifrados con el DEK cifrado se envían al cliente
- El cliente solicita a KMS que descifre la clave cifrada utilizando la CMK y KMS envía de vuelta el DEK en texto plano
- El cliente ahora puede descifrar los datos cifrados

</details>

<details>

<summary><strong>Cifrado del lado del cliente con claves proporcionadas por el cliente, CSE-C</strong></summary>

Usando este mecanismo, puedes utilizar tus propias claves proporcionadas y usar un cliente AWS-SDK para cifrar tus datos antes de enviarlos a S3 para su almacenamiento.

- Cifrado:
- El cliente genera un DEK y cifra los datos en texto plano
- Luego, utilizando su propia CMK personalizada, cifra el DEK
- envía los datos cifrados + DEK cifrado a S3 donde se almacenan
- Descifrado:
- S3 envía los datos cifrados y el DEK
- Como el cliente ya tiene la CMK utilizada para cifrar el DEK, descifra el DEK y luego utiliza el DEK en texto plano para descifrar los datos

</details>

### **Enumeración**

Una de las principales formas tradicionales de comprometer organizaciones de AWS comienza por comprometer buckets accesibles públicamente. **Puedes encontrar** [**enumeradores de buckets públicos en esta página**](../aws-unauthenticated-enum-access/#s3-buckets)**.**
```bash
# Get buckets ACLs
aws s3api get-bucket-acl --bucket <bucket-name>
aws s3api get-object-acl --bucket <bucket-name> --key flag

# Get policy
aws s3api get-bucket-policy --bucket <bucket-name>
aws s3api get-bucket-policy-status --bucket <bucket-name> #if it's public

# list S3 buckets associated with a profile
aws s3 ls
aws s3api list-buckets

# list content of bucket (no creds)
aws s3 ls s3://bucket-name --no-sign-request
aws s3 ls s3://bucket-name --recursive

# list content of bucket (with creds)
aws s3 ls s3://bucket-name
aws s3api list-objects-v2 --bucket <bucket-name>
aws s3api list-objects --bucket <bucket-name>
aws s3api list-object-versions --bucket <bucket-name>

# copy local folder to S3
aws s3 cp MyFolder s3://bucket-name --recursive

# delete
aws s3 rb s3://bucket-name –-force

# download a whole S3 bucket
aws s3 sync s3://<bucket>/ .

# move S3 bucket to different location
aws s3 sync s3://oldbucket s3://newbucket --source-region us-west-1

# list the sizes of an S3 bucket and its contents
aws s3api list-objects --bucket BUCKETNAME --output json --query "[sum(Contents[].Size), length(Contents[])]"

# Update Bucket policy
aws s3api put-bucket-policy --policy file:///root/policy.json --bucket <bucket-name>
##JSON policy example
{
"Id": "Policy1568185116930",
"Version": "2012-10-17",
"Statement": [
{
"Sid": "Stmt1568184932403",
"Action": [
"s3:ListBucket"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome",
"Principal": "*"
},
{
"Sid": "Stmt1568185007451",
"Action": [
"s3:GetObject"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome/*",
"Principal": "*"
}
]
}

# Update bucket ACL
aws s3api get-bucket-acl --bucket <bucket-name> # Way 1 to get the ACL
aws s3api put-bucket-acl --bucket <bucket-name> --access-control-policy file://acl.json

aws s3api get-object-acl --bucket <bucket-name> --key flag #Way 2 to get the ACL
aws s3api put-object-acl --bucket <bucket-name> --key flag --access-control-policy file://objacl.json

##JSON ACL example
## Make sure to modify the Owner’s displayName and ID according to the Object ACL you retrieved.
{
"Owner": {
"DisplayName": "<DisplayName>",
"ID": "<ID>"
},
"Grants": [
{
"Grantee": {
"Type": "Group",
"URI": "http://acs.amazonaws.com/groups/global/AuthenticatedUsers"
},
"Permission": "FULL_CONTROL"
}
]
}
## An ACL should give you the permission WRITE_ACP to be able to put a new ACL
```
### dual-stack <a href="#dual-stack-endpoints-description" id="dual-stack-endpoints-description"></a>

Puedes acceder a un bucket de S3 a través de un endpoint de doble pila utilizando un nombre de endpoint de estilo virtual hospedado o de estilo de ruta. Estos son útiles para acceder a S3 a través de IPv6.

Los endpoints de doble pila utilizan la siguiente sintaxis:

- `bucketname.s3.dualstack.aws-region.amazonaws.com`
- `s3.dualstack.aws-region.amazonaws.com/bucketname`

### Privesc

En la siguiente página puedes verificar cómo **abusar de los permisos de S3 para escalar privilegios**:

{{#ref}}
../aws-privilege-escalation/aws-s3-privesc.md
{{#endref}}

### Acceso No Autenticado

{{#ref}}
../aws-unauthenticated-enum-access/aws-s3-unauthenticated-enum.md
{{#endref}}

### S3 Post Explotación

{{#ref}}
../aws-post-exploitation/aws-s3-post-exploitation.md
{{#endref}}

### Persistencia

{{#ref}}
../aws-persistence/aws-s3-persistence.md
{{#endref}}

## Otras vulnerabilidades de S3

### Problema de Envenenamiento de Caché HTTP de S3 <a href="#heading-s3-http-desync-cache-poisoning-issue" id="heading-s3-http-desync-cache-poisoning-issue"></a>

[**Según esta investigación**](https://rafa.hashnode.dev/exploiting-http-parsers-inconsistencies#heading-s3-http-desync-cache-poisoning-issue) fue posible almacenar en caché la respuesta de un bucket arbitrario como si perteneciera a otro diferente. Esto podría haberse abusado para cambiar, por ejemplo, las respuestas de archivos javascript y comprometer páginas arbitrarias utilizando S3 para almacenar código estático.

## Amazon Athena

Amazon Athena es un servicio de consulta interactivo que facilita **analizar datos** directamente en Amazon Simple Storage Service (Amazon **S3**) **usando** **SQL** estándar.

Necesitas **preparar una tabla de base de datos relacional** con el formato del contenido que va a aparecer en los buckets de S3 monitoreados. Y luego, Amazon Athena podrá poblar la base de datos a partir de los registros, para que puedas consultarla.

Amazon Athena soporta la **capacidad de consultar datos de S3 que ya están cifrados** y, si está configurado para hacerlo, **Athena también puede cifrar los resultados de la consulta que luego pueden ser almacenados en S3**.

**Este cifrado de resultados es independiente de los datos de S3 consultados subyacentes**, lo que significa que incluso si los datos de S3 no están cifrados, los resultados consultados pueden estar cifrados. Un par de puntos a tener en cuenta es que Amazon Athena solo soporta datos que han sido **cifrados** con los **siguientes métodos de cifrado de S3**, **SSE-S3, SSE-KMS y CSE-KMS**.

SSE-C y CSE-E no son soportados. Además de esto, es importante entender que Amazon Athena solo ejecutará consultas contra **objetos cifrados que están en la misma región que la consulta misma**. Si necesitas consultar datos de S3 que han sido cifrados usando KMS, entonces se requieren permisos específicos por parte del usuario de Athena para permitirles realizar la consulta.

### Enumeración
```bash
# Get catalogs
aws athena list-data-catalogs

# Get databases inside catalog
aws athena list-databases --catalog-name <catalog-name>
aws athena list-table-metadata --catalog-name <catalog-name> --database-name <db-name>

# Get query executions, queries and results
aws athena list-query-executions
aws athena get-query-execution --query-execution-id <id> # Get query and meta of results
aws athena get-query-results --query-execution-id <id> # This will rerun the query and get the results

# Get workgroups & Prepared statements
aws athena list-work-groups
aws athena list-prepared-statements --work-group <wg-name>
aws athena get-prepared-statement --statement-name <name> --work-group <wg-name>

# Run query
aws athena start-query-execution --query-string <query>
```
## Referencias

- [https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3](https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3)
- [https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)

{{#include ../../../banners/hacktricks-training.md}}
