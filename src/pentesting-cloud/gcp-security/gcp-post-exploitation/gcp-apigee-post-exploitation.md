# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

Один проект тенанта Apigee можна використати, щоб дістатися до сервера метаданих Message Processor, викрасти його service account і перемкнутися на спільний аналітичний pipeline Dataflow, який читає/записує cross-tenant buckets.

### Expose the metadata server through Apigee

- Встановіть ціль проксі Apigee на `http://169.254.169.254` і робіть запити токенів до `/computeMetadata/v1/instance/service-accounts/default/token` з заголовком `Metadata-Flavor: Google`.
- GCP metadata відкидає запити, що містять `X-Forwarded-For`; Apigee додає цей заголовок за замовчуванням. Видаліть його за допомогою `AssignMessage` перед проксируванням:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Перелічіть вкрадений сервісний акаунт Apigee

- The leaked SA (Google-managed under `gcp-sa-apigee`) можна перерахувати за допомогою інструментів, таких як [gcpwn](https://github.com/NetSPI/gcpwn), щоб швидко перевірити дозволи.
- Спостерігалися потужні дозволи, включаючи **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, та **Pub/Sub topic publish**. Базове виявлення:
```bash
gcloud compute disks list --project <tenant-project>
```
### Snapshot екфільтрація для непрозорих керованих сервісів

Маючи права на disk/snapshot, ви можете офлайн дослідити керовані рантайми навіть якщо не можете увійти в tenant project:

1. Створіть snapshot цільового диска в tenant project.
2. Скопіюйте/мігруйте snapshot у свій проект.
3. Відтворіть диск із snapshot і приєднайте його до свого VM.
4. Змонтуйте і перегляньте логи/конфіги, щоб відновити внутрішні назви bucket, service accounts та опції pipeline.

### Dataflow dependency replacement via writable staging bucket

- Analytics workers під час старту тягнули JAR з GCS staging bucket. Оскільки Apigee SA мав права на запис у bucket, завантажте й підправте JAR (наприклад, за допомогою Recaf), щоб викликати `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` і вкрасти **Dataflow worker** token.
- Dataflow workers не мали internet egress; ексфільтруйте, записавши токен у GCS bucket, контрольований атакуючим, використовуючи in-cluster GCP APIs.

### Force malicious JAR execution by abusing autoscaling

Існуючі workers не будуть перезавантажувати замінені артефакти. Переповніть pipeline input, щоб спровокувати запуск нових workers:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Щойно створені інстанси завантажують виправлені JARs і leak the Dataflow SA token.

### Помилка дизайну cross-tenant bucket

Декомпільований код Dataflow показав шляхи кешу, такі як `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` у спільному metadata bucket, без жодного tenant-specific компонента. Маючи Dataflow token, можна read/write:

- `tenantToTenantGroup` caches, які розкривають імена проектів + environment інших tenants.
- Папки `customFields` та `datastores`, що містять per-request analytics (включаючи end-user IPs та plaintext access tokens) для всіх tenants.
- Наявність Write access означає потенційне analytics tampering/poisoning.

## References

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
