# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee Metadaten-SSRF -> Dataflow mandantenübergreifender pivot

Ein einzelnes Apigee Tenant-Projekt kann missbraucht werden, um den Message Processor Metadaten-Server zu erreichen, dessen service account zu stehlen und in eine gemeinsame Dataflow-Analytics-Pipeline zu pivoten, die cross-tenant Buckets liest/schreibt.

### Expose the metadata server through Apigee

- Setze das Apigee Proxy-Target auf `http://169.254.169.254` und fordere Tokens von `/computeMetadata/v1/instance/service-accounts/default/token` mit `Metadata-Flavor: Google` an.
- GCP metadata weist Anfragen ab, die `X-Forwarded-For` enthalten; Apigee fügt diesen Header standardmäßig hinzu. Entferne ihn mit `AssignMessage`, bevor du weiterleitest:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Auflisten des gestohlenen Apigee Servicekontos

- Die leaked SA (von Google verwaltet unter `gcp-sa-apigee`) lässt sich mit Tools wie [gcpwn](https://github.com/NetSPI/gcpwn) enumerieren, um Berechtigungen schnell zu testen.
- Beobachtete weitreichende Berechtigungen umfassten **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, und **Pub/Sub topic publish**. Grundlegende Erkundung:
```bash
gcloud compute disks list --project <tenant-project>
```
### Snapshot exfiltration für opake verwaltete Dienste

Mit Disk-/Snapshot-Rechten können Sie verwaltete Runtimes offline untersuchen, selbst wenn Sie sich nicht in das Tenant-Projekt einloggen können:

1. Erstellen Sie einen Snapshot der Zieldisk im Tenant-Projekt.
2. Kopieren/migrieren Sie den Snapshot in Ihr Projekt.
3. Erstellen Sie eine Disk aus dem Snapshot neu und hängen Sie sie an Ihre VM an.
4. Mounten und prüfen Sie Logs/Configs, um interne Bucket-Namen, Servicekonten und Pipeline-Optionen wiederherzustellen.

### Dataflow dependency replacement via writable staging bucket

- Analytics-Worker zogen JARs aus einem GCS-Staging-Bucket beim Startup. Da das Apigee SA Schreibzugriff auf den Bucket hatte, laden Sie das JAR herunter und patchen es (z. B. mit Recaf), um `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` aufzurufen und das **Dataflow worker** Token zu stehlen.
- Dataflow-Worker hatten keinen Internet-Egress; exfiltrate, indem Sie das Token mit den in-cluster GCP APIs in einen vom Angreifer kontrollierten GCS-Bucket schreiben.

### Erzwingen der Ausführung bösartiger JARs durch Missbrauch von autoscaling

Bestehende Worker laden ersetzte Artefakte nicht neu. Fluten Sie den Pipeline-Eingang, um neue Worker auszulösen:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Neu bereitgestellte Instanzen laden die gepatchten JARs und leak den Dataflow SA token.

### Cross-tenant bucket design flaw

Im dekompilierten Dataflow-Code wurden Cache-Pfade wie `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` unter einem gemeinsamen metadata bucket gefunden, ohne irgendeine tenant-spezifische Komponente. Mit dem Dataflow token kannst du lesen/schreiben:

- `tenantToTenantGroup` Caches, die die project+environment-Namen anderer Tenants offenlegen.
- `customFields` und `datastores` Ordner, die pro-Anfrage-Analytics enthalten (einschließlich Endbenutzer-IP-Adressen und Klartext-Zugriffstoken) über alle Tenants hinweg.
- Schreibzugriff impliziert potenzielle Manipulation/Vergiftung der Analytics.

## References

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
