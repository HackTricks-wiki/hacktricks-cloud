# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

Mradi mmoja wa tenant wa Apigee unaweza kutumiwa vibaya kufikia Message Processor metadata server, kuiba service account yake, na kugeuka katika pipeline ya analytics ya Dataflow iliyoshirikiwa ambayo inasoma/inaandika buckets za cross-tenant.

### Fichua metadata server kupitia Apigee

- Weka target ya proxy ya Apigee kwa `http://169.254.169.254` na omba tokens kutoka `/computeMetadata/v1/instance/service-accounts/default/token` kwa `Metadata-Flavor: Google`.
- GCP metadata hukataa maombi yanayojumuisha `X-Forwarded-For`; Apigee huiongeza kiotomatiki. Ondoa kwa kutumia `AssignMessage` kabla ya kupitisha kupitia proxy:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Orodhesha akaunti ya huduma ya Apigee iliyoporwa

- The leaked SA (Google-managed under `gcp-sa-apigee`) inaweza kuorodheshwa kwa zana kama [gcpwn](https://github.com/NetSPI/gcpwn) ili kujaribu permissions kwa haraka.
- Permissions zenye nguvu zilizogunduliwa zilijumuisha **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, na **Pub/Sub topic publish**. Ugundaji wa msingi:
```bash
gcloud compute disks list --project <tenant-project>
```
### Snapshot exfiltration for opaque managed services

Kwa haki za disk/snapshot unaweza kuchunguza managed runtimes offline hata kama huwezi kuingia kwenye tenant project:

1. Tengeneza snapshot ya disk lengwa kwenye tenant project.
2. Nakili/hamisha snapshot kwenda project yako.
3. Tengeneza tena disk kutoka snapshot na uiweke kwenye VM yako.
4. Mount na chunguza logs/configs ili kupata majina ya internal buckets, service accounts, na options za pipeline.

### Dataflow dependency replacement via writable staging bucket

- Analytics workers zilivuta JARs kutoka GCS staging bucket wakati wa startup. Kwa sababu Apigee SA alikuwa na bucket write, pakua na patch JAR (mfano, kwa Recaf) ili kuita `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` na kuiba **Dataflow worker** token.
- Dataflow workers walikosa internet egress; exfiltrate kwa kuandika token kwenye GCS bucket inayodhibitiwa na attacker kwa kutumia in-cluster GCP APIs.

### Force malicious JAR execution by abusing autoscaling

Existing workers will not reload replaced artifacts. Flood the pipeline input to trigger new workers:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Instances mpya zilizotolewa hupakua JARs zilizorekebishwa na leak the Dataflow SA token.

### Mapungufu ya muundo wa Cross-tenant bucket

Msimbo wa Dataflow uliotengenezwa kwa decompilation ulionyesha njia za cache kama `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` chini ya shared metadata bucket, bila kipengele chochote maalum kwa tenant. Kwa Dataflow token unaweza kusoma/kuandika:

- `tenantToTenantGroup` caches zinazofichua majina ya project+environment ya tenants wengine.
- `customFields` and `datastores` folders zinazoshikilia analytics za kila ombi (including end-user IPs and plaintext access tokens) kwa tenants wote.
- Ufikiaji wa kuandika unaashiria uwezekano wa analytics tampering/poisoning.

## Marejeo

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
