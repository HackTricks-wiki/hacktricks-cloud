# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

Pojedynczy projekt tenant Apigee można wykorzystać, aby uzyskać dostęp do serwera metadanych Message Processor, ukraść jego service account i pivotować do współdzielonego potoku analitycznego Dataflow, który odczytuje/zapisuje cross-tenant buckets.

### Wystaw serwer metadanych przez Apigee

- Ustaw Apigee proxy target na `http://169.254.169.254` i żądaj tokenów z `/computeMetadata/v1/instance/service-accounts/default/token` z nagłówkiem `Metadata-Flavor: Google`.
- GCP metadata odrzuca żądania zawierające `X-Forwarded-For`; Apigee dodaje je domyślnie. Usuń go za pomocą `AssignMessage` przed przekazaniem przez proxy:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Enumeracja skradzionego konta serwisowego Apigee

- The leaked SA (zarządzane przez Google pod `gcp-sa-apigee`) można zenumerować narzędziami takimi jak [gcpwn](https://github.com/NetSPI/gcpwn), aby szybko przetestować uprawnienia.
- Zaobserwowane potężne uprawnienia obejmowały **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, oraz **Pub/Sub topic publish**. Podstawowe rozpoznanie:
```bash
gcloud compute disks list --project <tenant-project>
```
### Snapshot exfiltration for opaque managed services

Z uprawnieniami do dysku/snapshot możesz zbadać managed runtimes offline, nawet jeśli nie możesz zalogować się do tenant project:

1. Utwórz snapshot docelowego dysku w tenant project.
2. Skopiuj/przenieś snapshot do swojego projektu.
3. Odtwórz dysk ze snapshotu i dołącz go do swojej VM.
4. Zamontuj i przejrzyj logi/konfiguracje, aby odzyskać wewnętrzne nazwy bucketów, service accounts i opcje pipeline.

### Dataflow dependency replacement via writable staging bucket

- Analytics workers pobierały JARy z GCS staging bucket przy starcie. Ponieważ Apigee SA miało uprawnienie zapisu do bucketu, pobierz i zpatchuj JAR (np. z Recaf), aby wywołać `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` i ukraść **Dataflow worker** token.
- Dataflow workers nie miały egressu do internetu; exfiltrate przez zapisanie tokenu do kontrolowanego przez atakującego GCS bucket przy użyciu in-cluster GCP APIs.

### Force malicious JAR execution by abusing autoscaling

Istniejące workers nie przeładują zastąpionych artefaktów. Zalej pipeline input, aby wywołać nowe workers:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Nowo utworzone instancje pobierają załatane JARs i leak the Dataflow SA token.

### Błąd projektowy bucketu między tenantami

Zdekompilowany kod Dataflow pokazywał ścieżki cache takie jak `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` w ramach współdzielonego metadata bucketu, bez komponentu specyficznego dla konkretnego tenanta. Mając Dataflow token możesz read/write:

- `tenantToTenantGroup` caches ujawniające nazwy project+environment innych tenantów.
- foldery `customFields` i `datastores` zawierające per-request analytics (w tym end-user IPs i plaintext access tokens) dla wszystkich tenantów.
- Write access implies potential analytics tampering/poisoning.

## Referencje

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
