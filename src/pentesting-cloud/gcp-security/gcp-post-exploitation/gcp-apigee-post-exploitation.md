# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

Un seul projet tenant Apigee peut être abusé pour atteindre le serveur de métadonnées du Message Processor, voler son compte de service, et pivoter vers un pipeline d'analytics Dataflow partagé qui lit/écrit des buckets inter-locataires.

### Expose the metadata server through Apigee

- Définissez la target du proxy Apigee sur `http://169.254.169.254` et demandez des tokens depuis `/computeMetadata/v1/instance/service-accounts/default/token` avec `Metadata-Flavor: Google`.
- Le serveur de métadonnées GCP rejette les requêtes contenant `X-Forwarded-For` ; Apigee l'ajoute par défaut. Supprimez-le avec `AssignMessage` avant de relayer la requête :
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Énumérer le service account Apigee volé

- Le leaked SA (Google-managed under `gcp-sa-apigee`) peut être énuméré avec des outils comme [gcpwn](https://github.com/NetSPI/gcpwn) pour tester rapidement les permissions.
- Les permissions puissantes observées incluaient **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, et **Pub/Sub topic publish**. Découverte basique :
```bash
gcloud compute disks list --project <tenant-project>
```
### Exfiltration de snapshots pour des services gérés opaques

Avec des droits sur les disques/snapshots, vous pouvez inspecter des runtimes gérés hors ligne même si vous ne pouvez pas vous connecter au projet locataire :

1. Créez un snapshot d'un disque cible dans le projet locataire.
2. Copiez/migrez le snapshot vers votre projet.
3. Recréez un disque à partir du snapshot et attachez-le à votre VM.
4. Montez et inspectez les logs/configs pour récupérer les noms de buckets internes, les service accounts et les options de pipeline.

### Dataflow dependency replacement via writable staging bucket

- Les analytics workers récupéraient des JARs depuis un GCS staging bucket au démarrage. Parce que l'Apigee SA disposait d'un droit d'écriture sur le bucket, on pouvait télécharger et patcher le JAR (par ex. avec Recaf) pour appeler `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` et voler le **Dataflow worker** token.
- Les workers Dataflow n'avaient pas d'egress internet ; exfiltrer en écrivant le token dans un bucket GCS contrôlé par l'attaquant en utilisant les in-cluster GCP APIs.

### Force malicious JAR execution by abusing autoscaling

Les workers existants ne rechargeront pas les artefacts remplacés. Inondez l'entrée du pipeline pour déclencher de nouveaux workers :
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Les instances nouvellement provisionnées récupèrent les JARs patchés et provoquent le leak du Dataflow SA token.

### Défaut de conception du bucket cross-tenant

Le code Dataflow décompilé montrait des chemins de cache comme `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` sous un bucket de metadata partagé, sans aucun composant spécifique au tenant. Avec le Dataflow SA token, vous pouvez lire/écrire :

- `tenantToTenantGroup` caches exposant les noms de projet+environnement des autres tenants.
- `customFields` et `datastores` dossiers contenant des analytics par requête (y compris les IPs des utilisateurs finaux et des access tokens en clair) pour tous les tenants.
- L'accès en écriture implique un risque de falsification/empoisonnement des analytics.

## Références

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
