# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

Un único proyecto tenant de Apigee puede ser abusado para acceder al servidor de metadata del Message Processor, robar su cuenta de servicio y pivotar hacia una canalización analítica compartida de Dataflow que lee y escribe buckets entre tenants.

### Expose the metadata server through Apigee

- Configura el target del proxy de Apigee a `http://169.254.169.254` y solicita tokens desde `/computeMetadata/v1/instance/service-accounts/default/token` con `Metadata-Flavor: Google`.
- GCP metadata rechaza solicitudes que contengan `X-Forwarded-For`; Apigee lo añade por defecto. Elimínalo con `AssignMessage` antes de proxyear:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Enumerar la service account robada de Apigee

- La leaked SA (gestionada por Google bajo `gcp-sa-apigee`) puede ser enumerada con herramientas como [gcpwn](https://github.com/NetSPI/gcpwn) para probar rápidamente permisos.
- Se observaron permisos potentes que incluían **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, y **Pub/Sub topic publish**. Descubrimiento básico:
```bash
gcloud compute disks list --project <tenant-project>
```
### Exfiltración de snapshots para servicios gestionados opacos

Con permisos de disk/snapshot puedes inspeccionar runtimes gestionados offline incluso si no puedes iniciar sesión en el proyecto tenant:

1. Crea un snapshot de un disco objetivo en el proyecto tenant.
2. Copia/migra el snapshot a tu proyecto.
3. Recrea un disco a partir del snapshot y adjúntalo a tu VM.
4. Monta e inspecciona logs/configs para recuperar nombres de buckets internos, service accounts y opciones de pipeline.

### Reemplazo de dependencias de Dataflow mediante un staging bucket escribible

- Analytics workers descargaban JARs desde un GCS staging bucket al inicio. Debido a que la Apigee SA tenía permisos de escritura en el bucket, descarga y parchea el JAR (por ejemplo, con Recaf) para llamar a `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` y robar el token **Dataflow worker**.
- Los Dataflow workers carecían de egress a Internet; exfiltra escribiendo el token en un GCS bucket controlado por el atacante usando las GCP APIs in-cluster.

### Forzar la ejecución de un JAR malicioso abusando del autoscaling

Los workers existentes no recargarán artefactos reemplazados. Inunda la entrada del pipeline para provocar nuevos workers:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Las instancias recién aprovisionadas obtienen los JARs parchados y leak el Dataflow SA token.

### Falla de diseño del bucket cross-tenant

El código decompilado de Dataflow mostró rutas de cache como `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` bajo un bucket de metadata compartido, sin ningún componente específico por tenant. Con el Dataflow token puedes leer/escribir:

- `tenantToTenantGroup` caches que exponen los nombres de proyecto y entorno de otros tenants.
- Las carpetas `customFields` y `datastores` que contienen analytics por solicitud (incluyendo las IPs de usuarios finales y tokens de acceso en texto plano) de todos los tenants.
- El acceso de escritura implica potencial analytics tampering/poisoning.

## Referencias

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
