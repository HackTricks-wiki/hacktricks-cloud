# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

Ένα μεμονωμένο Apigee tenant project μπορεί να καταχραστεί για να προσεγγίσει τον Message Processor metadata server, να κλέψει τον service account του και να μεταπηδήσει σε έναν κοινόχρηστο Dataflow analytics pipeline που διαβάζει/γράφει σε cross-tenant buckets.

### Expose the metadata server through Apigee

- Ορίστε ένα Apigee proxy target σε `http://169.254.169.254` και ζητήστε tokens από `/computeMetadata/v1/instance/service-accounts/default/token` με `Metadata-Flavor: Google`.
- Το metadata του GCP απορρίπτει αιτήματα που περιέχουν `X-Forwarded-For`; το Apigee το προσθέτει εξ ορισμού. Αφαιρέστε το με `AssignMessage` πριν την προώθηση μέσω proxy:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Απαρίθμηση του κλεμμένου Apigee service account

- Το leaked SA (Google-managed under `gcp-sa-apigee`) μπορεί να απαριθμηθεί με εργαλεία όπως [gcpwn](https://github.com/NetSPI/gcpwn) για γρήγορο έλεγχο δικαιωμάτων.
- Εντοπίστηκαν ισχυρά δικαιώματα που περιελάμβαναν **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, και **Pub/Sub topic publish**. Βασική ανακάλυψη:
```bash
gcloud compute disks list --project <tenant-project>
```
### Snapshot exfiltration for opaque managed services

Με δικαιώματα disk/snapshot μπορείτε να επιθεωρήσετε managed runtimes offline ακόμη κι αν δεν μπορείτε να συνδεθείτε στο tenant project:

1. Δημιουργήστε ένα snapshot ενός target disk στο tenant project.
2. Αντιγράψτε/μεταφέρετε το snapshot στο project σας.
3. Αναδημιουργήστε έναν disk από το snapshot και προσαρτήστε τον στη VM σας.
4. Κάντε mount και επιθεωρήστε logs/configs για να ανακτήσετε internal bucket names, service accounts, και pipeline options.

### Dataflow dependency replacement via writable staging bucket

- Οι analytics workers τραβούσαν JARs από ένα GCS staging bucket κατά το startup. Επειδή το Apigee SA είχε bucket write, κατεβάστε και τροποποιήστε το JAR (π.χ. με Recaf) ώστε να καλέσει `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` και να κλέψει το **Dataflow worker** token.
- Οι Dataflow workers δεν είχαν internet egress· exfiltrate γράφοντας το token σε έναν attacker-controlled GCS bucket χρησιμοποιώντας τα in-cluster GCP APIs.

### Force malicious JAR execution by abusing autoscaling

Υπάρχοντες workers δεν θα ξαναφορτώσουν τα αντικαταστημένα artifacts. Πλημμυρίστε την pipeline input για να ενεργοποιήσετε νέους workers:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Πρόσφατα provisioned instances ανακτούν τα patched JARs και leak το Dataflow SA token.

### Cross-tenant bucket design flaw

Ο decompiled κώδικας του Dataflow εμφάνισε μονοπάτια cache όπως `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` κάτω από έναν κοινό metadata bucket, χωρίς κανένα tenant-specific component. Με το Dataflow token μπορείς να read/write:

- `tenantToTenantGroup` caches που αποκαλύπτουν τα project+environment ονόματα άλλων tenants.
- Φάκελοι `customFields` και `datastores` που κρατάνε per-request analytics (συμπεριλαμβανομένων των end-user IPs και plaintext access tokens) για όλους τους tenants.
- Η write πρόσβαση υποδηλώνει πιθανή αλλοίωση/poisoning των analytics.

## References

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
