# GCP - Apigee Post Exploitation

{{#include ../../../banners/hacktricks-training.md}}

## Apigee metadata SSRF -> Dataflow cross-tenant pivot

Tek bir Apigee tenant project, Message Processor metadata server'a ulaşmak, service account'unu çalmak ve cross-tenant bucket'ları okuyan/yazan paylaşılan bir Dataflow analytics pipeline'ına pivot yapmak için kötüye kullanılabilir.

### Expose the metadata server through Apigee

- Apigee proxy hedefini `http://169.254.169.254` olarak ayarlayın ve `Metadata-Flavor: Google` ile `/computeMetadata/v1/instance/service-accounts/default/token`'den token isteyin.
- GCP metadata `X-Forwarded-For` içeren istekleri reddeder; Apigee bunu varsayılan olarak ekler. Proxylemeden önce `AssignMessage` ile bunu çıkarın:
```xml
<AssignMessage name="strip-xff">
<Remove>
<Headers>
<Header name="X-Forwarded-For"/>
</Headers>
</Remove>
<IgnoreUnresolvedVariables>true</IgnoreUnresolvedVariables>
</AssignMessage>
```
### Çalınmış Apigee servis hesabını listele

- The leaked SA (Google tarafından `gcp-sa-apigee` altında yönetilen) gcpwn gibi araçlarla izinleri hızlıca test etmek için listelenebilir.
- Gözlemlenen güçlü izinler arasında şunlar vardı: **Compute disk/snapshot admin**, **GCS read/write across tenant buckets**, ve **Pub/Sub topic publish**. Temel keşif:
```bash
gcloud compute disks list --project <tenant-project>
```
### Snapshot exfiltration for opaque managed services

Disk/snapshot izinleriyle tenant projeye giriş yapamıyor olsanız bile yönetilen çalışma zamanlarını çevrimdışı inceleyebilirsiniz:

1. Tenant projedeki hedef diskin snapshot'ını oluşturun.
2. Snapshot'ı kendi projenize kopyalayın/göç ettirin.
3. Snapshot'tan bir disk yeniden oluşturun ve VM'inize takın.
4. Log'ları/konfigürasyonları mount edip iç bucket isimlerini, servis hesaplarını ve pipeline seçeneklerini geri çıkarın.

### Dataflow dependency replacement via writable staging bucket

- Analytics workers startup'ta GCS staging bucket'tan JAR'ları çekiyordu. Apigee SA'nın bucket yazma izni olduğundan JAR'ı indirin ve (ör. Recaf ile) `http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token` çağıracak ve **Dataflow worker** token'ını çalacak şekilde patch'leyin.
- Dataflow workers'ın internet egress'i yoktu; token'ı küme içi GCP API'lerini kullanarak saldırgan kontrollü bir GCS bucket'ına yazarak exfiltrate edin.

### Force malicious JAR execution by abusing autoscaling

Mevcut worker'lar değiştirilmiş artifact'ları yeniden yüklemeyecek. Yeni worker'ları tetiklemek için pipeline girişini aşırı yükleyin:
```bash
for i in {1..5000}; do
gcloud pubsub topics publish apigee-analytics-notifications \
--message "flood-$i" --project <tenant-project>
done
```
Yeni oluşturulan instance'lar yama uygulanmış JAR'ları alıyor ve leak the Dataflow SA token.

### Cross-tenant bucket tasarım hatası

Decompile edilmiş Dataflow kodu, paylaşılan bir metadata bucket'ı altında tenant'a özgü herhangi bir bileşen olmadan `revenue/edge/<api|mint>/tenant2TenantGroupCacheDir` gibi önbellek yolları gösteriyordu. Dataflow token ile okuyup/yazabilirsiniz:

- `tenantToTenantGroup` önbellekleri diğer tenant'ların project+environment isimlerini açığa çıkarır.
- `customFields` ve `datastores` klasörleri tüm tenant'lar genelinde isteğe bağlı analitik veriler (son-kullanıcı IP'leri ve düz metin access token'lar dahil) barındırır.
- Yazma erişimi analitik verilerde olası tahrifat/zehirleme anlamına gelir.

## Referanslar

- [GatewayToHeaven: Finding a Cross-Tenant Vulnerability in GCP's Apigee](https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/)
- [AssignMessage policy - header removal](https://cloud.google.com/apigee/docs/api-platform/reference/policies/assign-message-policy)

{{#include ../../../banners/hacktricks-training.md}}
