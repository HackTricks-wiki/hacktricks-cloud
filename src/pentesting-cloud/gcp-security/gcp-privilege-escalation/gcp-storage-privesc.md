# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

Podstawowe informacje:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

To uprawnienie pozwala na **pobieranie plików przechowywanych w Cloud Storage**. Może to potencjalnie umożliwić eskalację uprawnień, ponieważ w niektórych przypadkach **przechowywane są tam poufne informacje**. Co więcej, niektóre usługi GCP zapisują swoje dane w bucketach:

- **GCP Composer**: Kiedy tworzysz Composer Environment, **kod wszystkich DAGów** zostanie zapisany w **buckecie**. Te zadania mogą zawierać interesujące informacje w swoim kodzie.
- **GCR (Container Registry)**: **Image** kontenerów są przechowywane w **bucketach**, co oznacza, że jeśli możesz odczytać buckety, będziesz w stanie pobrać obrazy i **search for leaks and/or source code**.

### `storage.objects.setIamPolicy`

To uprawnienie pozwala ci **wykorzystać dowolny z poprzednich scenariuszy opisanych w tej sekcji**.
```bash
# Add binding
gcloud storage objects add-iam-policy-binding gs://<BUCKET_NAME>/<OBJECT_NAME> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role="<ROLE>" \
--project=<PROJECT_ID>

# Remove binding
gcloud storage objects remove-iam-policy-binding gs://<BUCKET_NAME>/<OBJECT_NAME> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role="<ROLE>" \
--project=<PROJECT_ID>

# Change Policy
gcloud storage objects set-iam-policy gs://<BUCKET_NAME>/<OBJECT_NAME> - \
--project=<PROJECT_ID> <<'POLICY'
{
"bindings": [
{
"role": "<ROLE>",
"members": [
"<MEMBER_TYPE>:<MEMBER_IDENTIFIER>"
]
}
]
}
POLICY

```
### **`storage.buckets.setIamPolicy`**

Przykład modyfikacji uprawnień przy użyciu tego uprawnienia znajdziesz na tej stronie:
```bash
# Add binding
gcloud storage buckets add-iam-policy-binding gs://<MY_BUCKET> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role=<ROLE> \
--project=<MY_PROJECT>

# Remove binding
gcloud storage buckets remove-iam-policy-binding gs://<MY_BUCKET> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role=<ROLE> \
--project=<MY_PROJECT>

# Change policy
gcloud storage buckets set-iam-policy gs://<BUCKET_NAME> - \
--project=<PROJECT_ID> <<'POLICY'
{
"bindings": [
{
"role": "<ROLE>",
"members": [
"<MEMBER_TYPE>:<MEMBER_IDENTIFIER>"
]
}
]
}
POLICY

```
{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

Funkcja "interoperability" Cloud Storage, przeznaczona do **cross-cloud interactions** (np. z AWS S3), polega na **tworzeniu HMAC keys dla Service Accounts i users**. Atakujący może to wykorzystać, **generując HMAC key dla Service Account z podwyższonymi uprawnieniami**, co pozwala na **eskalację uprawnień w Cloud Storage**. HMAC keys powiązane z użytkownikami można pobrać tylko przez web console, jednak zarówno access jak i secret keys pozostają **dostępne na stałe**, co umożliwia przechowywanie zapasowego dostępu. Natomiast HMAC keys powiązane z Service Account są dostępne przez API, ale ich access i secret keys nie są możliwe do odzyskania po utworzeniu, co utrudnia utrzymanie ciągłego dostępu.
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
Inny exploit script dla tej metody można znaleźć [here](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py).

### `storage.objects.create`, `storage.objects.delete` = Storage Write permissions

Aby **utworzyć nowy obiekt** inside a bucket potrzebujesz `storage.objects.create` i, zgodnie z [the docs](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions), potrzebujesz także `storage.objects.delete`, aby **zmodyfikować** istniejący obiekt.

Bardzo **częste wykorzystanie** bucketów, do których możesz zapisywać w chmurze, występuje gdy **bucket przechowuje pliki serwera WWW** — możesz wtedy być w stanie **wgrać nowy kod**, który zostanie użyty przez aplikację webową.

### Composer

**Composer** is **Apache Airflow** managed inside GCP. Ma kilka interesujących cech:

- Działa wewnątrz **klastra GKE**, więc **SA używany przez klaster jest dostępny** dla kodu uruchamianego w Composerze
- Wszystkie komponenty środowiska Composer (**code of DAGs**, plugins and data) są przechowywane inside a GCP bucket. Jeśli atakujący ma nad nim uprawnienia do odczytu i zapisu, może monitorować bucket i **whenever a DAG is created or updated, submit a backdoored version** tak, że środowisko Composer pobierze z storage wersję z backdoorem.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- Kod Cloud Functions jest przechowywany w Storage i za każdym razem, gdy tworzona jest nowa wersja, kod jest przesyłany do bucketu, a następnie na jego podstawie budowany jest nowy container. W związku z tym, **nadpisanie kodu przed zbudowaniem nowej wersji pozwala zmusić Cloud Function do wykonania arbitrary code**.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

Wersje AppEngine generują pewne dane inside a bucket o formacie nazwy: `staging.<project-id>.appspot.com`. W tym buckecie można znaleźć folder o nazwie `ae`, który będzie zawierał folder dla każdej wersji aplikacji AppEngine, a w tych folderach będzie można znaleźć plik `manifest.json`. Ten plik zawiera json ze wszystkimi plikami, które muszą zostać użyte do stworzenia danej wersji. Co więcej, można znaleźć **rzeczywiste nazwy plików, URL do nich inside the GCP bucket (pliki inside the bucket zmieniły swoją nazwę na ich sha1 hash) oraz sha1 hash każdego pliku.**

_Note that it's not possible to pre-takeover this bucket because GCP users aren't authorized to generate buckets using the domain name appspot.com._

Jednak przy dostępie do odczytu i zapisu do tego bucketa, możliwe jest eskalowanie uprawnień do SA przypisanego do wersji App Engine poprzez monitorowanie bucketa i za każdym razem, gdy nastąpi zmiana (nowa wersja), zmodyfikować nową wersję tak szybko, jak to możliwe. W ten sposób container tworzony z tego kodu wykona backdoored code.

Wspomniany atak można przeprowadzić na wiele różnych sposobów, wszystkie zaczynają się od monitorowania bucketa `staging.<project-id>.appspot.com`:

- Wgraj kompletny nowy kod wersji AppEngine do innego dostępnego bucketa i przygotuj **`manifest.json` file with the new bucket name and sha1 hashes of them**. Następnie, gdy w buckecie zostanie utworzona nowa wersja, wystarczy zmodyfikować plik `manifest.json` i przesłać złośliwy.
- Wgraj zmodyfikowany `requirements.txt`, który będzie używać **malicious dependencies code** i zaktualizuj plik `manifest.json` o nową nazwę pliku, URL i jego hash.
- Wgraj **zmodyfikowany `main.py` or `app.yaml` file that will execute the malicious code** i zaktualizuj plik `manifest.json` o nową nazwę pliku, URL i jego hash.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** stores the images inside buckets, jeśli możesz **write those buckets** możesz być w stanie **move laterally to where those buckets are being run.**
- Bucket używany przez GCR będzie miał URL podobny do `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (The top level subdomains are specified [here](https://cloud.google.com/container-registry/docs/pushing-and-pulling)).

> [!TIP]
> Ta usługa jest przestarzała, więc ten atak nie jest już użyteczny. Ponadto, Artifact Registry, usługa która zastępuje tę, nie przechowuje obrazów w bucketach.

## **References**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
