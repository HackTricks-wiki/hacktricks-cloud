# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

Basic Information:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

This permission allows you to **download files stored inside Cloud Storage**. This will potentially allow you to escalate privileges because in some occasions **sensitive information is saved there**. Moreover, some GCP services stores their information in buckets:

- **GCP Composer**: When you create a Composer Environment the **code of all the DAGs** will be saved inside a **bucket**. These tasks might contain interesting information inside of their code.
- **GCR (Container Registry)**: The **image** of the containers are stored inside **buckets**, which means that if you can read the buckets you will be able to download the images and **search for leaks and/or source code**.

### `storage.objects.setIamPolicy`

You can give you permission to **abuse any of the previous scenarios of this section**.

### **`storage.buckets.setIamPolicy`**

For an example on how to modify permissions with this permission check this page:

{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

La fonctionnalité "interoperability" de Cloud Storage, conçue pour les **cross-cloud interactions** comme avec AWS S3, implique la **création de HMAC keys pour les Service Accounts et les users**. Un attaquant peut exploiter cela en **générant une HMAC key pour un Service Account avec elevated privileges**, ce qui permet **escalating privileges within Cloud Storage**. Alors que les HMAC keys associées aux users ne sont récupérables que via le web console, both the access and secret keys restent **perpetually accessible**, permettant un stockage de secours pour un accès potentiel. En revanche, les HMAC keys liées aux Service Accounts sont accessibles via l'API, mais leurs access and secret keys ne sont pas récupérables après la création, ajoutant une couche de complexité pour un accès continu.

<details><summary>Créer et utiliser HMAC key pour privilege escalation</summary>
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
</details>

Another exploit script for this method can be found [here](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py).

### `storage.objects.create`, `storage.objects.delete` = Permissions d'écriture Storage

Pour **créer un nouvel objet** dans un bucket vous avez besoin de `storage.objects.create` et, selon [the docs](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions), vous avez aussi besoin de `storage.objects.delete` pour **modifier** un objet existant.

Une exploitation très **courante** des buckets où vous pouvez écrire dans le cloud est lorsque le **bucket contient des fichiers de serveur web** : vous pourriez être en mesure de **stocker du nouveau code** qui sera utilisé par l'application web.

### Composer

**Composer** est **Apache Airflow** géré dans GCP. Il présente plusieurs caractéristiques intéressantes :

- Il s'exécute dans un **GKE cluster**, donc le **SA utilisé par le cluster est accessible** par le code s'exécutant dans Composer.
- Tous les composants d'un environnement Composer (**code of DAGs**, plugins et data) sont stockés dans un bucket GCP. Si l'attaquant a des permissions de lecture et d'écriture dessus, il pourrait surveiller le bucket et **à chaque fois qu'un DAG est créé ou mis à jour, soumettre une version backdoored** afin que l'environnement Composer récupère depuis le storage la version backdoored.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- Le code des Cloud Functions est stocké dans Storage et dès qu'une nouvelle version est créée le code est poussé vers le bucket puis le nouveau container est construit à partir de ce code. Par conséquent, **en écrasant le code avant que la nouvelle version ne soit construite, il est possible de faire exécuter du code arbitraire par la cloud function**.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

Les versions AppEngine génèrent des données dans un bucket ayant pour nom le format : `staging.<project-id>.appspot.com`. Dans ce bucket, il est possible de trouver un dossier appelé `ae` qui contiendra un dossier par version de l'application AppEngine et à l'intérieur de ces dossiers on pourra trouver le fichier `manifest.json`. Ce fichier contient un json avec tous les fichiers qui doivent être utilisés pour créer la version spécifique. De plus, il est possible de trouver les **vrais noms des fichiers, l'URL vers eux dans le bucket GCP (les fichiers dans le bucket ont changé de nom pour leur sha1 hash) et le sha1 hash de chaque fichier.**

_Note que ce n'est pas possible de pré-usurper ce bucket parce que les utilisateurs GCP ne sont pas autorisés à créer des buckets utilisant le nom de domaine appspot.com._

Cependant, avec un accès en lecture et écriture sur ce bucket, il est possible d'escalader les privilèges vers le SA attaché à la version App Engine en surveillant le bucket et à chaque fois qu'un changement est effectué (nouvelle version), modifier la nouvelle version aussi rapidement que possible. De cette manière, le container créé à partir de ce code exécutera le code backdoored.

L'attaque mentionnée peut être réalisée de nombreuses façons différentes, toutes commencent par surveiller le bucket `staging.<project-id>.appspot.com` :

- Téléverser le code complet de la nouvelle version AppEngine dans un bucket différent et disponible et préparer un **`manifest.json` file with the new bucket name and sha1 hashes of them**. Ensuite, lorsque une nouvelle version est créée dans le bucket, il suffit de modifier le fichier `manifest.json` et d'uploader la version malveillante.
- Téléverser une version modifiée de `requirements.txt` qui utilisera du **malicious dependencies code** et mettre à jour le `manifest.json` avec le nouveau nom de fichier, l'URL et le hash correspondant.
- Téléverser un **`main.py` ou `app.yaml` modifié qui exécutera le code malveillant** et mettre à jour le `manifest.json` avec le nouveau nom de fichier, l'URL et le hash correspondant.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** stocke les images dans des buckets, si vous pouvez **écrire dans ces buckets** vous pourriez être capable de **move laterally to where those buckets are being run.**
- Le bucket utilisé par GCR aura une URL similaire à `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (Les sous-domaines de premier niveau sont spécifiés [here](https://cloud.google.com/container-registry/docs/pushing-and-pulling)).

> [!TIP]
> Ce service est déprécié donc cette attaque n'est plus utile. De plus, Artifact Registry, le service qui remplace celui-ci, ne stocke pas les images dans des buckets.

## **Références**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
