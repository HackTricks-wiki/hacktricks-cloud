# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

Basic Information:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

To uprawnienie pozwala Ci **pobrać pliki zapisane w Cloud Storage**. Może to potencjalnie pozwolić na eskalację uprawnień, ponieważ w niektórych przypadkach **przechowywane są tam poufne informacje**. Co więcej, niektóre usługi GCP zapisują swoje dane w buckets:

- **GCP Composer**: Gdy utworzysz Composer Environment, **kod wszystkich DAGów** zostanie zapisany w **bucket**. Te zadania mogą zawierać interesujące informacje w swoim kodzie.
- **GCR (Container Registry)**: **obrazy** kontenerów są przechowywane w **bucketach**, co oznacza, że jeśli możesz czytać buckety, będziesz w stanie pobrać obrazy i **wyszukać leaks i/lub kod źródłowy**.

### `storage.objects.setIamPolicy`

To uprawnienie pozwala Ci **wykorzystać dowolny z powyższych scenariuszy opisanych w tej sekcji**.

### **`storage.buckets.setIamPolicy`**

Przykład pokazujący, jak modyfikować uprawnienia za pomocą tego uprawnienia, znajdziesz na tej stronie:

{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

Funkcja "interoperability" w Cloud Storage, zaprojektowana dla **cross-cloud interactions** (np. z AWS S3), obejmuje **tworzenie HMAC keys dla Service Accounts i użytkowników**. Atakujący może to wykorzystać, **generując HMAC key dla Service Account z podwyższonymi uprawnieniami**, tym samym **eskalując uprawnienia w Cloud Storage**. Podczas gdy HMAC keys powiązane z użytkownikami można odzyskać jedynie przez web console, zarówno access i secret keys pozostają **na stałe dostępne**, co pozwala na potencjalne przechowywanie zapasowego dostępu. Natomiast HMAC keys powiązane z Service Account są dostępne przez API, ale ich access i secret keys nie są możliwe do odzyskania po utworzeniu, co utrudnia ciągły dostęp.

<details><summary>Utwórz i użyj HMAC key for privilege escalation</summary>
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
</details>

Another exploit script for this method can be found [here](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py).

### `storage.objects.create`, `storage.objects.delete` = Storage — uprawnienia zapisu

Aby **utworzyć nowy obiekt** w bucketcie potrzebujesz `storage.objects.create` i, zgodnie z [the docs](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions), potrzebujesz też `storage.objects.delete`, aby **modyfikować** istniejący obiekt.

Bardzo **częstym sposobem eskalacji** przy bucketach, do których można zapisywać, jest sytuacja gdy **bucket przechowuje pliki serwera WWW** — możesz być w stanie **zapisać nowy kod**, który zostanie użyty przez aplikację webową.

### Composer

**Composer** to zarządzany w GCP **Apache Airflow**. Ma kilka interesujących cech:

- Działa wewnątrz **GKE cluster**, więc **SA używane przez klaster jest dostępne** dla kodu uruchamianego w Composer
- Wszystkie komponenty środowiska composer (**kod DAGs**, pluginy i dane) są przechowywane w GCP bucket. Jeśli atakujący ma uprawnienia odczytu i zapisu do tego bucketa, może monitorować bucket i **za każdym razem, gdy DAG zostanie utworzony lub zaktualizowany, wstawić wersję z backdoorem**, tak aby środowisko composer pobrało z storage zmodyfikowaną wersję.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- Kod Cloud Functions jest przechowywany w Storage i ilekroć tworzona jest nowa wersja, kod jest pushowany do bucketa, a następnie nowy kontener jest budowany z tego kodu. W związku z tym, **nadpisanie kodu zanim nowa wersja zostanie zbudowana pozwala na zmuszenie cloud function do wykonania dowolnego kodu**.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

Wersje AppEngine generują pewne dane wewnątrz bucketa o formacie nazwy: `staging.<project-id>.appspot.com`. W tym buckecie można znaleźć folder o nazwie `ae`, który będzie zawierał folder dla każdej wersji aplikacji AppEngine, a w tych folderach będzie można znaleźć plik `manifest.json`. Ten plik zawiera json ze wszystkimi plikami, które muszą być użyte do stworzenia konkretnej wersji. Ponadto można znaleźć **rzeczywiste nazwy plików, URL do nich wewnątrz GCP bucket (pliki w buckecie zmieniły nazwę na ich sha1 hash) oraz sha1 hash każdego pliku.**

_Zwróć uwagę, że nie jest możliwe wcześniejsze przejęcie tego bucketa, ponieważ użytkownicy GCP nie mają uprawnień do tworzenia bucketów używających domeny appspot.com._

Jednak mając dostęp do odczytu i zapisu do tego bucketa, można eskalować uprawnienia do SA przypisanego do wersji App Engine poprzez monitorowanie bucketa i za każdym razem, gdy nastąpi zmiana (nowa wersja), jak najszybszą modyfikację nowej wersji. W ten sposób kontener tworzony z tego kodu wykona backdoored kod.

Wspomniany atak można przeprowadzić na wiele sposobów, wszystkie zaczynają się od monitorowania bucketa `staging.<project-id>.appspot.com`:

- Prześlij kompletny nowy kod wersji AppEngine do innego dostępnego bucketa i przygotuj **plik `manifest.json` z nazwą nowego bucketa i sha1 hashami plików**. Następnie, gdy nowa wersja zostanie stworzona w oryginalnym buckecie, wystarczy zmodyfikować `manifest.json` i wgrać złośliwy.
- Wgraj zmodyfikowany `requirements.txt`, który będzie używać **złośliwych zależności** i zaktualizuj `manifest.json` z nową nazwą pliku, URL i hashem.
- Wgraj **zmodyfikowany `main.py` lub `app.yaml`, który wykona złośliwy kod** i zaktualizuj `manifest.json` z nową nazwą pliku, URL i hashem.

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** przechowuje images wewnątrz bucketów — jeśli możesz **zapisywać w tych bucketach**, możesz później **poruszać się lateralnie tam, gdzie te buckety są uruchamiane.**
- Bucket używany przez GCR będzie miał URL podobny do `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (górne subdomeny są określone [here](https://cloud.google.com/container-registry/docs/pushing-and-pulling)).

> [!TIP]
> Ta usługa jest deprecated, więc ten atak nie jest już użyteczny. Ponadto Artifact Registry, usługa która ją zastępuje, nie przechowuje images w bucketach.

## **References**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
