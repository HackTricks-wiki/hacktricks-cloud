# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

Basic Information:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

Diese Berechtigung erlaubt dir, **Dateien herunterzuladen, die in Cloud Storage gespeichert sind**. Dies kann dir potenziell erlauben, escalate privileges, da in einigen Fällen **sensible Informationen dort gespeichert werden**. Außerdem speichern einige GCP-Services ihre Informationen in Buckets:

- **GCP Composer**: Wenn du ein Composer Environment erstellst, wird der **Code aller DAGs** in einem **Bucket** gespeichert. Diese Tasks könnten interessante Informationen in ihrem Code enthalten.
- **GCR (Container Registry)**: Die **Images** der Container werden in **Buckets** gespeichert, was bedeutet, dass du, wenn du die Buckets lesen kannst, die Images herunterladen und **nach leaks und/oder Quellcode** suchen kannst.

### `storage.objects.setIamPolicy`

Damit kannst du dir die Berechtigung geben, **jede der vorherigen Szenarien dieses Abschnitts zu missbrauchen**.

### **`storage.buckets.setIamPolicy`**

Ein Beispiel dafür, wie man Berechtigungen mit dieser Berechtigung ändert, findest du auf dieser Seite:

{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

Die "interoperability"-Funktion von Cloud Storage, entwickelt für **cross-cloud interactions** wie mit AWS S3, beinhaltet die **Erstellung von HMAC keys für Service Accounts und Benutzer**. Ein Angreifer kann dies ausnutzen, indem er **einen HMAC key für einen Service Account mit elevated privileges erzeugt**, und dadurch **escalating privileges innerhalb von Cloud Storage** ermöglicht. Während HMAC keys, die Benutzern zugeordnet sind, nur über die Web-Konsole abrufbar sind, bleiben sowohl Access- als auch Secret-Keys **dauerhaft zugänglich**, was das Speichern von Backup-Zugängen erlaubt. Im Gegensatz dazu sind HMAC keys, die mit Service Accounts verknüpft sind, per API zugänglich, aber ihre Access- und Secret-Keys sind nach der Erstellung nicht mehr abrufbar, was die Aufrechterhaltung eines kontinuierlichen Zugangs erschwert.

<details><summary>Erstellen und Verwenden eines HMAC key für privilege escalation</summary>
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
</details>

Ein weiteres Exploit-Skript für diese Methode ist [hier](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py) zu finden.

### `storage.objects.create`, `storage.objects.delete` = Storage Write permissions

Um ein **neues Objekt** in einem Bucket zu erstellen, benötigen Sie `storage.objects.create` und, laut [der Dokumentation](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions), außerdem `storage.objects.delete`, um ein vorhandenes Objekt zu **ändern**.

Eine sehr **häufige Ausnutzung** von Buckets, in die man in der Cloud schreiben kann, ist der Fall, dass der **Bucket Webserver-Dateien speichert** — man könnte in der Lage sein, **neuen Code zu speichern**, der von der Webanwendung verwendet wird.

### Composer

**Composer** ist **Apache Airflow**, das in GCP verwaltet wird. Es hat mehrere interessante Eigenschaften:

- Es läuft innerhalb eines **GKE-Clusters**, daher ist die **vom Cluster verwendete SA vom in Composer ausgeführten Code aus zugänglich**.
- Alle Komponenten einer Composer-Umgebung (**code of DAGs**, Plugins und Daten) werden in einem GCP-Bucket gespeichert. Wenn ein Angreifer Lese- und Schreibrechte darauf hat, könnte er den Bucket überwachen und **immer wenn ein DAG erstellt oder aktualisiert wird, eine backdoored Version einreichen**, sodass die Composer-Umgebung die backdoored Version aus dem Storage erhält.

Einen PoC dieses Angriffs findest du im Repo: [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- Der Code von Cloud Functions wird in Storage gespeichert und wann immer eine neue Version erstellt wird, wird der Code in den Bucket gepusht und daraus der neue Container gebaut. Daher ist es möglich, durch das Überschreiben des Codes, bevor die neue Version gebaut wird, die Cloud Function dazu zu bringen, arbitrary code auszuführen.

Einen PoC dieses Angriffs findest du im Repo: [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

AppEngine-Versionen erzeugen einige Daten in einem Bucket mit dem Format: `staging.<project-id>.appspot.com`. In diesem Bucket findet man einen Ordner namens `ae`, der pro Version der AppEngine-App einen Unterordner enthält; in diesen Ordnern ist die Datei `manifest.json` zu finden. Diese Datei enthält ein JSON mit allen Dateien, die zur Erstellung der jeweiligen Version verwendet werden müssen. Außerdem sind dort die **echten Namen der Dateien, die URL zu ihnen innerhalb des GCP-Buckets (die Dateien im Bucket haben ihren Namen durch ihren sha1-Hash ersetzt) und der sha1-Hash jeder Datei** aufgeführt.

_Hinweis: Es ist nicht möglich, diesen Bucket im Vorfeld zu übernehmen, weil GCP-Benutzer nicht berechtigt sind, Buckets mit der Domain appspot.com zu erstellen._

Mit Lese- und Schreibzugriff auf diesen Bucket ist es jedoch möglich, auf die SA zu eskalieren, die an die App Engine-Version angehängt ist, indem man den Bucket überwacht und jedes Mal, wenn eine Änderung vorgenommen wird (neue Version), die neue Version so schnell wie möglich verändert. Auf diese Weise wird der Container, der aus diesem Code erstellt wird, den backdoored Code ausführen.

Der beschriebene Angriff kann auf verschiedene Arten durchgeführt werden; alle beginnen mit der Überwachung des Buckets `staging.<project-id>.appspot.com`:

- Lade den kompletten neuen Code der AppEngine-Version in einen anderen verfügbaren Bucket hoch und erstelle eine **`manifest.json`-Datei mit dem neuen Bucket-Namen und den sha1-Hashes** der Dateien. Wenn dann eine neue Version im Bucket erstellt wird, musst du nur die `manifest.json`-Datei modifizieren und die bösartige Version hochladen.
- Lade eine modifizierte `requirements.txt`-Version hoch, die die **bösartigen Abhängigkeiten** verwendet, und aktualisiere die `manifest.json`-Datei mit dem neuen Dateinamen, der URL und dem Hash.
- Lade eine **modifizierte `main.py` oder `app.yaml`-Datei hoch, die den bösartigen Code ausführt**, und aktualisiere die `manifest.json`-Datei mit dem neuen Dateinamen, der URL und dem Hash.

Einen PoC dieses Angriffs findest du im Repo: [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** speichert die Images in Buckets; wenn du in diese Buckets **schreiben** kannst, könntest du dich lateral bewegen zu den Orten, an denen diese Buckets ausgeführt werden.
- Der von GCR verwendete Bucket hat eine URL ähnlich zu `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (Die Top-Level-Subdomains sind [hier](https://cloud.google.com/container-registry/docs/pushing-and-pulling) angegeben).

> [!TIP]
> Dieser Service ist deprecated, daher ist dieser Angriff nicht mehr nützlich. Außerdem speichert Artifact Registry, der ersetzende Service, die Images nicht in Buckets.

## **Referenzen**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
