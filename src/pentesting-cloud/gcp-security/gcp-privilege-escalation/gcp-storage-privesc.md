# GCP - Storage Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Storage

मूल जानकारी:

{{#ref}}
../gcp-services/gcp-storage-enum.md
{{#endref}}

### `storage.objects.get`

This permission आपको Cloud Storage के अंदर stored files को **download** करने की अनुमति देता है। कभी-कभी **संवेदनशील जानकारी वहीं saved रहती है**, इसलिए यह privilege escalation की संभावना पैदा कर सकता है। इसके अलावा, कुछ GCP सेवाएँ अपनी जानकारी buckets में स्टोर करती हैं:

- **GCP Composer**: जब आप एक Composer Environment बनाते हैं तो सभी DAGs का **code** एक **bucket** के अंदर saved रहता है। इन tasks के code में दिलचस्प जानकारी मिल सकती है।
- **GCR (Container Registry)**: containers की **image** भी **buckets** में stored होती हैं, जिसका मतलब है कि अगर आप buckets पढ़ सकते हैं तो images डाउनलोड करके **search for leaks and/or source code** कर पाएंगे।

### `storage.objects.setIamPolicy`

यह permission आपको इस सेक्शन के किसी भी पहले बताए गए scenario को **abuse** करने की अनुमति दे सकता है।

### **`storage.buckets.setIamPolicy`**

permissions को modify करने का एक उदाहरण देखने के लिए इस पेज को देखें:

{{#ref}}
../gcp-unauthenticated-enum-and-access/gcp-storage-unauthenticated-enum/gcp-public-buckets-privilege-escalation.md
{{#endref}}

### `storage.hmacKeys.create`

Cloud Storage की "interoperability" feature, जो AWS S3 जैसी cross-cloud interactions के लिए डिज़ाइन की गई है, में **Service Accounts और users के लिए HMAC keys का creation** शामिल है। एक attacker इसका फायदा उठाकर **उच्च privileges वाले Service Account के लिए HMAC key generate** कर सकता है, और इस तरह Cloud Storage के अंदर **privileges escalate** कर सकता है। जबकि user-associated HMAC keys केवल web console से retrieveable होते हैं, access और secret keys दोनों **perpetually accessible** रह सकते हैं, जो potential backup access storage की अनुमति देते हैं। इसके विपरीत, Service Account-linked HMAC keys API-accessible होते हैं, लेकिन उनके access और secret keys creation के बाद retrievable नहीं होते, जो continuous access के मामले में जटिलता जोड़ता है।

<details><summary>Create and use HMAC key for privilege escalation</summary>
```bash
# Create key
gsutil hmac create <sa-email> # You might need to execute this inside a VM instance

## If you have TROUBLES creating the HMAC key this was you can also do it contacting the API directly:
PROJECT_ID = '$PROJECT_ID'
TARGET_SERVICE_ACCOUNT = f"exam-storage-sa-read-flag-3@{PROJECT_ID}.iam.gserviceaccount.com"
ACCESS_TOKEN = "$CLOUDSDK_AUTH_ACCESS_TOKEN"
import requests
import json
key = requests.post(
f'https://www.googleapis.com/storage/v1/projects/{PROJECT_ID}/hmacKeys',
params={'access_token': ACCESS_TOKEN, 'serviceAccountEmail': TARGET_SERVICE_ACCOUNT}
).json()
#print(json.dumps(key, indent=4))
print(f'ID: {key["metadata"]["accessId"]}')
print(f'Secret: {key["secret"]}')


# Configure gsutil to use the HMAC key
gcloud config set pass_credentials_to_gsutil false
gsutil config -a

# Use it
gsutil ls gs://[BUCKET_NAME]

# Restore
gcloud config set pass_credentials_to_gsutil true
```
</details>

Another exploit script for this method can be found [here](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/storage.hmacKeys.create.py).

### `storage.objects.create`, `storage.objects.delete` = Storage Write permissions

एक bucket के अंदर नया ऑब्जेक्ट **create** करने के लिए आपको `storage.objects.create` चाहिए और, [the docs](https://cloud.google.com/storage/docs/access-control/iam-permissions#object_permissions) के अनुसार, किसी मौजूद ऑब्जेक्ट को **modify** करने के लिए आपको `storage.objects.delete` भी चाहिए।

एक बहुत ही सामान्य exploitation उन buckets का होता है जिनमें आप क्लाउड में लिख सकते हैं — खासकर जब वह **bucket web server files सेव कर रहा हो**, तब आप ऐसा कर सकते हैं कि नया code स्टोर कर दें जो web application द्वारा उपयोग में लाया जाएगा।

### Composer

**Composer** GCP के अंदर managed **Apache Airflow** है। इसमें कुछ महत्वपूर्ण विशेषताएँ हैं:

- यह **GKE cluster** के अंदर चलता है, इसलिए cluster जो **SA** उपयोग करता है वह Composer के अंदर चल रहे code द्वारा accessible होता है।
- Composer environments के सभी components (यानी **code of DAGs**, plugins और data) एक GCP bucket में store होते हैं। अगर attacker के पास उस पर read और write permissions हैं, तो वह bucket को monitor कर सकता है और **जब भी कोई DAG बनाया या अपडेट किया जाए, एक backdoored version submit कर सकता है** ताकि composer environment storage से वह backdoored version ले ले।

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs**](https://github.com/carlospolop/Monitor-Backdoor-Composer-DAGs)

### Cloud Functions

- Cloud Functions का code Storage में store होता है और जब भी नया version बनाया जाता है तो code bucket में push होता है और फिर उसी code से नया container build होता है। इसलिए, **नए version के build होने से पहले code को overwrite कर देना संभव है ताकि cloud function arbitrary code execute करे**।

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions**](https://github.com/carlospolop/Monitor-Backdoor-Cloud-Functions)

### App Engine

AppEngine versions कुछ डेटा `staging.<project-id>.appspot.com` नाम के bucket में generate करते हैं। इस bucket के अंदर `ae` नाम का एक फ़ोल्डर मिलता है जिसमें AppEngine app के प्रत्येक version का एक फ़ोल्डर होगा और उन फ़ोल्डर्स के अंदर `manifest.json` फ़ाइल मिलेगी। इस फ़ाइल में उस specific version को बनाने के लिए उपयोग होने वाली सभी फ़ाइलों का JSON होता है। इसके अलावा, यहाँ आप फ़ाइलों के **real names, उनके GCP bucket के अंदर के URLs (बकेट के अंदर फ़ाइलों के नाम उनके sha1 hash में बदल दिए गए हैं) और प्रत्येक फ़ाइल का sha1 hash** भी पा सकते हैं।

_Note that it's not possible to pre-takeover this bucket because GCP users aren't authorized to generate buckets using the domain name appspot.com._

हालाँकि, इस bucket पर read & write access होने पर App Engine version से जुड़े SA को escalate करना संभव है — बस bucket को monitor करके और जब भी कोई change (नया version) होता है, नए version को जितनी जल्दी हो सके modify कर देना। इस तरह, उस code से बन रहा container backdoored code execute करेगा।

यह हमला कई तरीकों से किया जा सकता है, सभी की शुरुआत `staging.<project-id>.appspot.com` bucket की monitoring से होती है:

- AppEngine version का पूरा नया code किसी दूसरे उपलब्ध bucket में upload करें और एक **`manifest.json`** फ़ाइल तैयार रखें जिसमें नए bucket का नाम और उनकी sha1 hashes हों। फिर जब original bucket में नया version बने, आप बस `manifest.json` को modify करके malicious वाला upload कर दें।
- एक modified `requirements.txt` upload करें जो malicious dependencies को उपयोग करेगा और `manifest.json` को नए filename, URL और hash के साथ update कर दें।
- एक modified `main.py` या `app.yaml` upload करें जो malicious code execute करे और `manifest.json` को नए filename, URL और hash के साथ update कर दें।

**You can find a PoC of this attack in the repo:** [**https://github.com/carlospolop/Monitor-Backdoor-AppEngine**](https://github.com/carlospolop/Monitor-Backdoor-AppEngine)

### GCR

- **Google Container Registry** images को buckets में store करता है; अगर आप उन buckets में **write** कर सकते हैं तो आप संभवतः उन जगहों पर **move laterally** कर सकते हैं जहाँ वे buckets run हो रहे हैं।
- GCR जो bucket उपयोग करता है उसका URL कुछ इस तरह होगा: `gs://<eu/usa/asia/nothing>.artifacts.<project>.appspot.com` (Top level subdomains यहाँ specified हैं: [https://cloud.google.com/container-registry/docs/pushing-and-pulling]).

> [!TIP]
> This service is deprecated so this attack is no longer useful. Moreover, Artifact Registry, the service that substitutes this one, does't store the images in buckets.

## **References**

- [https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/#:\~:text=apiKeys.-,create,privileges%20than%20our%20own%20user.](https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/)

{{#include ../../../banners/hacktricks-training.md}}
