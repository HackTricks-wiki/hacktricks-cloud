# GCP -  Dataproc Enum

{{#include ../../../banners/hacktricks-training.md}}

## Informazioni di Base

Google Cloud Dataproc è un servizio completamente gestito per eseguire Apache Spark, Apache Hadoop, Apache Flink e altri framework di big data. È principalmente utilizzato per l'elaborazione dei dati, le query, l'apprendimento automatico e l'analisi in streaming. Dataproc consente alle organizzazioni di creare cluster per il calcolo distribuito con facilità, integrandosi perfettamente con altri servizi di Google Cloud Platform (GCP) come Cloud Storage, BigQuery e Cloud Monitoring.

I cluster Dataproc vengono eseguiti su macchine virtuali (VM), e l'account di servizio associato a queste VM determina i permessi e il livello di accesso del cluster.

## Componenti

Un cluster Dataproc include tipicamente:

Nodo Master: Gestisce le risorse del cluster e coordina i compiti distribuiti.

Nodi Worker: Eseguono i compiti distribuiti.

Account di Servizio: Gestiscono le chiamate API e accedono ad altri servizi GCP.

## Enumerazione

I cluster, i lavori e le configurazioni di Dataproc possono essere enumerati per raccogliere informazioni sensibili, come account di servizio, permessi e potenziali misconfigurazioni.

### Enumerazione del Cluster

Per enumerare i cluster Dataproc e recuperare i loro dettagli:
```
gcloud dataproc clusters list --region=<region>
gcloud dataproc clusters describe <cluster-name> --region=<region>
```
### Enumerazione dei Lavori
```
gcloud dataproc jobs list --region=<region>
gcloud dataproc jobs describe <job-id> --region=<region>
```
### Privesc

{{#ref}}
../gcp-privilege-escalation/gcp-dataproc-privesc.md
{{#endref}}

{{#include ../../../banners/hacktricks-training.md}}
