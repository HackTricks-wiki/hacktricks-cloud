# GCP - Dataproc Enum

{{#include ../../../banners/hacktricks-training.md}}

## Grundlegende Informationen

Google Cloud Dataproc ist ein vollständig verwalteter Dienst zum Ausführen von Apache Spark, Apache Hadoop, Apache Flink und anderen Big-Data-Frameworks. Es wird hauptsächlich für die Datenverarbeitung, Abfragen, maschinelles Lernen und Stream-Analytik verwendet. Dataproc ermöglicht es Organisationen, Cluster für verteiltes Rechnen einfach zu erstellen und nahtlos mit anderen Google Cloud Platform (GCP)-Diensten wie Cloud Storage, BigQuery und Cloud Monitoring zu integrieren.

Dataproc-Cluster laufen auf virtuellen Maschinen (VMs), und das Dienstkonto, das mit diesen VMs verbunden ist, bestimmt die Berechtigungen und den Zugriffslevel des Clusters.

## Komponenten

Ein Dataproc-Cluster umfasst typischerweise:

Master-Knoten: Verwaltet Clusterressourcen und koordiniert verteilte Aufgaben.

Worker-Knoten: Führen verteilte Aufgaben aus.

Dienstkonten: Bearbeiten API-Aufrufe und greifen auf andere GCP-Dienste zu.

## Enumeration

Dataproc-Cluster, Jobs und Konfigurationen können enumeriert werden, um sensible Informationen zu sammeln, wie z.B. Dienstkonten, Berechtigungen und potenzielle Fehlkonfigurationen.

### Cluster-Enumeration

Um Dataproc-Cluster zu enumerieren und deren Details abzurufen:
```
gcloud dataproc clusters list --region=<region>
gcloud dataproc clusters describe <cluster-name> --region=<region>
```
### Job Enumeration
```
gcloud dataproc jobs list --region=<region>
gcloud dataproc jobs describe <job-id> --region=<region>
```
### Privesc

{{#ref}}
../gcp-privilege-escalation/gcp-dataproc-privesc.md
{{#endref}}

{{#include ../../../banners/hacktricks-training.md}}
