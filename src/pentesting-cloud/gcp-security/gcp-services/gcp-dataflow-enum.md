# GCP - Dataflow 열거

{{#include ../../../banners/hacktricks-training.md}}

## 기본 정보

**Google Cloud Dataflow**는 **배치 및 스트리밍 데이터 처리**를 위한 완전관리형 서비스입니다. 조직이 Cloud Storage, BigQuery, Pub/Sub, Bigtable과 통합하여 대규모 데이터를 변환하고 분석하는 파이프라인을 구축할 수 있게 합니다. Dataflow 파이프라인은 프로젝트의 worker VMs에서 실행되며; 템플릿과 User-Defined Functions (UDFs)은 종종 GCS 버킷에 저장됩니다. [Learn more](https://cloud.google.com/dataflow).

## 구성 요소

Dataflow 파이프라인은 일반적으로 다음을 포함합니다:

**Template:** GCS에 저장된 파이프라인 구조와 단계를 정의하는 YAML 또는 JSON 정의(및 flex templates의 경우 Python/Java 코드).

**Launcher (Flex Templates):** 짧게 실행되는 Compute Engine 인스턴스가 Flex Template 실행 시 템플릿을 검증하고 작업 실행 전에 컨테이너를 준비하는 데 사용될 수 있습니다.

**Workers:** 템플릿에서 UDFs와 명령을 가져와 실제 데이터 처리 작업을 수행하는 Compute Engine VM입니다.

**Staging/Temp buckets:** 임시 파이프라인 데이터, 작업 아티팩트, UDF 파일, flex template 메타데이터(`.json`)를 저장하는 GCS 버킷입니다.

## 배치 vs 스트리밍 작업

Dataflow는 두 가지 실행 모드를 지원합니다:

**Batch jobs:** 고정된 유한 데이터셋을 처리합니다(예: 로그 파일, 테이블 내보내기). 작업은 한 번 실행되어 완료되면 종료됩니다. 작업 기간 동안 워커가 생성되고 완료되면 종료됩니다. Batch jobs는 일반적으로 ETL, 과거 분석, 또는 예약된 데이터 마이그레이션에 사용됩니다.

**Streaming jobs:** 무한하고 지속적으로 도착하는 데이터를 처리합니다(예: Pub/Sub 메시지, 실시간 센서 피드). 작업은 명시적으로 중지될 때까지 실행됩니다. 워커는 확장/축소될 수 있으며; autoscaling으로 인해 새로운 워커가 생성될 수 있고, 시작 시 GCS에서 파이프라인 구성요소(templates, UDFs)를 가져옵니다.

## 열거

Dataflow 작업 및 관련 리소스를 열거하여 서비스 계정, 템플릿 경로, 스테이징 버킷, UDF 위치 등을 수집할 수 있습니다.

### 작업 열거

Dataflow 작업을 열거하고 세부 정보를 가져오려면:
```bash
# List Dataflow jobs in the project
gcloud dataflow jobs list
# List Dataflow jobs (by region)
gcloud dataflow jobs list --region=<region>

# Describe job (includes service account, template GCS path, staging location, parameters)
gcloud dataflow jobs describe <job-id> --region=<region>
```
### 템플릿 및 Bucket 열거

작업 설명은 template GCS path, staging location 및 worker service account를 노출합니다—파이프라인 구성 요소를 저장하는 buckets를 식별하는 데 유용합니다.

작업 설명에 참조된 Buckets는 flex templates, UDFs 또는 YAML pipeline definitions을 포함할 수 있습니다:
```bash
# List objects in a bucket (look for .json flex templates, .py UDFs, .yaml pipeline defs)
gcloud storage ls gs://<bucket>/

# List objects recursively
gcloud storage ls gs://<bucket>/**
```
## Privilege Escalation

{{#ref}}
../gcp-privilege-escalation/gcp-dataflow-privesc.md
{{#endref}}

## Post Exploitation

{{#ref}}
../gcp-post-exploitation/gcp-dataflow-post-exploitation.md
{{#endref}}

## Persistence

{{#ref}}
../gcp-persistence/gcp-dataflow-persistence.md
{{#endref}}

## 참고자료

- [Dataflow overview](https://cloud.google.com/dataflow)
- [Pipeline workflow execution in Dataflow](https://cloud.google.com/dataflow/docs/guides/pipeline-workflows)
- [Troubleshoot templates](https://cloud.google.com/dataflow/docs/guides/troubleshoot-templates)

{{#include ../../../banners/hacktricks-training.md}}
