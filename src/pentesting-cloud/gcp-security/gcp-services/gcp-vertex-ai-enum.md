# GCP - Vertex AI Enumeracja

{{#include ../../../banners/hacktricks-training.md}}

## Vertex AI

[Vertex AI](https://cloud.google.com/vertex-ai) jest Google Cloud's **zintegrowaną platformą uczenia maszynowego** do budowania, wdrażania i zarządzania modelami AI na dużą skalę. Łączy różne usługi AI i ML w jednej, zintegrowanej platformie, umożliwiając data scientistom i inżynierom ML:

- **Trenować niestandardowe modele** przy użyciu AutoML lub niestandardowego treningu
- **Wdrażać modele** do skalowalnych punktów końcowych w celu uzyskiwania predykcji
- **Zarządzać cyklem życia ML** od eksperymentów do produkcji
- **Uzyskać dostęp do wstępnie wytrenowanych modeli** z Model Garden
- **Monitorować i optymalizować** wydajność modeli

### Kluczowe komponenty

#### Modele

Vertex AI **modele** reprezentują wytrenowane modele uczenia maszynowego, które można wdrożyć na punktach końcowych do serwowania predykcji. Modele mogą być:

- **Wgrywane** z niestandardowych kontenerów lub artefaktów modelu
- Tworzone przez szkolenie **AutoML**
- Importowane z **Model Garden** (modele wstępnie wytrenowane)
- **Wersjonowane** z wieloma wersjami dla jednego modelu

Każdy model posiada metadane, w tym informacje o frameworku, URI obrazu kontenera, lokalizacji artefaktu oraz konfiguracji serwowania.

#### Punkty końcowe

**Punkty końcowe** to zasoby, które hostują wdrożone modele i obsługują predykcje online. Kluczowe cechy:

- Mogą hostować **wiele wdrożonych modeli** (z dzieleniem ruchu)
- Zapewniają **HTTPS endpoints** dla predykcji w czasie rzeczywistym
- Wspierają **autoskalowanie** w zależności od ruchu
- Mogą używać **prywatnego** lub **publicznego** dostępu
- Wspierają **testy A/B** poprzez dzielenie ruchu

#### Custom Jobs

**Custom jobs** pozwalają uruchamiać niestandardowy kod treningowy używając własnych kontenerów lub pakietów Python. Funkcje obejmują:

- Wsparcie dla **distributed training** z wieloma pulami workerów
- Konfigurowalne **machine types** i **accelerators (GPUs/TPUs)**
- Dołączenie **Service account** do uzyskiwania dostępu do innych zasobów GCP
- Integracja z **Vertex AI Tensorboard** do wizualizacji
- Opcje **VPC connectivity**

#### Hyperparameter Tuning Jobs

Zadania te automatycznie **wyszukują optymalne hiperparametry**, uruchamiając wiele prób treningowych z różnymi kombinacjami parametrów.

#### Model Garden

**Model Garden** zapewnia dostęp do:

- Wstępnie wytrenowanych modeli Google
- Modeli open-source (w tym Hugging Face)
- Modeli firm trzecich
- Możliwości wdrożenia jednym kliknięciem

#### Tensorboards

**Tensorboards** zapewniają wizualizację i monitoring eksperymentów ML, śledząc metryki, grafy modeli i postęp treningu.

### Service Accounts & Permissions

Domyślnie usługi Vertex AI używają **Compute Engine default service account** (`PROJECT_NUMBER-compute@developer.gserviceaccount.com`), które mają uprawnienia **Editor** w projekcie. Jednak można określić niestandardowe service accounts przy:

- Tworzeniu custom jobs
- Wgrywaniu modeli
- Wdrażaniu modeli na punktach końcowych

To konto usługowe jest używane do:
- Dostępu do danych treningowych w Cloud Storage
- Zapisu logów do Cloud Logging
- Dostępu do sekretów z Secret Manager
- Interakcji z innymi usługami GCP

### Przechowywanie danych

- **Artefakty modeli** są przechowywane w bucketach Cloud Storage
- **Dane treningowe** zazwyczaj znajdują się w Cloud Storage lub BigQuery
- **Obrazy kontenerów** są przechowywane w Artifact Registry lub Container Registry
- **Logi** są wysyłane do Cloud Logging
- **Metryki** są wysyłane do Cloud Monitoring

### Szyfrowanie

Domyślnie Vertex AI używa **Google-managed encryption keys**. Możesz również skonfigurować:

- **Customer-managed encryption keys (CMEK)** z Cloud KMS
- Szyfrowanie ma zastosowanie do artefaktów modeli, danych treningowych i punktów końcowych

### Sieć

Zasoby Vertex AI można skonfigurować dla:

- **Publicznego dostępu do internetu** (domyślnie)
- **VPC peering** dla prywatnego dostępu
- **Private Service Connect** dla bezpiecznej łączności
- Wsparcia **Shared VPC**

### Enumeracja
```bash
# List models
gcloud ai models list --region=<region>
gcloud ai models describe <model-id> --region=<region>
gcloud ai models list-version <model-id> --region=<region>

# List endpoints
gcloud ai endpoints list --region=<region>
gcloud ai endpoints describe <endpoint-id> --region=<region>
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# List custom jobs
gcloud ai custom-jobs list --region=<region>
gcloud ai custom-jobs describe <job-id> --region=<region>

# Stream logs from a running job
gcloud ai custom-jobs stream-logs <job-id> --region=<region>

# List hyperparameter tuning jobs
gcloud ai hp-tuning-jobs list --region=<region>
gcloud ai hp-tuning-jobs describe <job-id> --region=<region>

# List model monitoring jobs
gcloud ai model-monitoring-jobs list --region=<region>
gcloud ai model-monitoring-jobs describe <job-id> --region=<region>

# List Tensorboards
gcloud ai tensorboards list --region=<region>
gcloud ai tensorboards describe <tensorboard-id> --region=<region>

# List indexes (for vector search)
gcloud ai indexes list --region=<region>
gcloud ai indexes describe <index-id> --region=<region>

# List index endpoints
gcloud ai index-endpoints list --region=<region>
gcloud ai index-endpoints describe <index-endpoint-id> --region=<region>

# Get operations (long-running operations status)
gcloud ai operations describe <operation-id> --region=<region>

# Test endpoint predictions (if you have access)
gcloud ai endpoints predict <endpoint-id> \
--region=<region> \
--json-request=request.json

# Make direct predictions (newer API)
gcloud ai endpoints direct-predict <endpoint-id> \
--region=<region> \
--json-request=request.json
```
### Zbieranie informacji o modelu
```bash
# Get detailed model information including versions
gcloud ai models describe <model-id> --region=<region>

# Check specific model version
gcloud ai models describe <model-id>@<version> --region=<region>

# List all versions of a model
gcloud ai models list-version <model-id> --region=<region>

# Get model artifact location (usually a GCS bucket)
gcloud ai models describe <model-id> --region=<region> --format="value(artifactUri)"

# Get container image URI
gcloud ai models describe <model-id> --region=<region> --format="value(containerSpec.imageUri)"
```
### Szczegóły punktu końcowego
```bash
# Get endpoint details including deployed models
gcloud ai endpoints describe <endpoint-id> --region=<region>

# Get endpoint URL
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].displayName)"

# Get service account used by endpoint
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].serviceAccount)"

# Check traffic split between models
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(trafficSplit)"
```
### Informacje o Custom Job
```bash
# Get job details including command, args, and service account
gcloud ai custom-jobs describe <job-id> --region=<region>

# Get service account used by job
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].serviceAccount)"

# Get container image used
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.imageUri)"

# Check environment variables (may contain secrets)
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.env)"

# Get network configuration
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.network)"
```
### Kontrola dostępu
```bash
# Note: IAM policies for individual Vertex AI resources are managed at the project level
# Check project-level permissions
gcloud projects get-iam-policy <project-id>

# Check service account permissions
gcloud iam service-accounts get-iam-policy <service-account-email>

# Check if endpoints allow unauthenticated access
# This is controlled by IAM bindings on the endpoint
gcloud projects get-iam-policy <project-id> \
--flatten="bindings[].members" \
--filter="bindings.role:aiplatform.user"
```
### Przechowywanie i Artefakty
```bash
# Models and training jobs often store artifacts in GCS
# List buckets that might contain model artifacts
gsutil ls

# Common artifact locations:
# gs://<project>-aiplatform-<region>/
# gs://<project>-vertex-ai/
# gs://<custom-bucket>/vertex-ai/

# Download model artifacts if accessible
gsutil -m cp -r gs://<bucket>/path/to/artifacts ./artifacts/

# Check for notebooks in AI Platform Notebooks
gcloud notebooks instances list --location=<location>
gcloud notebooks instances describe <instance-name> --location=<location>
```
### Model Garden
```bash
# List Model Garden endpoints
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# Model Garden models are often deployed with default configurations
# Check for publicly accessible endpoints
```
### Eskalacja uprawnień

Na poniższej stronie możesz sprawdzić, jak **nadużyć uprawnień Vertex AI, aby uzyskać wyższe uprawnienia**:

{{#ref}}
../gcp-privilege-escalation/gcp-vertex-ai-privesc.md
{{#endref}}

## Źródła

- [https://cloud.google.com/vertex-ai/docs](https://cloud.google.com/vertex-ai/docs)
- [https://cloud.google.com/vertex-ai/docs/reference/rest](https://cloud.google.com/vertex-ai/docs/reference/rest)

{{#include ../../../banners/hacktricks-training.md}}
