# GCP - Vertex AI Enumeración

{{#include ../../../banners/hacktricks-training.md}}

## Vertex AI

[Vertex AI](https://cloud.google.com/vertex-ai) es la **plataforma unificada de machine learning** de Google Cloud para construir, desplegar y gestionar modelos de IA a escala. Combina varios servicios de AI y ML en una única plataforma integrada, permitiendo a data scientists y ML engineers:

- **Entrenar modelos personalizados** usando AutoML o entrenamiento custom
- **Desplegar modelos** a endpoints escalables para predicciones
- **Gestionar el ciclo de vida de ML** desde la experimentación hasta producción
- **Acceder a modelos pre-entrenados** desde Model Garden
- **Supervisar y optimizar** el rendimiento de los modelos

### Componentes clave

#### Models

Los **models** de Vertex AI representan modelos de machine learning entrenados que pueden desplegarse en endpoints para servir predicciones. Los modelos pueden ser:

- **Subidos** desde contenedores personalizados o artefactos de modelo
- Creados mediante **AutoML** training
- Importados desde **Model Garden** (modelos pre-entrenados)
- **Versionados** con múltiples versiones por modelo

Cada modelo tiene metadata que incluye su framework, URI de la imagen del contenedor, ubicación del artefacto y configuración de serving.

#### Endpoints

Los **endpoints** son recursos que alojan modelos desplegados y sirven predicciones en línea. Características principales:

- Pueden alojar **múltiples modelos desplegados** (con traffic splitting)
- Proporcionan **endpoints HTTPS** para predicciones en tiempo real
- Soportan **autoscaling** basado en el tráfico
- Pueden usar acceso **privado** o **público**
- Soportan **A/B testing** mediante traffic splitting

#### Custom Jobs

Los **custom jobs** permiten ejecutar código de entrenamiento personalizado usando tus propios contenedores o paquetes Python. Características incluyen:

- Soporte para **distributed training** con múltiples worker pools
- Tipos de máquina y aceleradores (GPUs/TPUs) configurables
- Asociación de **service account** para acceder a otros recursos de GCP
- Integración con **Vertex AI Tensorboard** para visualización
- Opciones de **VPC connectivity**

#### Hyperparameter Tuning Jobs

Estas jobs buscan automáticamente los **hiperparámetros óptimos** ejecutando múltiples trials de entrenamiento con diferentes combinaciones de parámetros.

#### Model Garden

**Model Garden** proporciona acceso a:

- Modelos pre-entrenados de Google
- Modelos open-source (incluyendo Hugging Face)
- Modelos de terceros
- Capacidades de despliegue con un solo click

#### Tensorboards

Los **Tensorboards** ofrecen visualización y monitoreo para experimentos de ML, rastreando métricas, gráficos de modelos y progreso de entrenamiento.

### Service Accounts & Permissions

Por defecto, los servicios de Vertex AI usan la **Compute Engine default service account** (`PROJECT_NUMBER-compute@developer.gserviceaccount.com`), que tiene permisos de **Editor** en el proyecto. Sin embargo, puedes especificar cuentas de servicio personalizadas cuando:

- Creas custom jobs
- Subes modelos
- Despliegas modelos a endpoints

Esta cuenta de servicio se usa para:
- Acceder a datos de entrenamiento en Cloud Storage
- Escribir logs en Cloud Logging
- Acceder a secretos desde Secret Manager
- Interactuar con otros servicios de GCP

### Data Storage

- Los **model artifacts** se almacenan en buckets de **Cloud Storage**
- Los **datos de entrenamiento** típicamente residen en Cloud Storage o BigQuery
- Las **imágenes de contenedor** se almacenan en **Artifact Registry** o Container Registry
- Los **logs** se envían a **Cloud Logging**
- Las **métricas** se envían a **Cloud Monitoring**

### Encryption

Por defecto, Vertex AI usa **Google-managed encryption keys**. También puedes configurar:

- **Customer-managed encryption keys (CMEK)** desde Cloud KMS
- La encriptación aplica a artefactos de modelo, datos de entrenamiento y endpoints

### Networking

Los recursos de Vertex AI pueden configurarse para:

- **Acceso público a internet** (por defecto)
- **VPC peering** para acceso privado
- **Private Service Connect** para conectividad segura
- Soporte de **Shared VPC**

### Enumeration
```bash
# List models
gcloud ai models list --region=<region>
gcloud ai models describe <model-id> --region=<region>
gcloud ai models list-version <model-id> --region=<region>

# List endpoints
gcloud ai endpoints list --region=<region>
gcloud ai endpoints describe <endpoint-id> --region=<region>
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# List custom jobs
gcloud ai custom-jobs list --region=<region>
gcloud ai custom-jobs describe <job-id> --region=<region>

# Stream logs from a running job
gcloud ai custom-jobs stream-logs <job-id> --region=<region>

# List hyperparameter tuning jobs
gcloud ai hp-tuning-jobs list --region=<region>
gcloud ai hp-tuning-jobs describe <job-id> --region=<region>

# List model monitoring jobs
gcloud ai model-monitoring-jobs list --region=<region>
gcloud ai model-monitoring-jobs describe <job-id> --region=<region>

# List Tensorboards
gcloud ai tensorboards list --region=<region>
gcloud ai tensorboards describe <tensorboard-id> --region=<region>

# List indexes (for vector search)
gcloud ai indexes list --region=<region>
gcloud ai indexes describe <index-id> --region=<region>

# List index endpoints
gcloud ai index-endpoints list --region=<region>
gcloud ai index-endpoints describe <index-endpoint-id> --region=<region>

# Get operations (long-running operations status)
gcloud ai operations describe <operation-id> --region=<region>

# Test endpoint predictions (if you have access)
gcloud ai endpoints predict <endpoint-id> \
--region=<region> \
--json-request=request.json

# Make direct predictions (newer API)
gcloud ai endpoints direct-predict <endpoint-id> \
--region=<region> \
--json-request=request.json
```
### Recopilación de información del modelo
```bash
# Get detailed model information including versions
gcloud ai models describe <model-id> --region=<region>

# Check specific model version
gcloud ai models describe <model-id>@<version> --region=<region>

# List all versions of a model
gcloud ai models list-version <model-id> --region=<region>

# Get model artifact location (usually a GCS bucket)
gcloud ai models describe <model-id> --region=<region> --format="value(artifactUri)"

# Get container image URI
gcloud ai models describe <model-id> --region=<region> --format="value(containerSpec.imageUri)"
```
### Detalles del Endpoint
```bash
# Get endpoint details including deployed models
gcloud ai endpoints describe <endpoint-id> --region=<region>

# Get endpoint URL
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].displayName)"

# Get service account used by endpoint
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].serviceAccount)"

# Check traffic split between models
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(trafficSplit)"
```
### Información del trabajo personalizado
```bash
# Get job details including command, args, and service account
gcloud ai custom-jobs describe <job-id> --region=<region>

# Get service account used by job
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].serviceAccount)"

# Get container image used
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.imageUri)"

# Check environment variables (may contain secrets)
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.env)"

# Get network configuration
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.network)"
```
### Control de acceso
```bash
# Note: IAM policies for individual Vertex AI resources are managed at the project level
# Check project-level permissions
gcloud projects get-iam-policy <project-id>

# Check service account permissions
gcloud iam service-accounts get-iam-policy <service-account-email>

# Check if endpoints allow unauthenticated access
# This is controlled by IAM bindings on the endpoint
gcloud projects get-iam-policy <project-id> \
--flatten="bindings[].members" \
--filter="bindings.role:aiplatform.user"
```
### Almacenamiento y artefactos
```bash
# Models and training jobs often store artifacts in GCS
# List buckets that might contain model artifacts
gsutil ls

# Common artifact locations:
# gs://<project>-aiplatform-<region>/
# gs://<project>-vertex-ai/
# gs://<custom-bucket>/vertex-ai/

# Download model artifacts if accessible
gsutil -m cp -r gs://<bucket>/path/to/artifacts ./artifacts/

# Check for notebooks in AI Platform Notebooks
gcloud notebooks instances list --location=<location>
gcloud notebooks instances describe <instance-name> --location=<location>
```
### Model Garden
```bash
# List Model Garden endpoints
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# Model Garden models are often deployed with default configurations
# Check for publicly accessible endpoints
```
### Escalada de privilegios

En la página siguiente puedes ver cómo **abusar de los permisos de Vertex AI para escalar privilegios**:

{{#ref}}
../gcp-privilege-escalation/gcp-vertex-ai-privesc.md
{{#endref}}

## Referencias

- [https://cloud.google.com/vertex-ai/docs](https://cloud.google.com/vertex-ai/docs)
- [https://cloud.google.com/vertex-ai/docs/reference/rest](https://cloud.google.com/vertex-ai/docs/reference/rest)

{{#include ../../../banners/hacktricks-training.md}}
