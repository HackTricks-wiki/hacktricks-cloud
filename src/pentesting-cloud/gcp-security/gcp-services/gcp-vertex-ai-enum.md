# GCP - Vertex AI 列挙

{{#include ../../../banners/hacktricks-training.md}}

## Vertex AI

[Vertex AI](https://cloud.google.com/vertex-ai) は Google Cloud の **統合された機械学習プラットフォーム**で、AIモデルの構築、デプロイ、管理を大規模に行うためのサービスです。データサイエンティストやMLエンジニアが以下を行えるようにします：

- **カスタムモデルの学習**（AutoML またはカスタムトレーニングを使用）
- **モデルのデプロイ**して予測のためのスケーラブルなエンドポイントを提供
- **実験から本番までのMLライフサイクルの管理**
- **Model Garden からの事前学習済みモデルへのアクセス**
- **モデルの監視と最適化**

### 主要コンポーネント

#### モデル

Vertex AI の **モデル** は、予測提供のためにエンドポイントへデプロイできる学習済み機械学習モデルを表します。モデルは以下の方法で扱えます：

- カスタムコンテナやモデルアーティファクトから **アップロード**
- **AutoML** による作成
- **Model Garden**（事前学習済みモデル）からのインポート
- モデルごとに複数の **バージョン管理**

各モデルには、フレームワーク、コンテナイメージURI、アーティファクトの場所、サービング構成などのメタデータがあります。

#### エンドポイント

**Endpoints** はデプロイされたモデルをホスティングし、オンライン予測を提供するリソースです。主な機能：

- **複数のデプロイ済みモデル**をホスト可能（トラフィックスプリッティング対応）
- リアルタイム予測のための **HTTPS エンドポイント** を提供
- トラフィックに応じた **オートスケーリング** をサポート
- **プライベート**または**パブリック**アクセスの利用可
- トラフィックスプリッティングによる **A/B テスト** をサポート

#### Custom Jobs

**Custom jobs** は独自のコンテナやPythonパッケージを使ってカスタムトレーニングコードを実行するための機能です。主な特徴：

- **複数のワーカープールによる分散トレーニング**をサポート
- 設定可能な **machine types** や **accelerators**（GPU/TPU）
- 他のGCPリソースにアクセスするための **service account** 添付
- 可視化のための **Vertex AI Tensorboard** との統合
- **VPC 接続** オプション

#### Hyperparameter Tuning Jobs

これらのジョブは、異なるパラメータ組み合わせで複数のトレーニング試行を実行して、最適なハイパーパラメータを自動で探索します。

#### Model Garden

**Model Garden** は以下へのアクセスを提供します：

- Google の事前学習済みモデル
- オープンソースモデル（Hugging Face を含む）
- サードパーティ製モデル
- ワンクリックデプロイ機能

#### Tensorboards

**Tensorboards** はML実験の可視化と監視を提供し、メトリクス、モデルグラフ、トレーニング進捗を追跡します。

### サービスアカウントと権限

デフォルトでは、Vertex AI サービスは **Compute Engine default service account**（`PROJECT_NUMBER-compute@developer.gserviceaccount.com`）を使用し、プロジェクトに対して **Editor** 権限を持ちます。ただし、次のような場合にカスタムサービスアカウントを指定できます：

- Custom jobs 作成時
- モデルのアップロード時
- モデルをエンドポイントにデプロイする際

このサービスアカウントは以下のために使用されます：
- Cloud Storage 内のトレーニングデータへのアクセス
- Cloud Logging へのログ書き込み
- Secret Manager からのシークレットアクセス
- 他の GCP サービスとの連携

### データの保存

- **モデルアーティファクト** は **Cloud Storage** バケットに保存されます
- **トレーニングデータ** は通常 Cloud Storage や BigQuery に保存されます
- **コンテナイメージ** は **Artifact Registry** または Container Registry に保存されます
- **ログ** は **Cloud Logging** に送られます
- **メトリクス** は **Cloud Monitoring** に送られます

### 暗号化

デフォルトでは、Vertex AI は **Google-managed encryption keys** を使用します。以下の構成も可能です：

- Cloud KMS による **Customer-managed encryption keys (CMEK)**
- 暗号化はモデルアーティファクト、トレーニングデータ、エンドポイントに適用されます

### ネットワーキング

Vertex AI リソースは以下のように設定できます：

- **パブリックインターネットアクセス**（デフォルト）
- **VPC peering** によるプライベートアクセス
- **Private Service Connect** によるセキュアな接続
- **Shared VPC** サポート

### 列挙
```bash
# List models
gcloud ai models list --region=<region>
gcloud ai models describe <model-id> --region=<region>
gcloud ai models list-version <model-id> --region=<region>

# List endpoints
gcloud ai endpoints list --region=<region>
gcloud ai endpoints describe <endpoint-id> --region=<region>
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# List custom jobs
gcloud ai custom-jobs list --region=<region>
gcloud ai custom-jobs describe <job-id> --region=<region>

# Stream logs from a running job
gcloud ai custom-jobs stream-logs <job-id> --region=<region>

# List hyperparameter tuning jobs
gcloud ai hp-tuning-jobs list --region=<region>
gcloud ai hp-tuning-jobs describe <job-id> --region=<region>

# List model monitoring jobs
gcloud ai model-monitoring-jobs list --region=<region>
gcloud ai model-monitoring-jobs describe <job-id> --region=<region>

# List Tensorboards
gcloud ai tensorboards list --region=<region>
gcloud ai tensorboards describe <tensorboard-id> --region=<region>

# List indexes (for vector search)
gcloud ai indexes list --region=<region>
gcloud ai indexes describe <index-id> --region=<region>

# List index endpoints
gcloud ai index-endpoints list --region=<region>
gcloud ai index-endpoints describe <index-endpoint-id> --region=<region>

# Get operations (long-running operations status)
gcloud ai operations describe <operation-id> --region=<region>

# Test endpoint predictions (if you have access)
gcloud ai endpoints predict <endpoint-id> \
--region=<region> \
--json-request=request.json

# Make direct predictions (newer API)
gcloud ai endpoints direct-predict <endpoint-id> \
--region=<region> \
--json-request=request.json
```
### モデル情報収集
```bash
# Get detailed model information including versions
gcloud ai models describe <model-id> --region=<region>

# Check specific model version
gcloud ai models describe <model-id>@<version> --region=<region>

# List all versions of a model
gcloud ai models list-version <model-id> --region=<region>

# Get model artifact location (usually a GCS bucket)
gcloud ai models describe <model-id> --region=<region> --format="value(artifactUri)"

# Get container image URI
gcloud ai models describe <model-id> --region=<region> --format="value(containerSpec.imageUri)"
```
### エンドポイントの詳細
```bash
# Get endpoint details including deployed models
gcloud ai endpoints describe <endpoint-id> --region=<region>

# Get endpoint URL
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].displayName)"

# Get service account used by endpoint
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].serviceAccount)"

# Check traffic split between models
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(trafficSplit)"
```
### カスタムジョブ情報
```bash
# Get job details including command, args, and service account
gcloud ai custom-jobs describe <job-id> --region=<region>

# Get service account used by job
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].serviceAccount)"

# Get container image used
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.imageUri)"

# Check environment variables (may contain secrets)
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.env)"

# Get network configuration
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.network)"
```
### アクセス制御
```bash
# Note: IAM policies for individual Vertex AI resources are managed at the project level
# Check project-level permissions
gcloud projects get-iam-policy <project-id>

# Check service account permissions
gcloud iam service-accounts get-iam-policy <service-account-email>

# Check if endpoints allow unauthenticated access
# This is controlled by IAM bindings on the endpoint
gcloud projects get-iam-policy <project-id> \
--flatten="bindings[].members" \
--filter="bindings.role:aiplatform.user"
```
### ストレージとアーティファクト
```bash
# Models and training jobs often store artifacts in GCS
# List buckets that might contain model artifacts
gsutil ls

# Common artifact locations:
# gs://<project>-aiplatform-<region>/
# gs://<project>-vertex-ai/
# gs://<custom-bucket>/vertex-ai/

# Download model artifacts if accessible
gsutil -m cp -r gs://<bucket>/path/to/artifacts ./artifacts/

# Check for notebooks in AI Platform Notebooks
gcloud notebooks instances list --location=<location>
gcloud notebooks instances describe <instance-name> --location=<location>
```
### モデルガーデン
```bash
# List Model Garden endpoints
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# Model Garden models are often deployed with default configurations
# Check for publicly accessible endpoints
```
### Privilege Escalation

次のページで、**abuse Vertex AI permissions to escalate privileges** の方法を確認できます:

{{#ref}}
../gcp-privilege-escalation/gcp-vertex-ai-privesc.md
{{#endref}}

## 参考

- [https://cloud.google.com/vertex-ai/docs](https://cloud.google.com/vertex-ai/docs)
- [https://cloud.google.com/vertex-ai/docs/reference/rest](https://cloud.google.com/vertex-ai/docs/reference/rest)

{{#include ../../../banners/hacktricks-training.md}}
