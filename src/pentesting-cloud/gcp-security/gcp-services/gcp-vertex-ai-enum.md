# GCP - Vertex AI 열거

{{#include ../../../banners/hacktricks-training.md}}

## Vertex AI

[Vertex AI](https://cloud.google.com/vertex-ai)는 대규모로 AI 모델을 빌드, 배포 및 관리하기 위한 Google Cloud의 **통합 머신러닝 플랫폼**입니다. 다양한 AI 및 ML 서비스를 단일 통합 플랫폼으로 결합하여 데이터 과학자와 ML 엔지니어가 다음을 수행할 수 있게 합니다:

- **AutoML** 또는 커스텀 트레이닝을 사용하여 **맞춤형 모델을 학습**
- 예측을 위해 **모델을 엔드포인트에 배포**
- 실험부터 운영까지 **ML 수명주기 관리**
- **Model Garden**의 사전 학습된 모델에 접근
- 모델 성능을 **모니터링 및 최적화**

### 핵심 구성요소

#### Models

Vertex AI의 **models**는 예측을 제공하기 위해 엔드포인트에 배포할 수 있는 학습된 머신러닝 모델을 나타냅니다. 모델은 다음과 같을 수 있습니다:

- 커스텀 컨테이너 또는 모델 아티팩트에서 **업로드**
- **AutoML** 트레이닝을 통해 생성
- **Model Garden**(사전 학습된 모델)에서 가져오기
- 모델당 여러 버전으로 **버전 관리**

각 모델은 프레임워크, 컨테이너 이미지 URI, 아티팩트 위치, 서빙 구성 등 메타데이터를 가집니다.

#### Endpoints

**Endpoints**는 배포된 모델을 호스팅하고 온라인 예측을 제공하는 리소스입니다. 주요 기능:

- **여러 배포된 모델** 호스팅 가능(트래픽 분할 지원)
- 실시간 예측을 위한 **HTTPS 엔드포인트** 제공
- 트래픽 기반 **오토스케일링** 지원
- **Public** 또는 **Private** 접근 가능
- 트래픽 분할을 통한 **A/B 테스트** 지원

#### Custom Jobs

**Custom jobs**는 자체 컨테이너나 Python 패키지를 사용하여 커스텀 트레이닝 코드를 실행할 수 있게 합니다. 기능:

- 여러 워커 풀을 사용한 **분산 학습** 지원
- 구성 가능한 **머신 타입** 및 **가속기**(GPUs/TPUs)
- 다른 GCP 리소스에 접근하기 위한 **서비스 계정** 연결
- 시각화를 위한 **Vertex AI Tensorboard** 통합
- **VPC 연결** 옵션

#### Hyperparameter Tuning Jobs

이 작업들은 서로 다른 매개변수 조합으로 여러 트레이닝 실험을 실행하여 **최적의 하이퍼파라미터를 자동으로 탐색**합니다.

#### Model Garden

**Model Garden**은 다음에 대한 접근을 제공합니다:

- 구글의 사전 학습된 모델
- Hugging Face를 포함한 오픈 소스 모델
- 타사 모델
- 원클릭 배포 기능

#### Tensorboards

**Tensorboards**는 ML 실험에 대한 시각화 및 모니터링을 제공하며, 지표, 모델 그래프 및 학습 진행 상황을 추적합니다.

### 서비스 계정 및 권한

기본적으로 Vertex AI 서비스는 프로젝트에 대해 **Editor** 권한이 있는 **Compute Engine default service account**(`PROJECT_NUMBER-compute@developer.gserviceaccount.com`)를 사용합니다. 그러나 다음과 같은 경우 커스텀 서비스 계정을 지정할 수 있습니다:

- custom jobs 생성 시
- 모델 업로드 시
- 모델을 endpoints에 배포할 때

이 서비스 계정은 다음에 사용됩니다:
- Cloud Storage에 있는 학습 데이터 접근
- Cloud Logging에 로그 작성
- Secret Manager에서 시크릿 접근
- 다른 GCP 서비스와 상호작용

### 데이터 저장

- **모델 아티팩트**는 **Cloud Storage** 버킷에 저장
- **학습 데이터**는 일반적으로 Cloud Storage 또는 BigQuery에 저장
- **컨테이너 이미지**는 **Artifact Registry** 또는 Container Registry에 저장
- **로그**는 **Cloud Logging**으로 전송
- **메트릭**은 **Cloud Monitoring**으로 전송

### 암호화

기본적으로 Vertex AI는 **Google-managed encryption keys**를 사용합니다. 또한 구성할 수 있습니다:

- Cloud KMS의 **Customer-managed encryption keys (CMEK)**
- 암호화는 모델 아티팩트, 학습 데이터 및 엔드포인트에 적용

### 네트워킹

Vertex AI 리소스는 다음과 같이 구성할 수 있습니다:

- **Public internet access**(기본)
- **VPC peering**을 통한 프라이빗 접근
- **Private Service Connect**를 통한 보안 연결
- **Shared VPC** 지원

### 열거
```bash
# List models
gcloud ai models list --region=<region>
gcloud ai models describe <model-id> --region=<region>
gcloud ai models list-version <model-id> --region=<region>

# List endpoints
gcloud ai endpoints list --region=<region>
gcloud ai endpoints describe <endpoint-id> --region=<region>
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# List custom jobs
gcloud ai custom-jobs list --region=<region>
gcloud ai custom-jobs describe <job-id> --region=<region>

# Stream logs from a running job
gcloud ai custom-jobs stream-logs <job-id> --region=<region>

# List hyperparameter tuning jobs
gcloud ai hp-tuning-jobs list --region=<region>
gcloud ai hp-tuning-jobs describe <job-id> --region=<region>

# List model monitoring jobs
gcloud ai model-monitoring-jobs list --region=<region>
gcloud ai model-monitoring-jobs describe <job-id> --region=<region>

# List Tensorboards
gcloud ai tensorboards list --region=<region>
gcloud ai tensorboards describe <tensorboard-id> --region=<region>

# List indexes (for vector search)
gcloud ai indexes list --region=<region>
gcloud ai indexes describe <index-id> --region=<region>

# List index endpoints
gcloud ai index-endpoints list --region=<region>
gcloud ai index-endpoints describe <index-endpoint-id> --region=<region>

# Get operations (long-running operations status)
gcloud ai operations describe <operation-id> --region=<region>

# Test endpoint predictions (if you have access)
gcloud ai endpoints predict <endpoint-id> \
--region=<region> \
--json-request=request.json

# Make direct predictions (newer API)
gcloud ai endpoints direct-predict <endpoint-id> \
--region=<region> \
--json-request=request.json
```
### 모델 정보 수집
```bash
# Get detailed model information including versions
gcloud ai models describe <model-id> --region=<region>

# Check specific model version
gcloud ai models describe <model-id>@<version> --region=<region>

# List all versions of a model
gcloud ai models list-version <model-id> --region=<region>

# Get model artifact location (usually a GCS bucket)
gcloud ai models describe <model-id> --region=<region> --format="value(artifactUri)"

# Get container image URI
gcloud ai models describe <model-id> --region=<region> --format="value(containerSpec.imageUri)"
```
### 엔드포인트 세부정보
```bash
# Get endpoint details including deployed models
gcloud ai endpoints describe <endpoint-id> --region=<region>

# Get endpoint URL
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].displayName)"

# Get service account used by endpoint
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].serviceAccount)"

# Check traffic split between models
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(trafficSplit)"
```
### 사용자 지정 작업 정보
```bash
# Get job details including command, args, and service account
gcloud ai custom-jobs describe <job-id> --region=<region>

# Get service account used by job
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].serviceAccount)"

# Get container image used
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.imageUri)"

# Check environment variables (may contain secrets)
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.env)"

# Get network configuration
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.network)"
```
### 액세스 제어
```bash
# Note: IAM policies for individual Vertex AI resources are managed at the project level
# Check project-level permissions
gcloud projects get-iam-policy <project-id>

# Check service account permissions
gcloud iam service-accounts get-iam-policy <service-account-email>

# Check if endpoints allow unauthenticated access
# This is controlled by IAM bindings on the endpoint
gcloud projects get-iam-policy <project-id> \
--flatten="bindings[].members" \
--filter="bindings.role:aiplatform.user"
```
### 저장소 및 아티팩트
```bash
# Models and training jobs often store artifacts in GCS
# List buckets that might contain model artifacts
gsutil ls

# Common artifact locations:
# gs://<project>-aiplatform-<region>/
# gs://<project>-vertex-ai/
# gs://<custom-bucket>/vertex-ai/

# Download model artifacts if accessible
gsutil -m cp -r gs://<bucket>/path/to/artifacts ./artifacts/

# Check for notebooks in AI Platform Notebooks
gcloud notebooks instances list --location=<location>
gcloud notebooks instances describe <instance-name> --location=<location>
```
### Model Garden
```bash
# List Model Garden endpoints
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# Model Garden models are often deployed with default configurations
# Check for publicly accessible endpoints
```
### Privilege Escalation

다음 페이지에서 **abuse Vertex AI permissions to escalate privileges** 방법을 확인할 수 있습니다:

{{#ref}}
../gcp-privilege-escalation/gcp-vertex-ai-privesc.md
{{#endref}}

## 참고자료

- [https://cloud.google.com/vertex-ai/docs](https://cloud.google.com/vertex-ai/docs)
- [https://cloud.google.com/vertex-ai/docs/reference/rest](https://cloud.google.com/vertex-ai/docs/reference/rest)

{{#include ../../../banners/hacktricks-training.md}}
