# GCP - Vertex AI Enum

{{#include ../../../banners/hacktricks-training.md}}

## Vertex AI

[Vertex AI](https://cloud.google.com/vertex-ai) is Google Cloud se geïntegreerde masjienleer-platform vir die bou, ontplooiing en bestuur van AI-modelle op skaal. Dit kombineer verskeie AI- en ML-dienste in een geïntegreerde platform, wat datascientists en ML-ingenieurs in staat stel om:

- Oplei aangepaste modelle met AutoML of custom training
- Ontplooi modelle na skaalbare endpoints vir voorspellings
- Bestuur die ML-levensiklus van eksperimentering tot produksie
- Verkry toegang tot pre-trained models uit Model Garden
- Monitor en optimaliseer modelprestasie

### Key Components

#### Models

Vertex AI models verteenwoordig opgelei masjienleer-modelle wat na endpoints ontplooi kan word vir die dien van voorspellings. Modelle kan wees:

- Uploaded vanaf custom containers of model artifacts
- Gemaak deur AutoML training
- Geïmporteer vanaf Model Garden (pre-trained models)
- Versioned met meerdere weergawes per model

Elke model het metadata insluitend sy framework, container image URI, artifact location, en serving configuration.

#### Endpoints

Endpoints is hulpbronne wat ontplooide models huisves en online voorspellings bedien. Sleutelfunksies:

- Kan meerdere deployed models huisves (met traffic splitting)
- Verskaf HTTPS endpoints vir real-time voorspellings
- Ondersteun autoscaling gebaseer op verkeer
- Kan private of public toegang gebruik
- Ondersteun A/B testing deur traffic splitting

#### Custom Jobs

Custom jobs laat jou toe om custom training kode te laat loop met jou eie containers of Python-pakkette. Kenmerke sluit in:

- Ondersteuning vir distributed training met meerdere worker pools
- Konfigureerbare machine types en accelerators (GPUs/TPUs)
- Service account attachment vir toegang tot ander GCP-resources
- Integrasie met Vertex AI Tensorboard vir visualisering
- VPC connectivity opsies

#### Hyperparameter Tuning Jobs

Hierdie jobs soek outomaties vir optimale hyperparameters deur meerdere training trials met verskillende parameterkombinasies te hardloop.

#### Model Garden

Model Garden bied toegang tot:

- Pre-trained Google models
- Open-source models (insluitend Hugging Face)
- Third-party models
- Een-kliek ontplooiingsvermoëns

#### Tensorboards

Tensorboards bied visualisering en monitoring vir ML-eksperimente, wat metrics, model graphs en training progress opspoor.

### Service Accounts & Permissions

By verstek gebruik Vertex AI-dienste die Compute Engine default service account (`PROJECT_NUMBER-compute@developer.gserviceaccount.com`), wat Editor-permissies op die projek het. Jy kan egter custom service accounts spesifiseer wanneer:

- Custom jobs geskep word
- Modelle geupload word
- Modelle na endpoints ontplooi word

Hierdie service account word gebruik om:
- Toegang tot training data in Cloud Storage te kry
- Logs na Cloud Logging te skryf
- Toegang tot secrets vanaf Secret Manager te kry
- Interaksie met ander GCP-dienste te hê

### Data Storage

- Model artifacts word gestoor in Cloud Storage buckets
- Training data woon gewoonlik in Cloud Storage of BigQuery
- Container images word gestoor in Artifact Registry of Container Registry
- Logs word na Cloud Logging gestuur
- Metrics word na Cloud Monitoring gestuur

### Encryption

By verstek gebruik Vertex AI Google-managed encryption keys. Jy kan ook konfigureer:

- Customer-managed encryption keys (CMEK) vanaf Cloud KMS
- Encryption geld vir model artifacts, training data, en endpoints

### Networking

Vertex AI-hulpbronne kan gekonfigureer word vir:

- Public internet access (verstek)
- VPC peering vir private toegang
- Private Service Connect vir veilige konnektiwiteit
- Shared VPC ondersteuning

### Enumeration
```bash
# List models
gcloud ai models list --region=<region>
gcloud ai models describe <model-id> --region=<region>
gcloud ai models list-version <model-id> --region=<region>

# List endpoints
gcloud ai endpoints list --region=<region>
gcloud ai endpoints describe <endpoint-id> --region=<region>
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# List custom jobs
gcloud ai custom-jobs list --region=<region>
gcloud ai custom-jobs describe <job-id> --region=<region>

# Stream logs from a running job
gcloud ai custom-jobs stream-logs <job-id> --region=<region>

# List hyperparameter tuning jobs
gcloud ai hp-tuning-jobs list --region=<region>
gcloud ai hp-tuning-jobs describe <job-id> --region=<region>

# List model monitoring jobs
gcloud ai model-monitoring-jobs list --region=<region>
gcloud ai model-monitoring-jobs describe <job-id> --region=<region>

# List Tensorboards
gcloud ai tensorboards list --region=<region>
gcloud ai tensorboards describe <tensorboard-id> --region=<region>

# List indexes (for vector search)
gcloud ai indexes list --region=<region>
gcloud ai indexes describe <index-id> --region=<region>

# List index endpoints
gcloud ai index-endpoints list --region=<region>
gcloud ai index-endpoints describe <index-endpoint-id> --region=<region>

# Get operations (long-running operations status)
gcloud ai operations describe <operation-id> --region=<region>

# Test endpoint predictions (if you have access)
gcloud ai endpoints predict <endpoint-id> \
--region=<region> \
--json-request=request.json

# Make direct predictions (newer API)
gcloud ai endpoints direct-predict <endpoint-id> \
--region=<region> \
--json-request=request.json
```
### Modelinligtinginsameling
```bash
# Get detailed model information including versions
gcloud ai models describe <model-id> --region=<region>

# Check specific model version
gcloud ai models describe <model-id>@<version> --region=<region>

# List all versions of a model
gcloud ai models list-version <model-id> --region=<region>

# Get model artifact location (usually a GCS bucket)
gcloud ai models describe <model-id> --region=<region> --format="value(artifactUri)"

# Get container image URI
gcloud ai models describe <model-id> --region=<region> --format="value(containerSpec.imageUri)"
```
### Eindpuntbesonderhede
```bash
# Get endpoint details including deployed models
gcloud ai endpoints describe <endpoint-id> --region=<region>

# Get endpoint URL
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].displayName)"

# Get service account used by endpoint
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(deployedModels[0].serviceAccount)"

# Check traffic split between models
gcloud ai endpoints describe <endpoint-id> --region=<region> --format="value(trafficSplit)"
```
### Aangepaste Taakinligting
```bash
# Get job details including command, args, and service account
gcloud ai custom-jobs describe <job-id> --region=<region>

# Get service account used by job
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].serviceAccount)"

# Get container image used
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.imageUri)"

# Check environment variables (may contain secrets)
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.workerPoolSpecs[0].containerSpec.env)"

# Get network configuration
gcloud ai custom-jobs describe <job-id> --region=<region> --format="value(jobSpec.network)"
```
### Toegangsbeheer
```bash
# Note: IAM policies for individual Vertex AI resources are managed at the project level
# Check project-level permissions
gcloud projects get-iam-policy <project-id>

# Check service account permissions
gcloud iam service-accounts get-iam-policy <service-account-email>

# Check if endpoints allow unauthenticated access
# This is controlled by IAM bindings on the endpoint
gcloud projects get-iam-policy <project-id> \
--flatten="bindings[].members" \
--filter="bindings.role:aiplatform.user"
```
### Berging en Artefakte
```bash
# Models and training jobs often store artifacts in GCS
# List buckets that might contain model artifacts
gsutil ls

# Common artifact locations:
# gs://<project>-aiplatform-<region>/
# gs://<project>-vertex-ai/
# gs://<custom-bucket>/vertex-ai/

# Download model artifacts if accessible
gsutil -m cp -r gs://<bucket>/path/to/artifacts ./artifacts/

# Check for notebooks in AI Platform Notebooks
gcloud notebooks instances list --location=<location>
gcloud notebooks instances describe <instance-name> --location=<location>
```
### Modeltuin
```bash
# List Model Garden endpoints
gcloud ai endpoints list --list-model-garden-endpoints-only --region=<region>

# Model Garden models are often deployed with default configurations
# Check for publicly accessible endpoints
```
### Privilege Escalation

Op die volgende bladsy kan jy kyk hoe om **abuse Vertex AI permissions to escalate privileges**:

{{#ref}}
../gcp-privilege-escalation/gcp-vertex-ai-privesc.md
{{#endref}}

## Verwysings

- [https://cloud.google.com/vertex-ai/docs](https://cloud.google.com/vertex-ai/docs)
- [https://cloud.google.com/vertex-ai/docs/reference/rest](https://cloud.google.com/vertex-ai/docs/reference/rest)

{{#include ../../../banners/hacktricks-training.md}}
