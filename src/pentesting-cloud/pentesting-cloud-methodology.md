# Pentesting Cloud Methodik

{{#include ../banners/hacktricks-training.md}}

<figure><img src="../images/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## Grundlegende Methodik

Jede Cloud hat ihre Eigenheiten, aber allgemein gibt es ein paar **gemeinsame Dinge, die ein Pentester prüfen sollte**, wenn er eine Cloud-Umgebung testet:

- **Benchmark-Checks**
- Das hilft dir, **die Größe** der Umgebung und **die verwendeten Dienste** zu verstehen
- Es ermöglicht dir auch, einige **schnelle Fehlkonfigurationen** zu finden, da du die meisten dieser Tests mit **automatisierten Tools** durchführen kannst
- **Services Enumeration**
- Wenn du die Benchmark-Tests korrekt durchgeführt hast, wirst du hier wahrscheinlich nicht viele weitere Fehlkonfigurationen finden, aber möglicherweise solche, die im Benchmark-Test nicht gesucht wurden.
- Das ermöglicht dir zu wissen, **was genau** in der Cloud-Umgebung verwendet wird
- Das hilft sehr in den nächsten Schritten
- **Überprüfe exponierte Assets**
- Das kann während des vorherigen Abschnitts gemacht werden; du musst **alles finden, was potenziell irgendwie ins Internet exponiert ist** und wie darauf zugegriffen werden kann.
- Hier betrachte ich **manuell exponierte Infrastruktur** wie Instanzen mit Webseiten oder anderen offenstehenden Ports, und auch andere **cloud-managed Services, die konfiguriert** werden können, um exponiert zu sein (z. B. DBs oder buckets)
- Dann solltest du prüfen, **ob diese Ressource exponiert werden kann oder nicht** (vertrauliche Informationen? Vulnerabilities? Fehlkonfigurationen im exponierten Service?)
- **Berechtigungen prüfen**
- Hier solltest du **alle Berechtigungen jeder Rolle/jedes Benutzers** innerhalb der Cloud herausfinden und wie sie verwendet werden
- Zu **viele hochprivilegierte** (kontrollieren alles) Accounts? Generierte Keys, die nicht verwendet werden?... Die meisten dieser Prüfungen sollten bereits in den Benchmark-Tests gemacht worden sein
- Wenn der Kunde OpenID oder SAML oder eine andere **federation** verwendet, musst du ihn möglicherweise um weitere **Informationen** bitten, **wie jede Rolle zugewiesen wird** (es ist nicht dasselbe, ob die Admin-Rolle einem Nutzer oder 100 zugewiesen ist)
- Es reicht **nicht aus herauszufinden**, welche Benutzer **Admin**-Berechtigungen "\*:\*". Es gibt viele **andere Berechtigungen**, die je nach verwendeten Diensten sehr **sensibel** sein können.
- Darüber hinaus gibt es **potentielle privesc**-Wege, die man durch Missbrauch von Berechtigungen verfolgen kann. All diese Dinge sollten berücksichtigt werden und **so viele privesc-Pfade wie möglich** sollten berichtet werden.
- **Integrationen prüfen**
- Es ist sehr wahrscheinlich, dass **Integrationen mit anderen Clouds oder SaaS** innerhalb der Cloud-Umgebung verwendet werden.
- Bei **Integrationen der Cloud, die du auditierst**, mit anderen Plattformen solltest du mitteilen, **wer Zugriff hat, diese Integration (ab)zuusenzen** und du solltest fragen, **wie sensibel** die ausgeführte Aktion ist.\
Zum Beispiel: Wer kann in einen AWS-Bucket schreiben, aus dem GCP Daten bezieht (frage, wie sensibel die Aktion in GCP ist, die diese Daten verarbeitet).
- Bei **Integrationen innerhalb der Cloud, die du auditierst**, von externen Plattformen aus, solltest du fragen, **wer extern Zugriff hat, diese Integration (ab)zuusenzen** und prüfen, wie diese Daten verwendet werden.\
Zum Beispiel: Wenn ein Service ein Docker-Image verwendet, das in GCR gehostet wird, solltest du fragen, wer Zugriff hat, dieses zu verändern und welche sensiblen Informationen und Zugriffe dieses Image erhält, wenn es innerhalb einer AWS-Cloud ausgeführt wird.

## Multi-Cloud-Tools

Es gibt mehrere Tools, die verwendet werden können, um verschiedene Cloud-Umgebungen zu testen. Die Installationsschritte und Links werden in diesem Abschnitt angegeben.

### [PurplePanda](https://github.com/carlospolop/purplepanda)

Ein Tool, um **schlechte Konfigurationen und privesc path in Clouds und über Clouds/SaaS hinweg zu identifizieren.**

{{#tabs }}
{{#tab name="Install" }}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{{#endtab }}
{{#endtabs }}

### [Prowler](https://github.com/prowler-cloud/prowler)

Es unterstützt **AWS, GCP & Azure**. Prüfe, wie jeder Provider konfiguriert wird unter [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws)
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{{#tabs }}
{{#tab name="Install" }}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{{#endtab }}
{{#endtabs }}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{{#tabs }}
{{#tab name="Install" }}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{{#endtab }}
{{#endtabs }}

### [Steampipe](https://github.com/turbot)

{{#tabs }}
{{#tab name="Install" }}
Lade und installiere Steampipe ([https://steampipe.io/downloads](https://steampipe.io/downloads)). Oder verwende Brew:
```
brew tap turbot/tap
brew install steampipe
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>Alle Projekte prüfen</summary>

Um alle Projekte zu prüfen, müssen Sie die Datei `gcp.spc` erzeugen, die alle zu testenden Projekte angibt. Sie können einfach den Anweisungen des folgenden Skripts folgen
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

Um **andere GCP-Einblicke** zu prüfen (nützlich zur Aufzählung von Diensten), verwenden Sie: [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

Um Terraform GCP-Code zu prüfen: [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

Weitere GCP-Plugins für Steampipe: [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{{#endtab }}

{{#tab name="AWS" }}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
Um Terraform AWS-Code zu überprüfen: [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

Weitere AWS-Plugins von Steampipe: [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{{#endtab }}
{{#endtabs }}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
Es benötigt python2.7 und scheint nicht mehr gepflegt zu sein.

### Nessus

Nessus verfügt über einen _**Audit Cloud Infrastructure**_ Scan, der folgende Plattformen unterstützt: AWS, Azure, Office 365, Rackspace, Salesforce. Für **Azure** sind einige zusätzliche Konfigurationen erforderlich, um eine **Client Id** zu erhalten.

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist ist ein **multi-cloud tool for getting Assets** (Hostnames, IP Addresses) von Cloud Providers.

{{#tabs }}
{{#tab name="Cloudlist" }}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{{#endtab }}

{{#tab name="Second Tab" }}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{{#endtab }}
{{#endtabs }}

### [**cartography**](https://github.com/lyft/cartography)

Cartography ist ein Python-Tool, das Infrastruktur-Assets und deren Beziehungen in einer intuitiven Graphansicht zusammenführt, die von einer Neo4j-Datenbank bereitgestellt wird.

{{#tabs }}
{{#tab name="Install" }}
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{{#endtab }}
{{#endtabs }}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase sammelt Assets und Beziehungen aus Diensten und Systemen, einschließlich Cloud-Infrastruktur, SaaS-Anwendungen, Sicherheitskontrollen und mehr, und stellt sie in einer intuitiven Graphansicht dar, die von der Neo4j-Datenbank unterstützt wird.

{{#tabs }}
{{#tab name="Install" }}
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{{#endtab }}

{{#tab name="GCP" }}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
- name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: "{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}"
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
{{#endtab }}
{{#endtabs }}

### [**SkyArk**](https://github.com/cyberark/SkyArk)

Ermittelt die am höchsten privilegierten Benutzer in der gescannten AWS- oder Azure-Umgebung, einschließlich der AWS Shadow Admins. Verwendet powershell.
```bash
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

Ein Tool, um die Infrastruktur, Dateien und Apps eines Unternehmens (Ziels) bei den führenden Cloud-Anbietern (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode) zu finden.

### [CloudFox](https://github.com/BishopFox/cloudfox)

- CloudFox ist ein Tool, um ausnutzbare Angriffspfade in Cloud-Infrastrukturen zu finden (derzeit werden nur AWS & Azure unterstützt; GCP kommt demnächst).
- Es ist ein Enumeration-Tool, das manuelles pentesting ergänzen soll.
- Es erstellt oder verändert keine Daten innerhalb der Cloud-Umgebung.

### Weitere Listen von Cloud-Sicherheits-Tools

- [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{{#ref}}
gcp-security/
{{#endref}}

### Workspace

{{#ref}}
workspace-security/
{{#endref}}

## AWS

{{#ref}}
aws-security/
{{#endref}}

## Azure

{{#ref}}
azure-security/
{{#endref}}

### Attack Graph

[**Stormspotter** ](https://github.com/Azure/Stormspotter) erstellt einen "attack graph" der Ressourcen in einer Azure subscription. Es ermöglicht red teams und pentesters, die attack surface und pivot opportunities innerhalb eines tenants zu visualisieren und befähigt Ihre Verteidiger, sich schnell zu orientieren und Incident Response‑Arbeiten zu priorisieren.

### Office365

Du benötigst **Global Admin** oder mindestens **Global Admin Reader** (beachte, dass Global Admin Reader etwas eingeschränkt ist). Diese Einschränkungen treten jedoch in einigen PS-Modulen auf und können umgangen werden, indem man auf die Funktionen **via the web application** zugreift.


{{#include ../banners/hacktricks-training.md}}
