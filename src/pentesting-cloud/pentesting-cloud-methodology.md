# Metodología de Pentesting en la Nube

{{#include ../banners/hacktricks-training.md}}

<figure><img src="../images/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## Metodología Básica

Cada nube tiene sus propias peculiaridades, pero en general hay algunas **cosas comunes que un pentester debe verificar** al probar un entorno en la nube:

- **Verificaciones de referencia**
- Esto te ayudará a **entender el tamaño** del entorno y **los servicios utilizados**
- También te permitirá encontrar algunas **mala configuraciones rápidas** ya que puedes realizar la mayoría de estas pruebas con **herramientas automatizadas**
- **Enumeración de Servicios**
- Probablemente no encontrarás muchas más mala configuraciones aquí si realizaste correctamente las pruebas de referencia, pero podrías encontrar algunas que no se buscaron en la prueba de referencia.
- Esto te permitirá saber **qué se está utilizando exactamente** en el entorno de la nube
- Esto ayudará mucho en los siguientes pasos
- **Verificar activos expuestos**
- Esto se puede hacer durante la sección anterior, necesitas **descubrir todo lo que está potencialmente expuesto** a Internet de alguna manera y cómo se puede acceder a ello.
- Aquí estoy tomando **infraestructura expuesta manualmente** como instancias con páginas web u otros puertos expuestos, y también sobre otros **servicios gestionados en la nube que pueden ser configurados** para estar expuestos (como bases de datos o buckets)
- Luego deberías verificar **si ese recurso puede ser expuesto o no** (¿información confidencial? ¿vulnerabilidades? ¿mala configuraciones en el servicio expuesto?)
- **Verificar permisos**
- Aquí deberías **descubrir todos los permisos de cada rol/usuario** dentro de la nube y cómo se utilizan
- ¿Demasiadas cuentas **altamente privilegiadas** (controlan todo)? ¿Claves generadas no utilizadas?... La mayoría de estas verificaciones ya deberían haberse realizado en las pruebas de referencia
- Si el cliente está utilizando OpenID o SAML u otra **federación**, es posible que necesites pedirles más **información** sobre **cómo se asigna cada rol** (no es lo mismo que el rol de administrador sea asignado a 1 usuario o a 100)
- **No es suficiente encontrar** qué usuarios tienen permisos de **administrador** "\*:\*". Hay muchos **otros permisos** que dependiendo de los servicios utilizados pueden ser muy **sensibles**.
- Además, hay **potenciales caminos de privesc** a seguir abusando de los permisos. Todas estas cosas deben ser tenidas en cuenta y **se deben reportar tantos caminos de privesc como sea posible**.
- **Verificar Integraciones**
- Es muy probable que **integraciones con otras nubes o SaaS** se estén utilizando dentro del entorno de la nube.
- Para **integraciones de la nube que estás auditando** con otra plataforma, deberías notificar **quién tiene acceso para (ab)usar esa integración** y deberías preguntar **qué tan sensible** es la acción que se está realizando.\
Por ejemplo, quién puede escribir en un bucket de AWS del cual GCP está obteniendo datos (pregunta qué tan sensible es la acción en GCP al tratar esos datos).
- Para **integraciones dentro de la nube que estás auditando** desde plataformas externas, deberías preguntar **quién tiene acceso externamente para (ab)usar esa integración** y verificar cómo se está utilizando esos datos.\
Por ejemplo, si un servicio está utilizando una imagen de Docker alojada en GCR, deberías preguntar quién tiene acceso para modificar eso y qué información sensible y acceso obtendrá esa imagen al ejecutarse dentro de una nube de AWS.

## Herramientas Multi-Nube

Hay varias herramientas que se pueden utilizar para probar diferentes entornos en la nube. Los pasos de instalación y enlaces se indicarán en esta sección.

### [PurplePanda](https://github.com/carlospolop/purplepanda)

Una herramienta para **identificar malas configuraciones y caminos de privesc en nubes y a través de nubes/SaaS.**

{{#tabs }}
{{#tab name="Instalar" }}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{{#endtab }}
{{#endtabs }}

### [Prowler](https://github.com/prowler-cloud/prowler)

Soporta **AWS, GCP y Azure**. Consulta cómo configurar cada proveedor en [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws)
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{{#tabs }}
{{#tab name="Instalar" }}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{{#endtab }}
{{#endtabs }}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{{#tabs }}
{{#tab name="Instalar" }}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{{#endtab }}
{{#endtabs }}

### [Steampipe](https://github.com/turbot)

{{#tabs }}
{{#tab name="Instalar" }}
Descarga e instala Steampipe ([https://steampipe.io/downloads](https://steampipe.io/downloads)). O usa Brew:
```
brew tap turbot/tap
brew install steampipe
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>Revisar todos los Proyectos</summary>

Para revisar todos los proyectos, necesitas generar el archivo `gcp.spc` indicando todos los proyectos a probar. Solo puedes seguir las indicaciones del siguiente script.
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

Para verificar **otros insights de GCP** (útil para enumerar servicios) usa: [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

Para verificar el código de Terraform GCP: [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

Más plugins de GCP de Steampipe: [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{{#endtab }}

{{#tab name="AWS" }}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
Para verificar el código de Terraform AWS: [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

Más complementos de AWS de Steampipe: [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{{#endtab }}
{{#endtabs }}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
Requiere python2.7 y parece no estar mantenido.

### Nessus

Nessus tiene un _**Audit Cloud Infrastructure**_ escaneo que soporta: AWS, Azure, Office 365, Rackspace, Salesforce. Se necesitan algunas configuraciones adicionales en **Azure** para obtener un **Client Id**.

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist es una **herramienta multi-nube para obtener Activos** (Nombres de host, Direcciones IP) de Proveedores de Nube.

{{#tabs }}
{{#tab name="Cloudlist" }}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{{#endtab }}

{{#tab name="Second Tab" }}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{{#endtab }}
{{#endtabs }}

### [**cartography**](https://github.com/lyft/cartography)

Cartography es una herramienta de Python que consolida los activos de infraestructura y las relaciones entre ellos en una vista gráfica intuitiva impulsada por una base de datos Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{{#endtab }}
{{#endtabs }}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase recopila activos y relaciones de servicios y sistemas, incluyendo infraestructura en la nube, aplicaciones SaaS, controles de seguridad y más, en una vista gráfica intuitiva respaldada por la base de datos Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{{#endtab }}

{{#tab name="GCP" }}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
- name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: "{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}"
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
{{#endtab }}
{{#endtabs }}

### [**SkyArk**](https://github.com/cyberark/SkyArk)

Descubre los usuarios más privilegiados en el entorno escaneado de AWS o Azure, incluidos los AWS Shadow Admins. Utiliza PowerShell.
```powershell
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

Una herramienta para encontrar la infraestructura, archivos y aplicaciones de una empresa (objetivo) en los principales proveedores de nube (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode).

### [CloudFox](https://github.com/BishopFox/cloudfox)

- CloudFox es una herramienta para encontrar rutas de ataque explotables en la infraestructura de la nube (actualmente solo se admite AWS y Azure, con GCP en camino).
- Es una herramienta de enumeración que está destinada a complementar el pentesting manual.
- No crea ni modifica ningún dato dentro del entorno de la nube.

### Más listas de herramientas de seguridad en la nube

- [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{{#ref}}
gcp-security/
{{#endref}}

### Workspace

{{#ref}}
workspace-security/
{{#endref}}

## AWS

{{#ref}}
aws-security/
{{#endref}}

## Azure

{{#ref}}
azure-security/
{{#endref}}

### Attack Graph

[**Stormspotter** ](https://github.com/Azure/Stormspotter) crea un “gráfico de ataque” de los recursos en una suscripción de Azure. Permite a los equipos rojos y pentesters visualizar la superficie de ataque y las oportunidades de pivote dentro de un inquilino, y potencia a tus defensores para orientarse y priorizar rápidamente el trabajo de respuesta a incidentes.

### Office365

Necesitas **Global Admin** o al menos **Global Admin Reader** (pero ten en cuenta que Global Admin Reader es un poco limitado). Sin embargo, esas limitaciones aparecen en algunos módulos de PS y se pueden eludir accediendo a las funciones **a través de la aplicación web**.

{{#include ../banners/hacktricks-training.md}}
