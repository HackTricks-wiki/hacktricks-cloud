# Metodología de pentesting en la nube

{{#include ../banners/hacktricks-training.md}}

<figure><img src="../images/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## Metodología básica

Cada nube tiene sus propias peculiaridades pero en general hay algunas **cosas comunes que un pentester debería revisar** al evaluar un entorno en la nube:

- **Comprobaciones de benchmark**
- Esto te ayudará a **entender el tamaño** del entorno y **los servicios utilizados**
- También te permitirá encontrar algunas **misconfiguraciones rápidas**, ya que puedes realizar la mayoría de estas pruebas con **herramientas automatizadas**
- **Enumeración de servicios**
- Probablemente no encontrarás muchas más misconfiguraciones aquí si realizaste correctamente las comprobaciones de benchmark, pero podrías encontrar algunas que no se buscaron en las pruebas de benchmark.
- Esto te permitirá saber **qué se está usando exactamente** en el entorno en la nube
- Esto ayudará mucho en los siguientes pasos
- **Comprobar activos expuestos**
- Esto puede hacerse durante la sección anterior; necesitas **identificar todo lo que potencialmente está expuesto** a Internet de alguna manera y cómo puede ser accedido.
- Aquí me refiero a **infraestructura expuesta manualmente** como instancias con páginas web u otros puertos expuestos, y también a otros **servicios gestionados en la nube que pueden configurarse** para estar expuestos (como DBs o buckets)
- Luego deberías comprobar **si ese recurso puede ser expuesto o no** (¿información confidencial? ¿vulnerabilidades? ¿misconfiguraciones en el servicio expuesto?)
- **Comprobar permisos**
- Aquí deberías **identificar todos los permisos de cada rol/usuario** dentro de la nube y cómo se usan
- ¿Demasiadas cuentas con **privilegios elevados** (controlan todo)? ¿Claves generadas que no se usan?... La mayoría de estas comprobaciones deberían haberse hecho ya en los tests de benchmark
- Si el cliente está usando OpenID o SAML u otra **federación** puede que necesites pedirles más **información** sobre **cómo se asigna cada rol** (no es lo mismo que el rol admin esté asignado a 1 usuario o a 100)
- **No es suficiente encontrar** qué usuarios tienen permisos **admin** "*:*". Hay muchos **otros permisos** que, dependiendo de los servicios usados, pueden ser muy **sensibles**.
- Además, existen **posibles rutas de privesc** que se pueden seguir abusando de permisos. Todas estas cosas deben tenerse en cuenta y **se deben reportar tantos caminos de privesc como sea posible**.
- **Comprobar integraciones**
- Es altamente probable que **se estén usando integraciones con otras nubes o SaaS** dentro del entorno en la nube.
- Para **las integraciones de la nube que estás auditando** con otra plataforma, deberías notificar **quién tiene acceso para (ab)usar esa integración** y deberías preguntar **qué tan sensible** es la acción que se realiza.\
Por ejemplo, quién puede escribir en un bucket de AWS del cual GCP está obteniendo datos (preguntar qué tan sensible es la acción en GCP al tratar esos datos).
- Para **las integraciones dentro de la nube que estás auditando** desde plataformas externas, deberías preguntar **quién tiene acceso externamente para (ab)usar esa integración** y comprobar cómo se están usando esos datos.\
Por ejemplo, si un servicio está usando una imagen Docker alojada en GCR, deberías preguntar quién tiene acceso para modificarla y qué información sensible y accesos obtendrá esa imagen cuando se ejecute dentro de una nube AWS.

## Herramientas Multi-Cloud

Hay varias herramientas que se pueden usar para evaluar diferentes entornos en la nube. Los pasos de instalación y los enlaces se indicarán en esta sección.

### [PurplePanda](https://github.com/carlospolop/purplepanda)

Una herramienta para **identificar malas configuraciones y rutas de privesc en nubes y entre nubes/SaaS.**

{{#tabs }}
{{#tab name="Install" }}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{{#endtab }}
{{#endtabs }}

### [Prowler](https://github.com/prowler-cloud/prowler)

Soporta **AWS, GCP & Azure**. Consulta cómo configurar cada proveedor en [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws)
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{{#tabs }}
{{#tab name="Install" }}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{{#endtab }}
{{#endtabs }}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{{#tabs }}
{{#tab name="Install" }}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{{#endtab }}
{{#endtabs }}

### [Steampipe](https://github.com/turbot)

{{#tabs }}
{{#tab name="Install" }}
Descarga e instala Steampipe ([https://steampipe.io/downloads](https://steampipe.io/downloads)). O usa Brew:
```
brew tap turbot/tap
brew install steampipe
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>Comprobar todos los proyectos</summary>

Para comprobar todos los proyectos necesitas generar el archivo `gcp.spc` indicando todos los proyectos a probar. Puedes seguir las indicaciones del siguiente script
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

Para comprobar **otros GCP insights** (útiles para enumerar servicios) utilice: [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

Para revisar código Terraform de GCP: [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

Más plugins de GCP para Steampipe: [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{{#endtab }}

{{#tab name="AWS" }}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
Para revisar el código Terraform AWS: [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

Más plugins AWS de Steampipe: [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{{#endtab }}
{{#endtabs }}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
Requiere python2.7 y parece no estar mantenido.

### Nessus

Nessus tiene un escaneo _**Audit Cloud Infrastructure**_ que soporta: AWS, Azure, Office 365, Rackspace, Salesforce. Se necesitan algunas configuraciones adicionales en **Azure** para obtener un **Client Id**.

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist es una **herramienta multi-cloud para obtener activos** (nombres de host, direcciones IP) de proveedores de nube.

{{#tabs }}
{{#tab name="Cloudlist" }}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{{#endtab }}

{{#tab name="Second Tab" }}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{{#endtab }}
{{#endtabs }}

### [**cartography**](https://github.com/lyft/cartography)

Cartography es una herramienta en Python que consolida los activos de infraestructura y las relaciones entre ellos en una vista de grafo intuitiva impulsada por una base de datos Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{{#endtab }}
{{#endtabs }}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase recopila activos y relaciones de servicios y sistemas, incluyendo infraestructura en la nube, aplicaciones SaaS, controles de seguridad y más, en una vista de grafo intuitiva respaldada por la base de datos Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{{#endtab }}

{{#tab name="GCP" }}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
- name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: "{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}"
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
{{#endtab }}
{{#endtabs }}

### [**SkyArk**](https://github.com/cyberark/SkyArk)

Detecta los usuarios más privilegiados en el entorno AWS o Azure escaneado, incluyendo los AWS Shadow Admins. Utiliza powershell.
```bash
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

Una herramienta para encontrar la infraestructura de una empresa (objetivo), archivos y apps en los principales proveedores de nube (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode).

### [CloudFox](https://github.com/BishopFox/cloudfox)

- CloudFox es una herramienta para encontrar rutas de ataque explotables en la infraestructura en la nube (actualmente solo soporta AWS & Azure, con GCP próximamente).
- Es una herramienta de enumeración destinada a complementar el pentesting manual.
- No crea ni modifica ningún dato dentro del entorno en la nube.

### More lists of cloud security tools

- [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{{#ref}}
gcp-security/
{{#endref}}

### Workspace

{{#ref}}
workspace-security/
{{#endref}}

## AWS

{{#ref}}
aws-security/
{{#endref}}

## Azure

{{#ref}}
azure-security/
{{#endref}}

## Common Cloud Security Features

### Confidential Computing

{{#ref}}
confidential-computing/luks2-header-malleability-null-cipher-abuse.md
{{#endref}}

{{#include ../banners/hacktricks-training.md}}
