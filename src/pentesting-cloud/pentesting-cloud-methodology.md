# Méthodologie de Pentesting Cloud

{{#include ../banners/hacktricks-training.md}}

<figure><img src="../images/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## Méthodologie de base

Chaque cloud a ses propres particularités, mais en général, il y a quelques **éléments communs qu'un pentester devrait vérifier** lors du test d'un environnement cloud :

- **Vérifications de référence**
- Cela vous aidera à **comprendre la taille** de l'environnement et les **services utilisés**
- Cela vous permettra également de trouver quelques **mauvais configurations rapides** car vous pouvez effectuer la plupart de ces tests avec des **outils automatisés**
- **Énumération des services**
- Vous ne trouverez probablement pas beaucoup plus de mauvaises configurations ici si vous avez correctement effectué les tests de référence, mais vous pourriez en trouver certaines qui n'étaient pas recherchées dans le test de référence.
- Cela vous permettra de savoir **ce qui est exactement utilisé** dans l'environnement cloud
- Cela aidera beaucoup dans les étapes suivantes
- **Vérifiez les actifs exposés**
- Cela peut être fait lors de la section précédente, vous devez **découvrir tout ce qui est potentiellement exposé** à Internet d'une manière ou d'une autre et comment cela peut être accessible.
- Ici, je parle d'**infrastructure exposée manuellement** comme des instances avec des pages web ou d'autres ports exposés, et aussi d'autres **services gérés par le cloud qui peuvent être configurés** pour être exposés (comme des bases de données ou des buckets)
- Ensuite, vous devriez vérifier **si cette ressource peut être exposée ou non** (informations confidentielles ? vulnérabilités ? mauvaises configurations dans le service exposé ?)
- **Vérifiez les permissions**
- Ici, vous devriez **découvrir toutes les permissions de chaque rôle/utilisateur** à l'intérieur du cloud et comment elles sont utilisées
- Trop de comptes **hautement privilégiés** (contrôle total) ? Clés générées non utilisées ?... La plupart de ces vérifications auraient déjà dû être effectuées dans les tests de référence
- Si le client utilise OpenID ou SAML ou autre **fédération**, vous pourriez avoir besoin de leur demander plus d'**informations** sur **comment chaque rôle est attribué** (ce n'est pas la même chose que le rôle d'administrateur soit attribué à 1 utilisateur ou à 100)
- Il **n'est pas suffisant de trouver** quels utilisateurs ont des permissions **admin** "\*:\*". Il y a beaucoup d'**autres permissions** qui, selon les services utilisés, peuvent être très **sensibles**.
- De plus, il existe des **chemins potentiels de privesc** à suivre en abusant des permissions. Toutes ces choses doivent être prises en compte et **autant de chemins de privesc que possible** doivent être rapportés.
- **Vérifiez les intégrations**
- Il est très probable que des **intégrations avec d'autres clouds ou SaaS** soient utilisées à l'intérieur de l'environnement cloud.
- Pour les **intégrations du cloud que vous auditez** avec d'autres plateformes, vous devriez notifier **qui a accès à (ab)user de cette intégration** et vous devriez demander **à quel point** l'action effectuée est sensible.\
Par exemple, qui peut écrire dans un bucket AWS d'où GCP obtient des données (demandez à quel point l'action est sensible dans GCP traitant ces données).
- Pour les **intégrations à l'intérieur du cloud que vous auditez** provenant de plateformes externes, vous devriez demander **qui a accès de l'extérieur pour (ab)user de cette intégration** et vérifier comment ces données sont utilisées.\
Par exemple, si un service utilise une image Docker hébergée dans GCR, vous devriez demander qui a accès pour la modifier et quelles informations sensibles et accès obtiendra cette image lorsqu'elle est exécutée à l'intérieur d'un cloud AWS.

## Outils Multi-Cloud

Il existe plusieurs outils qui peuvent être utilisés pour tester différents environnements cloud. Les étapes d'installation et les liens seront indiqués dans cette section.

### [PurplePanda](https://github.com/carlospolop/purplepanda)

Un outil pour **identifier les mauvaises configurations et les chemins de privesc dans les clouds et entre les clouds/SaaS.**

{{#tabs }}
{{#tab name="Install" }}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{{#endtab }}
{{#endtabs }}

### [Prowler](https://github.com/prowler-cloud/prowler)

Il prend en charge **AWS, GCP & Azure**. Vérifiez comment configurer chaque fournisseur dans [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws)
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{{#tabs }}
{{#tab name="Installer" }}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{{#endtab }}
{{#endtabs }}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{{#tabs }}
{{#tab name="Installer" }}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{{#endtab }}
{{#endtabs }}

### [Steampipe](https://github.com/turbot)

{{#tabs }}
{{#tab name="Installer" }}
Téléchargez et installez Steampipe ([https://steampipe.io/downloads](https://steampipe.io/downloads)). Ou utilisez Brew :
```
brew tap turbot/tap
brew install steampipe
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>Vérifiez tous les projets</summary>

Pour vérifier tous les projets, vous devez générer le fichier `gcp.spc` indiquant tous les projets à tester. Vous pouvez simplement suivre les indications du script suivant.
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

Pour vérifier **d'autres insights GCP** (utiles pour énumérer les services) utilisez : [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

Pour vérifier le code Terraform GCP : [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

Plus de plugins GCP de Steampipe : [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{{#endtab }}

{{#tab name="AWS" }}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
Pour vérifier le code Terraform AWS : [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

Plus de plugins AWS de Steampipe : [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{{#endtab }}
{{#endtabs }}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
Cela nécessite python2.7 et semble non maintenu.

### Nessus

Nessus a un _**Audit Cloud Infrastructure**_ scan prenant en charge : AWS, Azure, Office 365, Rackspace, Salesforce. Certaines configurations supplémentaires dans **Azure** sont nécessaires pour obtenir un **Client Id**.

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist est un **outil multi-cloud pour obtenir des actifs** (noms d'hôtes, adresses IP) des fournisseurs de cloud.

{{#tabs }}
{{#tab name="Cloudlist" }}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{{#endtab }}

{{#tab name="Deuxième Onglet" }}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{{#endtab }}
{{#endtabs }}

### [**cartography**](https://github.com/lyft/cartography)

Cartography est un outil Python qui consolide les actifs d'infrastructure et les relations entre eux dans une vue graphique intuitive alimentée par une base de données Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{{#endtab }}
{{#endtabs }}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase collecte des actifs et des relations à partir de services et de systèmes, y compris l'infrastructure cloud, les applications SaaS, les contrôles de sécurité, et plus encore, dans une vue graphique intuitive soutenue par la base de données Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{{#endtab }}

{{#tab name="GCP" }}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
- name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: "{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}"
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
{{#endtab }}
{{#endtabs }}

### [**SkyArk**](https://github.com/cyberark/SkyArk)

Découvrez les utilisateurs les plus privilégiés dans l'environnement AWS ou Azure scanné, y compris les AWS Shadow Admins. Il utilise PowerShell.
```powershell
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

Un outil pour trouver l'infrastructure, les fichiers et les applications d'une entreprise (cible) sur les principaux fournisseurs de cloud (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode).

### [CloudFox](https://github.com/BishopFox/cloudfox)

- CloudFox est un outil pour trouver des chemins d'attaque exploitables dans l'infrastructure cloud (actuellement uniquement AWS et Azure pris en charge avec GCP à venir).
- C'est un outil d'énumération qui est destiné à compléter le pentesting manuel.
- Il ne crée ni ne modifie aucune donnée dans l'environnement cloud.

### Plus de listes d'outils de sécurité cloud

- [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{{#ref}}
gcp-security/
{{#endref}}

### Workspace

{{#ref}}
workspace-security/
{{#endref}}

## AWS

{{#ref}}
aws-security/
{{#endref}}

## Azure

{{#ref}}
azure-security/
{{#endref}}

### Attack Graph

[**Stormspotter** ](https://github.com/Azure/Stormspotter) crée un “graphique d'attaque” des ressources dans une souscription Azure. Il permet aux équipes rouges et aux pentesters de visualiser la surface d'attaque et les opportunités de pivot dans un locataire, et renforce vos défenseurs pour s'orienter rapidement et prioriser le travail de réponse aux incidents.

### Office365

Vous avez besoin de **Global Admin** ou au moins de **Global Admin Reader** (mais notez que Global Admin Reader est un peu limité). Cependant, ces limitations apparaissent dans certains modules PS et peuvent être contournées en accédant aux fonctionnalités **via l'application web**.

{{#include ../banners/hacktricks-training.md}}
