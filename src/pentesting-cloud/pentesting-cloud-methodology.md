# Metodologia Pentestingu w Chmurze

{{#include ../banners/hacktricks-training.md}}

<figure><img src="../images/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## Podstawowa Metodologia

Każda chmura ma swoje własne szczególności, ale ogólnie istnieje kilka **wspólnych rzeczy, które pentester powinien sprawdzić** podczas testowania środowiska chmurowego:

- **Sprawdzanie standardów**
- To pomoże Ci **zrozumieć rozmiar** środowiska i **używane usługi**
- Pozwoli to również znaleźć kilka **szybkich błędów konfiguracyjnych**, ponieważ większość tych testów można przeprowadzić za pomocą **automatycznych narzędzi**
- **Enumaracja usług**
- Prawdopodobnie nie znajdziesz wielu więcej błędów konfiguracyjnych, jeśli poprawnie przeprowadziłeś testy standardów, ale możesz znaleźć niektóre, które nie były brane pod uwagę w teście standardów.
- To pozwoli Ci wiedzieć **co dokładnie jest używane** w środowisku chmurowym
- To bardzo pomoże w następnych krokach
- **Sprawdź wystawione zasoby**
- Można to zrobić podczas poprzedniej sekcji, musisz **dowiedzieć się, co jest potencjalnie wystawione** w Internecie i jak można to uzyskać.
- Tutaj mam na myśli **ręcznie wystawioną infrastrukturę**, taką jak instancje z stronami internetowymi lub innymi portami, które są wystawione, a także inne **usługi zarządzane w chmurze, które mogą być skonfigurowane** do wystawienia (takie jak bazy danych lub kosze)
- Następnie powinieneś sprawdzić **czy ten zasób może być wystawiony czy nie** (informacje poufne? luki? błędy konfiguracyjne w wystawionej usłudze?)
- **Sprawdź uprawnienia**
- Tutaj powinieneś **dowiedzieć się o wszystkich uprawnieniach każdego roli/użytkownika** w chmurze i jak są one używane
- Zbyt **wiele wysoko uprzywilejowanych** (kontrolujących wszystko) kont? Wygenerowane klucze, które nie są używane?... Większość tych sprawdzeń powinna być już wykonana w testach standardów
- Jeśli klient korzysta z OpenID lub SAML lub innej **federacji**, możesz potrzebować poprosić ich o dodatkowe **informacje** na temat **jak każda rola jest przypisywana** (to nie to samo, co przypisanie roli administratora do 1 użytkownika lub do 100)
- **Nie wystarczy znaleźć**, którzy użytkownicy mają **uprawnienia administratora** "\*:\*". Istnieje wiele **innych uprawnień**, które w zależności od używanych usług mogą być bardzo **wrażliwe**.
- Co więcej, istnieją **potencjalne ścieżki privesc**, które można śledzić, nadużywając uprawnień. Wszystkie te rzeczy powinny być brane pod uwagę i **jak najwięcej ścieżek privesc powinno być** zgłoszonych.
- **Sprawdź integracje**
- Jest bardzo prawdopodobne, że **integracje z innymi chmurami lub SaaS** są używane w środowisku chmurowym.
- Dla **integracji chmury, którą audytujesz** z inną platformą powinieneś powiadomić **kto ma dostęp do (nadużywania) tej integracji** i powinieneś zapytać **jak wrażliwa** jest wykonywana akcja.\
Na przykład, kto może pisać w koszu AWS, z którego GCP pobiera dane (zapytaj, jak wrażliwa jest akcja w GCP w związku z tymi danymi).
- Dla **integracji wewnątrz chmury, którą audytujesz** z zewnętrznych platform, powinieneś zapytać **kto ma dostęp zewnętrzny do (nadużywania) tej integracji** i sprawdzić, jak te dane są używane.\
Na przykład, jeśli usługa korzysta z obrazu Dockera hostowanego w GCR, powinieneś zapytać, kto ma dostęp do modyfikacji tego obrazu i jakie wrażliwe informacje i dostęp uzyska ten obraz po uruchomieniu w chmurze AWS.

## Narzędzia Multi-Cloud

Istnieje kilka narzędzi, które można wykorzystać do testowania różnych środowisk chmurowych. Kroki instalacji i linki będą wskazane w tej sekcji.

### [PurplePanda](https://github.com/carlospolop/purplepanda)

Narzędzie do **identyfikacji złych konfiguracji i ścieżek privesc w chmurach i między chmurami/SaaS.**

{{#tabs }}
{{#tab name="Install" }}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{{#endtab }}
{{#endtabs }}

### [Prowler](https://github.com/prowler-cloud/prowler)

Obsługuje **AWS, GCP i Azure**. Sprawdź, jak skonfigurować każdego dostawcę w [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws)
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{{#tabs }}
{{#tab name="Install" }}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{{#endtab }}
{{#endtabs }}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{{#tabs }}
{{#tab name="Instalacja" }}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{{#endtab }}
{{#endtabs }}

### [Steampipe](https://github.com/turbot)

{{#tabs }}
{{#tab name="Install" }}
Pobierz i zainstaluj Steampipe ([https://steampipe.io/downloads](https://steampipe.io/downloads)). Lub użyj Brew:
```
brew tap turbot/tap
brew install steampipe
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>Sprawdź wszystkie projekty</summary>

Aby sprawdzić wszystkie projekty, musisz wygenerować plik `gcp.spc`, wskazując wszystkie projekty do przetestowania. Możesz po prostu postępować zgodnie z instrukcjami z poniższego skryptu.
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

Aby sprawdzić **inne informacje GCP** (przydatne do enumeracji usług), użyj: [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

Aby sprawdzić kod Terraform GCP: [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

Więcej wtyczek GCP Steampipe: [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{{#endtab }}

{{#tab name="AWS" }}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
Aby sprawdzić kod Terraform AWS: [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

Więcej wtyczek AWS Steampipe: [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{{#endtab }}
{{#endtabs }}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
Wymaga python2.7 i wygląda na nieutrzymywane.

### Nessus

Nessus ma skan _**Audit Cloud Infrastructure**_ wspierający: AWS, Azure, Office 365, Rackspace, Salesforce. Wymagane są dodatkowe konfiguracje w **Azure**, aby uzyskać **Client Id**.

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist to **narzędzie multi-cloud do pozyskiwania zasobów** (nazwy hostów, adresy IP) od dostawców chmury.

{{#tabs }}
{{#tab name="Cloudlist" }}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{{#endtab }}

{{#tab name="Druga zakładka" }}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{{#endtab }}
{{#endtabs }}

### [**cartography**](https://github.com/lyft/cartography)

Cartography to narzędzie w Pythonie, które konsoliduje zasoby infrastruktury oraz relacje między nimi w intuicyjnym widoku graficznym zasilanym przez bazę danych Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{{#endtab }}
{{#endtabs }}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase zbiera zasoby i relacje z usług i systemów, w tym infrastruktury chmurowej, aplikacji SaaS, kontroli bezpieczeństwa i innych, w intuicyjny widok graficzny wspierany przez bazę danych Neo4j.

{{#tabs }}
{{#tab name="Install" }}
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{{#endtab }}

{{#tab name="GCP" }}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
- name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: "{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}"
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
{{#endtab }}
{{#endtabs }}

### [**SkyArk**](https://github.com/cyberark/SkyArk)

Odkryj najbardziej uprzywilejowanych użytkowników w zeskanowanym środowisku AWS lub Azure, w tym AWS Shadow Admins. Używa powershell.
```powershell
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

Narzędzie do znajdowania infrastruktury, plików i aplikacji firmy (cel) na czołowych dostawcach chmury (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode).

### [CloudFox](https://github.com/BishopFox/cloudfox)

- CloudFox to narzędzie do znajdowania podatnych ścieżek ataku w infrastrukturze chmurowej (obecnie wspierane tylko AWS i Azure, GCP wkrótce).
- Jest to narzędzie do enumeracji, które ma na celu uzupełnienie ręcznego pentestingu.
- Nie tworzy ani nie modyfikuje żadnych danych w środowisku chmurowym.

### Więcej list narzędzi do zabezpieczeń chmurowych

- [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{{#ref}}
gcp-security/
{{#endref}}

### Workspace

{{#ref}}
workspace-security/
{{#endref}}

## AWS

{{#ref}}
aws-security/
{{#endref}}

## Azure

{{#ref}}
azure-security/
{{#endref}}

### Attack Graph

[**Stormspotter** ](https://github.com/Azure/Stormspotter) tworzy "graf ataku" zasobów w subskrypcji Azure. Umożliwia zespołom red i pentesterom wizualizację powierzchni ataku i możliwości pivotowania w obrębie najemcy, a także wspomaga obrońców w szybkim orientowaniu się i priorytetyzowaniu pracy związanej z odpowiedzią na incydenty.

### Office365

Potrzebujesz **Global Admin** lub przynajmniej **Global Admin Reader** (ale zauważ, że Global Admin Reader jest nieco ograniczony). Jednak te ograniczenia pojawiają się w niektórych modułach PS i można je obejść, uzyskując dostęp do funkcji **za pośrednictwem aplikacji webowej**.

{{#include ../banners/hacktricks-training.md}}
