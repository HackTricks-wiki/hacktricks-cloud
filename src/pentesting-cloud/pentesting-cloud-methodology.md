# Pentesting क्लाउड कार्यप्रणाली

{{#include ../banners/hacktricks-training.md}}

<figure><img src="../images/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## मूल कार्यप्रणाली

हर क्लाउड की अपनी विशेषताएँ होती हैं लेकिन सामान्य तौर पर कुछ **सामान्य चीज़ें जिन्हें एक pentester को जांचना चाहिए** होती हैं जब एक क्लाउड वातावरण की जाँच की जा रही हो:

- **बेंचमार्क जांच**
- यह आपको वातावरण का **आकार समझने** और **उपयोग की जा रही सेवाओं** का पता लगाने में मदद करेगा
- यह आपको कुछ **त्वरित गलत कॉन्फ़िगरेशन** भी खोजने की अनुमति देगा क्योंकि आप इन परीक्षणों में से अधिकांश **स्वचालित टूल्स** के साथ चला सकते हैं
- **Services Enumeration**
- अगर आपने बेंचमार्क परीक्षण सही तरीके से किए हैं तो यहां आपको ज्यादा नए misconfigurations नहीं मिलेंगे, लेकिन आपको कुछ ऐसे मिल सकते हैं जिनकी बेंचमार्क टेस्ट में तलाश नहीं की गई थी।
- इससे आपको पता चलेगा कि क्लाउड env में **ठीक क्या उपयोग हो रहा है**
- यह अगले कदमों में बहुत मदद करेगा
- **प्रकट की गई संपत्तियों की जाँच**
- यह पिछली खण्ड के दौरान भी किया जा सकता है, आपको यह पता लगाना होगा कि इंटरनेट के प्रति किसी न किसी तरह से **क्या-क्या सम्भवतः एक्सपोज़ है** और उसे कैसे एक्सेस किया जा सकता है।
- यहाँ मैं **मैन्युअली एक्सपोज़ की गई infrastructure** जैसे वे इंस्टेंस जिन पर वेब पेज या अन्य पोर्ट्स खुले हैं, और साथ ही उन अन्य **क्लाउड managed सेवाओं** के बारे में बात कर रहा हूँ जिन्हें एक्सपोज़ होने के लिए कॉन्फ़िगर किया जा सकता है (जैसे DBs या buckets)
- फिर आपको चेक करना चाहिए **क्या वह resource एक्सपोज़ हो सकता है या नहीं** (गोपनीय जानकारी? vulnerabilities? एक्सपोज़ सेवा में misconfigurations?)
- **Permissions की जाँच**
- यहाँ आपको यह पता लगाना चाहिए कि क्लाउड के अंदर प्रत्येक role/user के **सभी permissions क्या हैं** और वे कैसे उपयोग किए जा रहे हैं
- बहुत सारे **highly privileged** (सब कुछ नियंत्रित करने वाले) खाते? Generated keys उपयोग में नहीं?... इन अधिकांश चेक्स को पहले बेंचमार्क परीक्षणों में किया जा चुका होना चाहिए
- यदि क्लाइंट OpenID या SAML या अन्य **federation** का उपयोग कर रहा है तो आपको उनसे आगे की **जानकारी** मांगनी पड़ सकती है कि **प्रत्येक role कैसे असाइन किया जा रहा है** (यह वही नहीं है कि admin role 1 user को असाइन है या 100 को)
- केवल यह पता लगाना **काफ़ी नहीं है** कि कौन से users के पास **admin** permissions "*:*" हैं। बहुत सारी **अन्य permissions** हैं जो उपयोग की जाने वाली सेवाओं के आधार पर बहुत **संवेदनशील** हो सकती हैं।
- इसके अलावा, permissions का दुरुपयोग करके फ़ॉलो करने के लिए **संभावित privesc** रास्ते होते हैं। इन सभी चीज़ों का ध्यान रखना चाहिए और जितने संभव हो उतने **privesc paths** रिपोर्ट किए जाने चाहिए।
- **इंटीग्रेशन की जाँच**
- यह बहुत सम्भाव्य है कि क्लाउड env के अंदर **other clouds या SaaS के साथ integrations** उपयोग हो रहे हों।
- जिन **integrations of the cloud you are auditing** को अन्य प्लेटफॉर्म के साथ जोड़ा गया है, उनके लिए आपको यह सूचित करना चाहिए **किसके पास उस integration का (ab)use करने की पहुँच है** और आपको पूछना चाहिए कि उस कार्य को करना कितना **सेंसिटिव** है।\
उदाहरण के लिए, कौन AWS bucket में लिख सकता है जहाँ से GCP डेटा ले रहा है (पूछें कि GCP में उस डेटा को प्रोसेस करना कितना संवेदनशील है).
- जिन **integrations inside the cloud you are auditing** को बाहरी प्लेटफॉर्म से एक्सेस किया जा रहा है, उनके लिए आपको यह पूछना चाहिए **बाहरी रूप से किसके पास उस integration का (ab)use करने की पहुँच है** और जाँच करनी चाहिए कि उस डेटा का उपयोग कैसे किया जा रहा है।\
उदाहरण के लिए, यदि कोई सेवा GCR में होस्ट की गई Docker image का उपयोग कर रही है, तो आपको पूछना चाहिए कि कौन उसे मॉडिफाई कर सकता है और जब वह image AWS क्लाउड के अंदर executed होगी तो उसे कौन सी संवेदनशील जानकारी और एक्सेस मिलेंगे।

## Multi-Cloud टूल्स

कई टूल्स हैं जिनका उपयोग विभिन्न क्लाउड परिवेशों का परीक्षण करने के लिए किया जा सकता है। इनसे संबंधित इंस्टॉलेशन चरण और लिंक इस खंड में दिए जाएंगे।

### [PurplePanda](https://github.com/carlospolop/purplepanda)

एक टूल जो क्लाउड्स और क्लाउड्स/SaaS के पार **bad configurations और privesc path** की पहचान करने के लिए है।

{{#tabs }}
{{#tab name="Install" }}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{{#endtab }}
{{#endtabs }}

### [Prowler](https://github.com/prowler-cloud/prowler)

यह **AWS, GCP & Azure** को सपोर्ट करता है। प्रत्येक प्रदाता को कैसे कॉन्फ़िगर करें, देखें: [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws)
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{{#tabs }}
{{#tab name="Install" }}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{{#endtab }}
{{#endtabs }}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{{#tabs }}
{{#tab name="Install" }}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{{#endtab }}
{{#endtabs }}

### [Steampipe](https://github.com/turbot)

{{#tabs }}
{{#tab name="Install" }}
Steampipe डाउनलोड और इंस्टॉल करें ([https://steampipe.io/downloads](https://steampipe.io/downloads)). या Brew का उपयोग करें:
```
brew tap turbot/tap
brew install steampipe
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>सभी प्रोजेक्ट्स की जाँच करें</summary>

सभी प्रोजेक्ट्स की जाँच करने के लिए आपको `gcp.spc` फाइल जनरेट करनी होगी जिसमें परीक्षण करने के लिए सभी प्रोजेक्ट्स निर्दिष्ट हों। आप बस निम्नलिखित स्क्रिप्ट के निर्देशों का पालन कर सकते हैं।
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

अन्य **GCP इनसाइट्स** (useful for enumerating services) देखने के लिए उपयोग करें: [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

Terraform GCP कोड देखने के लिए: [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

Steampipe के अन्य GCP plugins: [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{{#endtab }}

{{#tab name="AWS" }}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
Terraform AWS code देखने के लिए: [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

Steampipe के अधिक AWS plugins: [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{{#endtab }}
{{#endtabs }}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
यह python2.7 की आवश्यकता करता है और अप्रचलित/नीरखित लगता है।

### Nessus

Nessus में एक _**Audit Cloud Infrastructure**_ स्कैन है जो निम्नको सपोर्ट करता है: AWS, Azure, Office 365, Rackspace, Salesforce। **Azure** में कुछ अतिरिक्त कॉन्फ़िगरेशन्स चाहिए ताकि **Client Id** प्राप्त किया जा सके।

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist एक **मल्टी-क्लाउड टूल है जो Assets प्राप्त करता है** (Hostnames, IP Addresses) जो Cloud Providers से होता है।

{{#tabs }}
{{#tab name="Cloudlist" }}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{{#endtab }}

{{#tab name="Second Tab" }}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{{#endtab }}
{{#endtabs }}

### [**cartography**](https://github.com/lyft/cartography)

Cartography एक Python टूल है जो इन्फ्रास्ट्रक्चर संपत्तियों और उनके आपसी संबंधों को Neo4j डेटाबेस द्वारा संचालित एक सहज ग्राफ दृश्य में समेकित करता है।

{{#tabs }}
{{#tab name="Install" }}
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{{#endtab }}
{{#endtabs }}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase सेवाओं और सिस्टमों से एसेट्स और रिश्ते इकट्ठा करता है, जिनमें क्लाउड बुनियादी ढाँचा, SaaS applications, security controls और अन्य शामिल हैं, और इन्हें Neo4j database द्वारा समर्थित एक सहज ग्राफ़ दृश्य में प्रस्तुत करता है।

{{#tabs }}
{{#tab name="Install" }}
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{{#endtab }}

{{#tab name="GCP" }}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
- name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: "{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}"
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
{{#endtab }}
{{#endtabs }}

### [**SkyArk**](https://github.com/cyberark/SkyArk)

स्कैन किए गए AWS या Azure environment में सबसे अधिक privileged users की खोज करें, जिसमें AWS Shadow Admins भी शामिल हैं। यह powershell का उपयोग करता है।
```bash
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

एक टूल जो किसी कंपनी (target) के infrastructure, files और apps को शीर्ष क्लाउड प्रदाताओं (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode) पर खोजने के लिए है।

### [CloudFox](https://github.com/BishopFox/cloudfox)

- CloudFox एक टूल है जो क्लाउड infrastructure में exploitable attack paths खोजने के लिए है (वर्तमान में केवल AWS & Azure समर्थित हैं, GCP जल्द आ रहा है)।
- यह एक enumeration tool है जिसे manual pentesting की पूरकता के लिए बनाया गया है।
- यह क्लाउड environment के भीतर कोई भी data बनाता या संशोधित नहीं करता।

### More lists of cloud security tools

- [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{{#ref}}
gcp-security/
{{#endref}}

### Workspace

{{#ref}}
workspace-security/
{{#endref}}

## AWS

{{#ref}}
aws-security/
{{#endref}}

## Azure

{{#ref}}
azure-security/
{{#endref}}

### Attack Graph

[**Stormspotter** ](https://github.com/Azure/Stormspotter) Azure subscription में resources का “attack graph” बनाता है। यह red teams और pentesters को एक tenant के भीतर attack surface और pivot opportunities को visualize करने में सक्षम बनाता है, और आपके defenders को incident response के काम को तेजी से व्यवस्थित और प्राथमिकता देने में अतिरिक्त गति देता/देती है।

### Office365

आपको **Global Admin** या कम से कम **Global Admin Reader** की आवश्यकता होती है (हालाँकि ध्यान दें कि Global Admin Reader थोड़ी सीमित है)। हालांकि, ये सीमाएँ कुछ PS modules में दिखाई देती हैं और इन्हें **वेब एप्लिकेशन के माध्यम से** फीचर्स तक पहुँच कर बायपास किया जा सकता है।


{{#include ../banners/hacktricks-training.md}}
