# Pentesting Cloud 方法论

{{#include ../banners/hacktricks-training.md}}

<figure><img src="../images/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## 基本方法

每个 cloud 都有其特殊性，但一般来说在测试 cloud 环境时，有一些 **pentester 应该检查的常见事项**：

- **基准检查**
- 这将帮助你 **了解环境的规模** 以及 **所使用的服务**
- 这也能让你发现一些 **快速的错误配置**，因为你可以用 **自动化工具** 执行大部分这些测试
- **服务枚举**
- 如果你正确执行了基准测试，这里可能不会发现更多的错误配置，但你可能会发现一些基准测试中没有覆盖到的情况。
- 这将让你知道在 cloud 环境中 **到底在使用什么**
- 这对后续步骤会有很大帮助
- **检查暴露的资产**
- 这可以在上一节中完成，你需要 **找出所有可能以某种方式暴露给 Internet 的资源**，以及如何访问它们。
- 这里我指的是诸如带有网页的实例或暴露了其他端口的手动暴露基础设施，以及其他可配置为暴露的云托管服务（例如 DBs 或 buckets）
- 然后你应该检查 **该资源是否可以被暴露**（机密信息？漏洞？被暴露服务的错误配置？）
- **检查权限**
- 在此你应 **查明 cloud 内每个角色/用户的所有权限** 以及它们如何被使用
- 是否存在过多 **高度权限**（控制一切）的账户？生成的密钥未使用？……大多数这些检查本应已在基准测试中完成
- 如果客户使用 OpenID、SAML 或其他 **federation**，你可能需要向他们询问关于 **每个角色如何被分配** 的进一步 **信息**（将 admin 角色分配给 1 个用户与分配给 100 个用户并不相同）
- 仅仅找出哪些用户拥有 **admin** 权限 "*:*" 是不够的。还有许多 **其他权限**，根据所用服务可能非常 **敏感**。
- 此外，存在滥用权限的 **潜在 privesc** 路径。所有这些都应被考虑在内，并应尽可能报告 **尽量多的 privesc 路径**。
- **检查集成**
- 很有可能在该 cloud 环境中使用了与其他云或 SaaS 的 **集成**。
- 对于你正在审计的 cloud 与其他平台之间的 **integrations**，你应告知 **谁有权访问以（滥）用该集成**，并应询问该操作的 **敏感程度**。\
例如，谁能在一个 AWS bucket 写入数据，而 GCP 正从该 bucket 获取数据（询问在 GCP 处理该数据时该操作有多敏感）。
- 对于来自外部平台的、在你审计的 cloud 内的 **integrations**，你应询问 **谁在外部有权限访问以（滥）用该集成**，并检查该数据如何被使用。\
例如，如果某服务使用托管在 GCR 的 Docker 镜像，你应询问谁有权限修改该镜像，以及该镜像在在 AWS cloud 内执行时将会获得哪些敏感信息和访问权限。

## 多云工具

有若干工具可用于测试不同的 cloud 环境。本节将指明安装步骤和链接。

### [PurplePanda](https://github.com/carlospolop/purplepanda)

一个用于 **识别云内及跨云/SaaS 的错误配置和 privesc 路径** 的工具。

{{#tabs }}
{{#tab name="Install" }}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{{#endtab }}
{{#endtabs }}

### [Prowler](https://github.com/prowler-cloud/prowler)

它支持 **AWS、GCP 和 Azure**。请查看 [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws) 了解如何为每个提供商配置。
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{{#tabs }}
{{#tab name="Install" }}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{{#endtab }}
{{#endtabs }}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{{#tabs }}
{{#tab name="Install" }}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{{#endtab }}
{{#endtabs }}

### [Steampipe](https://github.com/turbot)

{{#tabs }}
{{#tab name="Install" }}
下载并安装 Steampipe ([https://steampipe.io/downloads](https://steampipe.io/downloads))。或者使用 Brew：
```
brew tap turbot/tap
brew install steampipe
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>检查所有项目</summary>

要检查所有项目，您需要生成 `gcp.spc` 文件来列出要测试的所有项目。您可以按照下面脚本中的说明进行操作。

</details>
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

要查看 **其他 GCP insights**（对枚举服务有用）请使用: [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

要查看 Terraform GCP 代码: [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

更多 Steampipe 的 GCP 插件: [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{{#endtab }}

{{#tab name="AWS" }}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
检查 Terraform AWS 代码： [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

更多 Steampipe 的 AWS 插件： [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{{#endtab }}
{{#endtabs }}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
需要 python2.7，且似乎已不再维护。

### Nessus

Nessus 有一个 _**Audit Cloud Infrastructure**_ 扫描，支持：AWS, Azure, Office 365, Rackspace, Salesforce。对于 **Azure** 需要一些额外配置以获取 **Client Id**。

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist 是一个 **multi-cloud tool for getting Assets** (Hostnames, IP Addresses) from Cloud Providers。

{{#tabs }}
{{#tab name="Cloudlist" }}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{{#endtab }}

{{#tab name="Second Tab" }}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{{#endtab }}
{{#endtabs }}

### [**cartography**](https://github.com/lyft/cartography)

Cartography 是一个 Python 工具，用于汇总基础设施资产及它们之间的关系，并以由 Neo4j 数据库驱动的直观图形视图展示。

{{#tabs }}
{{#tab name="Install" }}
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{{#endtab }}

{{#tab name="GCP" }}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{{#endtab }}
{{#endtabs }}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase 将来自服务和系统的资产与关系（包括云基础设施、SaaS 应用、安全控制等）收集到由 Neo4j 数据库支撑的直观图形视图中。

{{#tabs }}
{{#tab name="Install" }}
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{{#endtab }}

{{#tab name="GCP" }}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
- name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: "{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}"
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
{{#endtab }}
{{#endtabs }}

### [**SkyArk**](https://github.com/cyberark/SkyArk)

发现已扫描的 AWS 或 Azure 环境中权限最高的用户，包括 AWS Shadow Admins。它使用 powershell。
```bash
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

一个用于在主要云提供商（Amazon、Google、Microsoft、DigitalOcean、Alibaba、Vultr、Linode）上发现公司（目标）基础设施、文件和应用的工具。

### [CloudFox](https://github.com/BishopFox/cloudfox)

- CloudFox 是一个用于发现云基础设施中可利用的攻击路径的工具（目前仅支持 AWS & Azure，GCP 即将支持）。
- 它是一个枚举工具，旨在补充人工 pentesting。
- 它不会在云环境中创建或修改任何数据。

### 更多云安全工具列表

- [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{{#ref}}
gcp-security/
{{#endref}}

### Workspace

{{#ref}}
workspace-security/
{{#endref}}

## AWS

{{#ref}}
aws-security/
{{#endref}}

## Azure

{{#ref}}
azure-security/
{{#endref}}

### 攻击图

[**Stormspotter** ](https://github.com/Azure/Stormspotter)在 Azure 订阅中为资源创建“攻击图”。它使 red teams 和 pentesters 能够可视化租户内的攻击面和横向移动机会，并帮助你的防守方快速定位并优先处理事件响应工作。

### Office365

你需要 **Global Admin** 或至少 **Global Admin Reader**（注意 Global Admin Reader 有一些限制）。不过，这些限制会在某些 PS 模块中出现，并且可以通过 **通过 web 应用程序** 访问功能来绕过。

{{#include ../banners/hacktricks-training.md}}
