# Az - AI Foundry, AI Hubs, Azure OpenAI & AI Search

{{#include ../../../banners/hacktricks-training.md}}

## Dlaczego te usługi są ważne

Azure AI Foundry to rozwiązanie Microsoftu do budowania aplikacji GenAI. Hub agreguje AI projects, Azure ML workspaces, compute, data stores, registries, prompt flow assets oraz połączenia do downstream services takich jak **Azure OpenAI** i **Azure AI Search**. Każdy komponent zwykle udostępnia:

- **Długotrwałe klucze API** (OpenAI, Search, data connectors) replikowane w Azure Key Vault lub w obiektach połączeń workspace.
- **Managed Identities (MI)**, które kontrolują deployments, vector indexing jobs, model evaluation pipelines oraz operacje Git/GitHub Enterprise.
- **Cross-service links** (storage accounts, container registries, Application Insights, Log Analytics), które dziedziczą uprawnienia hub/project.
- **Multi-tenant connectors** (Hugging Face, Azure Data Lake, Event Hubs), które mogą leak upstream credentials or tokens.

Kompromitacja pojedynczego hub/project może więc oznaczać kontrolę nad downstream managed identities, compute clusters, online endpoints oraz dowolnymi search indexes lub OpenAI deployments referencjonowanymi przez prompt flows.

## Kluczowe komponenty i powierzchnia bezpieczeństwa

- **AI Hub (`Microsoft.MachineLearningServices/hubs`)**: Obiekt najwyższego poziomu definiujący region, managed network, system datastores, domyślny Key Vault, Container Registry, Log Analytics oraz hub-level identities. Skompromitowany hub pozwala atakującemu wstrzyknąć nowe projects, registries lub user-assigned identities.
- **AI Projects (`Microsoft.MachineLearningServices/workspaces`)**: Hostują prompt flows, data assets, environments, component pipelines oraz online/batch endpoints. Projects dziedziczą zasoby hub i mogą je zastąpić własnym storage, kv i MI. Każdy workspace przechowuje sekrety pod `/connections` i `/datastores`.
- **Managed Compute & Endpoints**: Obejmuje managed online endpoints, batch endpoints, serverless endpoints, AKS/ACI deployments oraz on-demand inference servers. Tokeny pobierane z Azure Instance Metadata Service (IMDS) wewnątrz tych runtime'ów zwykle niosą przypisania ról workspace/project MI (często `Contributor` lub `Owner`).
- **AI Registries & Model Catalog**: Umożliwiają dzielenie modeli, environments, components, danych i wyników ewaluacji w regionie. Registries mogą automatycznie synchronizować się z GitHub/Azure DevOps, co oznacza, że PATs mogą być osadzone w definicjach połączeń.
- **Azure OpenAI (`Microsoft.CognitiveServices/accounts` with `kind=OpenAI`)**: Dostarcza modele z rodziny GPT. Dostęp jest kontrolowany przez przypisania ról + admin/query keys. Wiele Foundry prompt flows przechowuje wygenerowane klucze jako sekrety lub zmienne środowiskowe dostępne z compute jobs.
- **Azure AI Search (`Microsoft.Search/searchServices`)**: Vector/index storage zazwyczaj podłączony przez Search admin key przechowywany w połączeniu projektu. Dane indeksu mogą zawierać wrażliwe embeddings, pobrane dokumenty lub surowe korpusy treningowe.

## Architektura istotna dla bezpieczeństwa

### Managed Identities & Role Assignments

- AI hubs/projects mogą włączać **system-assigned** lub **user-assigned** identities. Te tożsamości zwykle posiadają role na storage accounts, key vaults, container registries, Azure OpenAI resources, Azure AI Search services, Event Hubs, Cosmos DB lub custom APIs.
- Online endpoints dziedziczą project MI lub mogą zostać nadpisane dedykowanym user-assigned MI dla danego deploymentu.
- Prompt Flow connections i Automated Agents mogą żądać tokenów przez `DefaultAzureCredential`; przechwycenie metadata endpoint z compute daje tokeny umożliwiające lateral movement.

### Granice sieciowe

- Hubs/projects obsługują **`publicNetworkAccess`**, **private endpoints**, **Managed VNet** i **managedOutbound`** reguły. Nieprawidłowa konfiguracja `allowInternetOutbound` lub otwarte scoring endpoints umożliwiają bezpośrednią eksfiltrację.
- Azure OpenAI oraz AI Search obsługują **firewall rules**, **Private Endpoint Connections (PEC)**, **shared private link resources** oraz `trustedClientCertificates`. Gdy public access jest włączony, te usługi akceptują żądania z dowolnego source IP, który zna klucz.

### Magazyny danych i sekretów

- Domyślne wdrożenia hub/project tworzą **storage account**, **Azure Container Registry**, **Key Vault**, **Application Insights** oraz **Log Analytics** workspace wewnątrz ukrytej managed resource group (wzorzec: `mlw-<workspace>-rg`).
- Workspace **datastores** referencjonują blob/data lake containers i mogą osadzać SAS tokens, service principal secrets lub storage access keys.
- Workspace **connections** (dla Azure OpenAI, AI Search, Cognitive Services, Git, Hugging Face itd.) przechowują poświadczenia w workspace Key Vault i ujawniają je poprzez management plane przy listowaniu connection (wartości są base64-encoded JSON).
- **AI Search admin keys** dają pełny dostęp do odczytu/zapisu do indexes, skillsets, data sources oraz pozwalają na pobieranie dokumentów, które zasilają systemy RAG.

### Monitorowanie i łańcuch dostaw

- AI Foundry wspiera integrację z GitHub/Azure DevOps dla kodu i prompt flow assets. OAuth tokens lub PATs żyją w Key Vault + metadata połączeń.
- Model Catalog może mirrorować Hugging Face artifacts. Jeśli `trust_remote_code=true`, podczas deploymentu może zostać wykonany arbitralny kod Python.
- Data/feature pipelines logują do Application Insights lub Log Analytics, ujawniając connection strings.

## Enumeracja za pomocą `az`
```bash
# Install the Azure ML / AI CLI extension (if missing)
az extension add --name ml

# Enumerate AI Hubs (workspaces with kind=hub) and inspect properties
az ml workspace list --filtered-kinds hub --resource-group <RG> --query "[].{name:name, location:location, rg:resourceGroup}" -o table
az resource show --name <HUB> --resource-group <RG> \
--resource-type Microsoft.MachineLearningServices/workspaces \
--query "{location:location, publicNetworkAccess:properties.publicNetworkAccess, identity:identity, managedResourceGroup:properties.managedResourceGroup}" -o jsonc

# Enumerate AI Projects (kind=project) under a hub or RG
az resource list --resource-type Microsoft.MachineLearningServices/workspaces --query "[].{name:name, rg:resourceGroup, location:location}" -o table
az ml workspace list --filtered-kinds project --resource-group <RG> \
--query "[?contains(properties.hubArmId, '/workspaces/<HUB>')].{name:name, rg:resourceGroup, location:location}"

# Show workspace level settings (managed identity, storage, key vault, container registry)
az ml workspace show --name <WS> --resource-group <RG> \
--query "{managedNetwork:properties.managedNetwork, storageAccount:properties.storageAccount, containerRegistry:properties.containerRegistry, keyVault:properties.keyVault, identity:identity}"

# List workspace connections (OpenAI, AI Search, Git, data sources)
az ml connection list --workspace-name <WS> --resource-group <RG> --populate-secrets -o table
az ml connection show --workspace-name <WS> --resource-group <RG> --name <CONNECTION>
# For REST (returns base64 encoded secrets)
az rest --method GET \
--url "https://management.azure.com/subscriptions/<SUB>/resourceGroups/<RG>/providers/Microsoft.MachineLearningServices/workspaces/<WS>/connections/<CONN>?api-version=2024-04-01"

# Enumerate datastores and extract credentials/SAS
az ml datastore list --workspace-name <WS> --resource-group <RG>
az ml datastore show --name <DATASTORE> --workspace-name <WS> --resource-group <RG>

# List managed online/batch endpoints and deployments (capture identity per deployment)
az ml online-endpoint list --workspace-name <WS> --resource-group <RG>
az ml online-endpoint show --name <ENDPOINT> --workspace-name <WS> --resource-group <RG>
az ml online-deployment show --name <DEPLOYMENT> --endpoint-name <ENDPOINT> --workspace-name <WS> --resource-group <RG> \
--query "{identity:identity, environment:properties.environmentId, codeConfiguration:properties.codeConfiguration}"

# Discover prompt flows, components, environments, data assets
az ml component list --workspace-name <WS> --resource-group <RG>
az ml data list --workspace-name <WS> --resource-group <RG> --type uri_folder
az ml environment list --workspace-name <WS> --resource-group <RG>
az ml job list --workspace-name <WS> --resource-group <RG> --type pipeline

# List hub/project managed identities and their role assignments
az identity list --resource-group <RG>
az role assignment list --assignee <MI-PRINCIPAL-ID> --all

# Azure OpenAI resources (filter kind==OpenAI)
az resource list --resource-type Microsoft.CognitiveServices/accounts \
--query "[?kind=='OpenAI'].{name:name, rg:resourceGroup, location:location}" -o table
az cognitiveservices account list --resource-group <RG> \
--query "[?kind=='OpenAI'].{name:name, location:location}" -o table
az cognitiveservices account show --name <AOAI-NAME> --resource-group <RG>
az cognitiveservices account keys list --name <AOAI-NAME> --resource-group <RG>
az cognitiveservices account deployment list --name <AOAI-NAME> --resource-group <RG>
az cognitiveservices account network-rule list --name <AOAI-NAME> --resource-group <RG>

# Azure AI Search services
az search service list --resource-group <RG>
az search service show --name <SEARCH-NAME> --resource-group <RG> \
--query "{sku:sku.name, publicNetworkAccess:properties.publicNetworkAccess, privateEndpoints:properties.privateEndpointConnections}"
az search admin-key show --service-name <SEARCH-NAME> --resource-group <RG>
az search query-key list --service-name <SEARCH-NAME> --resource-group <RG>
az search shared-private-link-resource list --service-name <SEARCH-NAME> --resource-group <RG>

# AI Search data-plane (requires admin key in header)
az rest --method GET \
--url "https://<SEARCH-NAME>.search.windows.net/indexes?api-version=2024-07-01" \
--headers "api-key=<ADMIN-KEY>"
az rest --method GET \
--url "https://<SEARCH-NAME>.search.windows.net/datasources?api-version=2024-07-01" \
--headers "api-key=<ADMIN-KEY>"
az rest --method GET \
--url "https://<SEARCH-NAME>.search.windows.net/indexers?api-version=2024-07-01" \
--headers "api-key=<ADMIN-KEY>"

# Linkage between workspaces and search / openAI (REST helper)
az rest --method GET \
--url "https://management.azure.com/subscriptions/<SUB>/resourceGroups/<RG>/providers/Microsoft.MachineLearningServices/workspaces/<WS>/connections?api-version=2024-04-01" \
--query "value[?properties.target=='AzureAiSearch' || properties.target=='AzureOpenAI']"
```
## Na co zwracać uwagę podczas oceny

- **Zakres tożsamości**: Projekty często ponownie używają potężnej user-assigned identity przypisanej do wielu usług. Przechwycenie tokenów IMDS z dowolnego managed compute powoduje odziedziczenie tych uprawnień.
- **Connection objects**: Ładunek Base64 zawiera secret oraz metadata (endpoint URL, API version). Wiele zespołów zostawia tutaj OpenAI + Search admin keys zamiast rotować je często.
- **Git & external source connectors**: PATs lub OAuth refresh tokens mogą pozwolić na push access do kodu definiującego pipelines/prompt flows.
- **Datastores & data assets**: Udostępniają SAS tokens ważne przez miesiące; data assets mogą wskazywać na PII klientów, embeddings lub zbiory treningowe.
- **Managed Network overrides**: `allowInternetOutbound=true` lub `publicNetworkAccess=Enabled` sprawia, że eksfiltracja sekretów z jobs/endpoints jest trywialna.
- **Hub-managed resource group**: Zawiera storage account (`<workspace>storage`), container registry, KV i Log Analytics. Dostęp do tej RG często oznacza pełne przejęcie, nawet jeśli portal to ukrywa.

## Referencje

- [Azure AI Foundry architecture](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/ai-resources)
- [Azure Machine Learning CLI v2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-cli)
- [Azure OpenAI security controls](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/network-security)
- [Azure AI Search security](https://learn.microsoft.com/en-us/azure/search/search-security-overview)

{{#include ../../../banners/hacktricks-training.md}}
